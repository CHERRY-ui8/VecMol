"""
é”®ç›¸å…³è¯„ä¼°æ¨¡å—
åŒ…å«é”®åˆ¤æ–­ã€é”®é•¿åˆ†æã€ç¼ºå¤±é”®æ£€æµ‹ã€è¿é€šæ€§åˆ†æç­‰åŠŸèƒ½
"""

import torch
import numpy as np
from pathlib import Path
from tqdm import tqdm

from funcmol.evaluation.utils_evaluation import (
    bonds1, bonds2, bonds3,
    margin1, margin2, margin3,
    atom_decoder_dict
)


def get_all_possible_bond_orders(atom1, atom2, distance, 
                                 margin1_val=None, margin2_val=None, margin3_val=None):
    """
    è·å–æ‰€æœ‰åœ¨marginå†…çš„å¯èƒ½é”®ç±»å‹ï¼ˆä¸æŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    
    Args:
        atom1: åŸå­1ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        atom2: åŸå­2ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        distance: åŸå­é—´è·ç¦»ï¼ˆå•ä½ï¼šÃ…ï¼‰
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        list: æ‰€æœ‰å¯èƒ½çš„é”®ç±»å‹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (bond_order, standard_dist_pm, relative_deviation)
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    distance_pm = 100 * distance  # è½¬æ¢ä¸ºpmå•ä½
    possible_bonds = []
    
    # æ£€æŸ¥ä¸‰é”®
    if atom1 in bonds3 and atom2 in bonds3[atom1]:
        standard_bond3_pm = bonds3[atom1][atom2]
        threshold3_pm = standard_bond3_pm + margin3_val
        if distance_pm < threshold3_pm:
            relative_deviation = abs(distance_pm - standard_bond3_pm) / standard_bond3_pm
            possible_bonds.append((3, standard_bond3_pm, relative_deviation))
    
    # æ£€æŸ¥åŒé”®
    if atom1 in bonds2 and atom2 in bonds2[atom1]:
        standard_bond2_pm = bonds2[atom1][atom2]
        threshold2_pm = standard_bond2_pm + margin2_val
        if distance_pm < threshold2_pm:
            relative_deviation = abs(distance_pm - standard_bond2_pm) / standard_bond2_pm
            possible_bonds.append((2, standard_bond2_pm, relative_deviation))
    
    # æ£€æŸ¥å•é”®
    if atom1 in bonds1 and atom2 in bonds1[atom1]:
        standard_bond1_pm = bonds1[atom1][atom2]
        threshold1_pm = standard_bond1_pm + margin1_val
        if distance_pm < threshold1_pm:
            relative_deviation = abs(distance_pm - standard_bond1_pm) / standard_bond1_pm
            possible_bonds.append((1, standard_bond1_pm, relative_deviation))
    
    return possible_bonds


def get_bond_order(atom1, atom2, distance, check_exists=False, 
                   margin1_val=None, margin2_val=None, margin3_val=None):
    """
    åˆ¤æ–­é”®ç±»å‹ï¼ˆå•é”®/åŒé”®/ä¸‰é”®ï¼‰
    
    ä½¿ç”¨"æœ€æ¥è¿‘æ ‡å‡†é”®é•¿"åŸåˆ™ï¼šé€‰æ‹©è·ç¦»æœ€æ¥è¿‘æ ‡å‡†é”®é•¿çš„é”®ç±»å‹
    
    Args:
        atom1: åŸå­1ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼Œå¦‚ 'C', 'H'ï¼‰
        atom2: åŸå­2ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        distance: åŸå­é—´è·ç¦»ï¼ˆå•ä½ï¼šÃ…ï¼‰
        check_exists: æ˜¯å¦æ£€æŸ¥åŸå­å¯¹æ˜¯å¦å­˜åœ¨æ ‡å‡†é”®é•¿
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        int: é”®ç±»å‹ (0=æ— é”®, 1=å•é”®, 2=åŒé”®, 3=ä¸‰é”®)
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    distance_pm = 100 * distance  # è½¬æ¢ä¸ºpmå•ä½
    
    # æ£€æŸ¥åŸå­å¯¹æ˜¯å¦å­˜åœ¨æ ‡å‡†é”®é•¿
    if check_exists:
        if atom1 not in bonds1:
            return 0
        if atom2 not in bonds1[atom1]:
            return 0
    
    # ä½¿ç”¨"æœ€æ¥è¿‘æ ‡å‡†é”®é•¿"åŸåˆ™ï¼ˆæ–¹æ¡ˆ1ï¼šç›¸å¯¹åå·®ï¼‰
    # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„é”®ç±»å‹åŠå…¶æ ‡å‡†é”®é•¿
    candidate_bonds = []
    
    # æ£€æŸ¥ä¸‰é”®
    if atom1 in bonds3 and atom2 in bonds3[atom1]:
        standard_bond3_pm = bonds3[atom1][atom2]
        threshold3_pm = standard_bond3_pm + margin3_val
        if distance_pm < threshold3_pm:
            # ä½¿ç”¨ç›¸å¯¹åå·®è€Œéç»å¯¹åå·®
            relative_deviation = abs(distance_pm - standard_bond3_pm) / standard_bond3_pm
            candidate_bonds.append((3, standard_bond3_pm, relative_deviation))
    
    # æ£€æŸ¥åŒé”®
    if atom1 in bonds2 and atom2 in bonds2[atom1]:
        standard_bond2_pm = bonds2[atom1][atom2]
        threshold2_pm = standard_bond2_pm + margin2_val
        if distance_pm < threshold2_pm:
            # ä½¿ç”¨ç›¸å¯¹åå·®è€Œéç»å¯¹åå·®
            relative_deviation = abs(distance_pm - standard_bond2_pm) / standard_bond2_pm
            candidate_bonds.append((2, standard_bond2_pm, relative_deviation))
    
    # æ£€æŸ¥å•é”®
    if atom1 in bonds1 and atom2 in bonds1[atom1]:
        standard_bond1_pm = bonds1[atom1][atom2]
        threshold1_pm = standard_bond1_pm + margin1_val
        if distance_pm < threshold1_pm:
            # ä½¿ç”¨ç›¸å¯¹åå·®è€Œéç»å¯¹åå·®
            relative_deviation = abs(distance_pm - standard_bond1_pm) / standard_bond1_pm
            candidate_bonds.append((1, standard_bond1_pm, relative_deviation))
    
    # å¦‚æœæ²¡æœ‰å€™é€‰é”®ï¼Œè¿”å›æ— é”®
    if not candidate_bonds:
        return 0
    
    # é€‰æ‹©ç›¸å¯¹åå·®æœ€å°çš„é”®ç±»å‹ï¼ˆæœ€æ¥è¿‘æ ‡å‡†é”®é•¿ï¼‰
    candidate_bonds.sort(key=lambda x: x[2])  # æŒ‰ç›¸å¯¹åå·®æ’åº
    return candidate_bonds[0][0]  # è¿”å›é”®ç±»å‹


def get_expected_bond_order(atom1, atom2, distance, 
                            margin1_val=None, margin2_val=None, margin3_val=None):
    """
    æ ¹æ®è·ç¦»åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹ï¼ˆç”¨äºæ£€æµ‹ç¼ºå¤±é”®å’Œé”®ç±»å‹ä¸åŒ¹é…ï¼‰
    
    ä½¿ç”¨"æœ€æ¥è¿‘æ ‡å‡†é”®é•¿"åŸåˆ™ï¼šé€‰æ‹©è·ç¦»æœ€æ¥è¿‘æ ‡å‡†é”®é•¿çš„é”®ç±»å‹
    
    Args:
        atom1: åŸå­1ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        atom2: åŸå­2ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        distance: åŸå­é—´è·ç¦»ï¼ˆå•ä½ï¼šÃ…ï¼‰
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        tuple: (expected_order, standard_dist, threshold)
            - expected_order: æœŸæœ›çš„é”®ç±»å‹ (0/1/2/3)
            - standard_dist: å¯¹åº”çš„æ ‡å‡†é”®é•¿ï¼ˆå•ä½ï¼šÃ…ï¼‰
            - threshold: åˆ¤æ–­é˜ˆå€¼ï¼ˆå•ä½ï¼šÃ…ï¼‰
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    distance_pm = 100 * distance  # è½¬æ¢ä¸ºpmå•ä½
    
    # ä½¿ç”¨"æœ€æ¥è¿‘æ ‡å‡†é”®é•¿"åŸåˆ™ï¼ˆæ–¹æ¡ˆ1ï¼šç›¸å¯¹åå·®ï¼‰
    # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„é”®ç±»å‹åŠå…¶æ ‡å‡†é”®é•¿
    candidate_bonds = []
    
    # æ£€æŸ¥ä¸‰é”®
    if atom1 in bonds3 and atom2 in bonds3[atom1]:
        standard_bond3_pm = bonds3[atom1][atom2]
        threshold3_pm = standard_bond3_pm + margin3_val
        if distance_pm < threshold3_pm:
            # ä½¿ç”¨ç›¸å¯¹åå·®è€Œéç»å¯¹åå·®
            relative_deviation = abs(distance_pm - standard_bond3_pm) / standard_bond3_pm
            candidate_bonds.append((3, standard_bond3_pm, relative_deviation, threshold3_pm))
    
    # æ£€æŸ¥åŒé”®
    if atom1 in bonds2 and atom2 in bonds2[atom1]:
        standard_bond2_pm = bonds2[atom1][atom2]
        threshold2_pm = standard_bond2_pm + margin2_val
        if distance_pm < threshold2_pm:
            # ä½¿ç”¨ç›¸å¯¹åå·®è€Œéç»å¯¹åå·®
            relative_deviation = abs(distance_pm - standard_bond2_pm) / standard_bond2_pm
            candidate_bonds.append((2, standard_bond2_pm, relative_deviation, threshold2_pm))
    
    # æ£€æŸ¥å•é”®
    if atom1 in bonds1 and atom2 in bonds1[atom1]:
        standard_bond1_pm = bonds1[atom1][atom2]
        threshold1_pm = standard_bond1_pm + margin1_val
        if distance_pm < threshold1_pm:
            # ä½¿ç”¨ç›¸å¯¹åå·®è€Œéç»å¯¹åå·®
            relative_deviation = abs(distance_pm - standard_bond1_pm) / standard_bond1_pm
            candidate_bonds.append((1, standard_bond1_pm, relative_deviation, threshold1_pm))
    
    # å¦‚æœæ²¡æœ‰å€™é€‰é”®ï¼Œè¿”å›æ— é”®
    if not candidate_bonds:
        return 0, None, None
    
    # é€‰æ‹©ç›¸å¯¹åå·®æœ€å°çš„é”®ç±»å‹ï¼ˆæœ€æ¥è¿‘æ ‡å‡†é”®é•¿ï¼‰
    candidate_bonds.sort(key=lambda x: x[2])  # æŒ‰ç›¸å¯¹åå·®æ’åº
    best_order, best_standard_pm, _, best_threshold_pm = candidate_bonds[0]
    
    return best_order, best_standard_pm / 100.0, best_threshold_pm / 100.0


def optimize_bonds_for_stability(positions, atom_types, atom_decoder, charges,
                                 margin1_val=None, margin2_val=None, margin3_val=None,
                                 max_iterations=10):
    """
    å…¨å±€ä¼˜åŒ–é”®ç»„åˆï¼Œé€‰æ‹©ä½¿ç¨³å®šåŸå­æ¯”ä¾‹æœ€å¤§çš„ç»„åˆ
    
    ä½¿ç”¨è¿­ä»£æ”¹è¿›ç®—æ³•ï¼š
    1. åˆå§‹ï¼šä½¿ç”¨"æœ€æ¥è¿‘æ ‡å‡†é”®é•¿"åŸåˆ™é€‰æ‹©é”®
    2. è¿­ä»£æ”¹è¿›ï¼šå¯¹äºæ¯ä¸ªå¯èƒ½çš„é”®ï¼Œå°è¯•æ”¹å˜å®ƒçš„ç±»å‹ï¼Œçœ‹æ˜¯å¦èƒ½æé«˜ç¨³å®šæ€§
    3. é‡å¤ç›´åˆ°æ”¶æ•›æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        charges: [N] åŸå­ç”µè·
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
    
    Returns:
        torch.Tensor: ä¼˜åŒ–åçš„é”®ç±»å‹çŸ©é˜µ [N, N]
    """
    from funcmol.analysis.rdkit_functions import allowed_bonds
    
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    n = positions.shape[0]
    device = positions.device
    
    # è®¡ç®—æ‰€æœ‰åŸå­å¯¹çš„è·ç¦»
    pos = positions.unsqueeze(0)
    dists = torch.cdist(pos, pos, p=2).squeeze(0)
    
    # æ‰¾å‡ºæ‰€æœ‰å¯èƒ½çš„é”®ç±»å‹ï¼ˆåœ¨marginå†…çš„ï¼‰
    possible_bonds = {}  # {(i, j): [(order, std_dist, rel_dev), ...]}
    for i in range(n):
        for j in range(i):
            atom1 = atom_decoder[atom_types[i].item()]
            atom2 = atom_decoder[atom_types[j].item()]
            distance = dists[i, j].item()
            bonds = get_all_possible_bond_orders(
                atom1, atom2, distance, margin1_val, margin2_val, margin3_val
            )
            if bonds:
                possible_bonds[(i, j)] = bonds
                possible_bonds[(j, i)] = bonds  # å¯¹ç§°
    
    # åˆå§‹åŒ–ï¼šä½¿ç”¨"æœ€æ¥è¿‘æ ‡å‡†é”®é•¿"åŸåˆ™
    bond_types = torch.zeros((n, n), dtype=torch.int, device=device)
    for (i, j), bonds in possible_bonds.items():
        if i < j:  # åªå¤„ç†ä¸Šä¸‰è§’
            # é€‰æ‹©ç›¸å¯¹åå·®æœ€å°çš„
            bonds_sorted = sorted(bonds, key=lambda x: x[2])
            best_order = bonds_sorted[0][0]
            bond_types[i, j] = best_order
            bond_types[j, i] = best_order
    
    def calculate_stability_score(bond_matrix):
        """è®¡ç®—ç¨³å®šæ€§åˆ†æ•°ï¼ˆç¨³å®šåŸå­çš„æ¯”ä¾‹ï¼‰"""
        edge_types = bond_matrix.clone()
        edge_types[edge_types == 4] = 1.5
        edge_types[edge_types < 0] = 0
        valencies = torch.sum(edge_types, dim=-1).long()
        
        stable_count = 0
        for i, (atom_type, valency, charge) in enumerate(zip(atom_types, valencies, charges)):
            atom_type = atom_type.item()
            valency = valency.item()
            charge = charge.item()
            possible_bonds_list = allowed_bonds[atom_decoder[atom_type]]
            
            if type(possible_bonds_list) == int:
                is_stable = possible_bonds_list == valency
            elif type(possible_bonds_list) == dict:
                expected_bonds = possible_bonds_list.get(charge, possible_bonds_list.get(0))
                if type(expected_bonds) == int:
                    is_stable = expected_bonds == valency
                else:
                    is_stable = valency in expected_bonds
            else:
                is_stable = valency in possible_bonds_list
            
            if is_stable:
                stable_count += 1
        
        return stable_count / n if n > 0 else 0.0
    
    # è¿­ä»£æ”¹è¿›
    current_score = calculate_stability_score(bond_types)
    
    for _ in range(max_iterations):
        improved = False
        
        # å°è¯•æ”¹è¿›æ¯ä¸ªå¯èƒ½çš„é”®
        for (i, j), bonds in possible_bonds.items():
            if i >= j:  # åªå¤„ç†ä¸Šä¸‰è§’
                continue
            
            if len(bonds) <= 1:
                continue  # åªæœ‰ä¸€ä¸ªé€‰æ‹©ï¼Œæ— æ³•æ”¹è¿›
            
            # å°è¯•æ¯ä¸ªå¯èƒ½çš„é”®ç±»å‹
            best_order = bond_types[i, j].item()
            best_score = current_score
            
            for order, _, _ in bonds:
                if order == best_order:
                    continue
                
                # å°è¯•è¿™ä¸ªé”®ç±»å‹
                bond_types[i, j] = order
                bond_types[j, i] = order
                new_score = calculate_stability_score(bond_types)
                
                if new_score > best_score:
                    best_score = new_score
                    best_order = order
                    improved = True
            
            # æ¢å¤æœ€ä½³é€‰æ‹©
            bond_types[i, j] = best_order
            bond_types[j, i] = best_order
            current_score = best_score
        
        if not improved:
            break  # æ²¡æœ‰æ”¹è¿›ï¼Œæ”¶æ•›
    
    return bond_types


def build_xae_molecule(positions, atom_types, dataset_info, atom_decoder, 
                       margin1_val=None, margin2_val=None, margin3_val=None,
                       use_global_optimization=True, charges=None, 
                       use_iterative_improvement=True, max_iterations=10):
    """
    æ„å»ºåˆ†å­é”®çŸ©é˜µ
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
        use_global_optimization: æ˜¯å¦ä½¿ç”¨å…¨å±€ä¼˜åŒ–
            - True: å°åˆ†å­(n<=12)ä½¿ç”¨å›æº¯ç©·å°½æœç´¢ï¼Œå¤§åˆ†å­ä½¿ç”¨è¿­ä»£æ”¹è¿›æˆ–è´ªå¿ƒ
            - False: ä½¿ç”¨ç®€å•çš„"æœ€æ¥è¿‘æ ‡å‡†é”®é•¿"æ–¹æ³•ï¼ˆè´ªå¿ƒï¼‰
        charges: [N] åŸå­ç”µè·
        use_iterative_improvement: å¯¹äºå¤§åˆ†å­(n>12)ï¼Œæ˜¯å¦ä½¿ç”¨è¿­ä»£æ”¹è¿›ï¼ˆé»˜è®¤Trueï¼‰
            - True: ä½¿ç”¨è¿­ä»£æ”¹è¿›ï¼ˆä»è´ªå¿ƒè§£å¼€å§‹ï¼Œé€æ­¥æ”¹è¿›ï¼‰
            - False: ä½¿ç”¨çº¯è´ªå¿ƒç®—æ³•
        max_iterations: è¿­ä»£æ”¹è¿›çš„æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤10ï¼‰
    
    Returns:
        tuple: (X, A, E)
            - X: åŸå­ç±»å‹ [N]
            - A: é‚»æ¥çŸ©é˜µ [N, N] (bool)
            - E: é”®ç±»å‹çŸ©é˜µ [N, N] (int)
    """
    n = positions.shape[0]
    X = atom_types
    device = positions.device
    
    # é»˜è®¤ä½¿ç”¨å…¨å±€ä¼˜åŒ–ï¼ˆç©·å°½æ‰€æœ‰å¯èƒ½çš„é”®ç»„åˆï¼Œæ‰¾åˆ°ç¨³å®šåŸå­æ•°æœ€å¤šçš„ç»„åˆï¼‰
    # å¦‚æœuse_global_optimization=Falseï¼Œåˆ™ä½¿ç”¨ç®€å•çš„"æœ€æ¥è¿‘æ ‡å‡†é”®é•¿"æ–¹æ³•
    if use_global_optimization is False:
        # ä½¿ç”¨ç®€å•çš„"æœ€æ¥è¿‘æ ‡å‡†é”®é•¿"æ–¹æ³•ï¼ˆä¸è¿›è¡Œå…¨å±€ä¼˜åŒ–ï¼‰
        A = torch.zeros((n, n), dtype=torch.bool, device=device)
        E = torch.zeros((n, n), dtype=torch.int, device=device)
        
        pos = positions.unsqueeze(0)
        dists = torch.cdist(pos, pos, p=2).squeeze(0)
        
        for i in range(n):
            for j in range(i):
                atom1_str = atom_decoder[atom_types[i].item()]
                atom2_str = atom_decoder[atom_types[j].item()]
                if dataset_info['name'] == 'qm9':
                    order = get_bond_order(
                        atom1_str, 
                        atom2_str, 
                        dists[i, j],
                        margin1_val=margin1_val,
                        margin2_val=margin2_val,
                        margin3_val=margin3_val
                    )
                elif dataset_info['name'] == 'geom':
                    order = get_bond_order(
                        atom1_str, 
                        atom2_str, 
                        dists[i, j],
                        check_exists=True,
                        margin1_val=margin1_val,
                        margin2_val=margin2_val,
                        margin3_val=margin3_val
                    )
                    if order > 1:
                        order = 1
                
                if order > 0:
                    A[i, j] = 1
                    A[j, i] = 1
                    E[i, j] = order
                    E[j, i] = order
        
        return X, A, E
    
    # ä½¿ç”¨å…¨å±€ä¼˜åŒ–ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
    A = torch.zeros((n, n), dtype=torch.bool, device=device)
    E = torch.zeros((n, n), dtype=torch.int, device=device)
    
    pos = positions.unsqueeze(0)
    dists = torch.cdist(pos, pos, p=2).squeeze(0)
    
    # ä½¿ç”¨å…¨å±€ä¼˜åŒ–ï¼šç©·å°½æ‰€æœ‰å¯èƒ½çš„é”®ç»„åˆï¼Œæ‰¾åˆ°ç¨³å®šåŸå­æ•°æœ€å¤šçš„ç»„åˆ
    from funcmol.analysis.rdkit_functions import allowed_bonds
    
    # ç¬¬ä¸€æ­¥ï¼šæ‰¾å‡ºæ‰€æœ‰å¯èƒ½çš„é”®ï¼ˆè·ç¦»åœ¨marginå†…çš„æ‰€æœ‰é”®ç±»å‹ï¼‰
    # possible_bonds_dict: {(i, j): [(order, std, dev), ...]}
    possible_bonds_dict = {}
    for i in range(n):
        for j in range(i):
            # è·å–åŸå­ç±»å‹å­—ç¬¦ä¸²
            atom1_str = atom_decoder[atom_types[i].item()]
            atom2_str = atom_decoder[atom_types[j].item()]
            if dataset_info['name'] == 'qm9':
                possible_bonds = get_all_possible_bond_orders(
                    atom1_str, 
                    atom2_str, 
                    dists[i, j],
                    margin1_val=margin1_val,
                    margin2_val=margin2_val,
                    margin3_val=margin3_val
                )
            elif dataset_info['name'] == 'geom':
                # å¯¹äºgeomæ•°æ®é›†ï¼Œä½¿ç”¨limit_bonds_to_one
                possible_bonds = get_all_possible_bond_orders(
                    atom1_str, 
                    atom2_str, 
                    dists[i, j],
                    margin1_val=margin1_val,
                    margin2_val=margin2_val,
                    margin3_val=margin3_val
                )
                # é™åˆ¶ä¸ºå•é”®
                possible_bonds = [(1, std, dev) for order, std, dev in possible_bonds if order == 1]
            
            if possible_bonds:
                # å­˜å‚¨æ‰€æœ‰å¯èƒ½çš„é”®ç±»å‹ï¼ˆåŒ…æ‹¬0=æ— é”®ï¼‰
                possible_bonds_dict[(i, j)] = possible_bonds
    
    # ç¬¬äºŒæ­¥ï¼šå…¨å±€ä¼˜åŒ–ï¼Œç©·å°½æ‰€æœ‰å¯èƒ½çš„é”®ç»„åˆï¼Œæ‰¾åˆ°ç¨³å®šåŸå­æ•°æœ€å¤šçš„ç»„åˆ
    # ä½¿ç”¨é€’å½’å›æº¯æˆ–åŠ¨æ€è§„åˆ’æ¥æœç´¢æ‰€æœ‰å¯èƒ½çš„ç»„åˆ
    def calculate_stability_score(bond_matrix):
        """è®¡ç®—ç¨³å®šæ€§åˆ†æ•°ï¼ˆç¨³å®šåŸå­æ•°ï¼‰"""
        edge_types = bond_matrix.clone()
        edge_types[edge_types == 4] = 1.5
        edge_types[edge_types < 0] = 0
        valencies = torch.sum(edge_types, dim=-1).long()
        
        stable_count = 0
        for i, (atom_type, valency, charge) in enumerate(zip(atom_types, valencies, charges if charges is not None else torch.zeros(n, dtype=torch.long))):
            atom_type = atom_type.item()
            valency = valency.item()
            charge = charge.item()
            possible_bonds_list = allowed_bonds[atom_decoder[atom_type]]
            
            if type(possible_bonds_list) == int:
                is_stable = possible_bonds_list == valency
            elif type(possible_bonds_list) == dict:
                expected_bonds = possible_bonds_list.get(charge, possible_bonds_list.get(0))
                if type(expected_bonds) == int:
                    is_stable = expected_bonds == valency
                else:
                    is_stable = valency in expected_bonds
            else:
                is_stable = valency in possible_bonds_list
            
            if is_stable:
                stable_count += 1
        
        return stable_count
    
    # ä½¿ç”¨å›æº¯ç®—æ³•æœç´¢æ‰€æœ‰å¯èƒ½çš„é”®ç»„åˆï¼Œæ‰¾åˆ°ç¨³å®šåŸå­æ•°æœ€å¤šçš„ç»„åˆ
    # ä¸ºäº†æ•ˆç‡ï¼Œåªå¯¹åŸå­æ•°è¾ƒå°‘çš„åˆ†å­è¿›è¡Œç©·å°½æœç´¢ï¼Œå¯¹äºå¤§åˆ†å­ä½¿ç”¨æ”¹è¿›çš„è´ªå¿ƒç®—æ³•
    if n <= 12:  # å¯¹äºå°åˆ†å­ï¼Œä½¿ç”¨ç©·å°½æœç´¢ï¼ˆé™ä½é˜ˆå€¼ä»¥æé«˜æ•ˆç‡ï¼‰
        best_bond_matrix = None
        best_stable_count = -1
        
        # è·å–æ¯ä¸ªåŸå­çš„æœ€å¤§ä»·ï¼ˆç”¨äºå‰ªæï¼‰
        max_valencies = []
        for i in range(n):
            atom_str = atom_decoder[atom_types[i].item()]
            charge = charges[i].item() if charges is not None else 0
            possible_bonds_list = allowed_bonds[atom_str]
            if type(possible_bonds_list) == int:
                max_val = possible_bonds_list
            elif type(possible_bonds_list) == dict:
                expected_bonds = possible_bonds_list.get(charge, possible_bonds_list.get(0))
                if type(expected_bonds) == int:
                    max_val = expected_bonds
                else:
                    max_val = max(expected_bonds) if expected_bonds else 4
            else:
                max_val = max(possible_bonds_list) if possible_bonds_list else 4
            max_valencies.append(max_val)
        
        def backtrack(bond_matrix, pair_idx, pairs_list, used_valencies):
            nonlocal best_bond_matrix, best_stable_count
            
            if pair_idx == len(pairs_list):
                # æ‰€æœ‰åŸå­å¯¹éƒ½å·²å¤„ç†ï¼Œè®¡ç®—ç¨³å®šæ€§
                stable_count = calculate_stability_score(bond_matrix)
                if stable_count > best_stable_count:
                    best_stable_count = stable_count
                    best_bond_matrix = bond_matrix.clone()
                return
            
            i, j = pairs_list[pair_idx]
            possible_bonds = possible_bonds_dict.get((i, j), [])
            
            # å°è¯•æ— é”®
            bond_matrix[i, j] = 0
            bond_matrix[j, i] = 0
            backtrack(bond_matrix, pair_idx + 1, pairs_list, used_valencies)
            
            # å°è¯•æ‰€æœ‰å¯èƒ½çš„é”®ç±»å‹
            for order, _, _ in possible_bonds:
                # å‰ªæï¼šå¦‚æœæ·»åŠ è¿™ä¸ªé”®ä¼šå¯¼è‡´åŸå­ä»·è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡
                if used_valencies[i] + order > max_valencies[i] or used_valencies[j] + order > max_valencies[j]:
                    continue
                
                bond_matrix[i, j] = order
                bond_matrix[j, i] = order
                used_valencies[i] += order
                used_valencies[j] += order
                backtrack(bond_matrix, pair_idx + 1, pairs_list, used_valencies)
                # å›æº¯
                used_valencies[i] -= order
                used_valencies[j] -= order
        
        pairs_list = list(possible_bonds_dict.keys())
        temp_bond_matrix = torch.zeros((n, n), dtype=torch.int, device=device)
        used_valencies = [0] * n
        backtrack(temp_bond_matrix, 0, pairs_list, used_valencies)
        
        if best_bond_matrix is not None:
            E = best_bond_matrix
            A = (E > 0)
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨è´ªå¿ƒç®—æ³•ä½œä¸ºåå¤‡
            E = temp_bond_matrix
            A = (E > 0)
    else:
        # å¯¹äºå¤§åˆ†å­ï¼Œä½¿ç”¨è¿­ä»£æ”¹è¿›æˆ–è´ªå¿ƒç®—æ³•
        if use_iterative_improvement:
            # ä½¿ç”¨è¿­ä»£æ”¹è¿›ï¼šä»è´ªå¿ƒè§£å¼€å§‹ï¼Œé€æ­¥æ”¹è¿›
            # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨è´ªå¿ƒç®—æ³•è·å¾—åˆå§‹è§£
            candidate_bonds = []
            for (i, j), possible_bonds in possible_bonds_dict.items():
                if possible_bonds:
                    possible_bonds.sort(key=lambda x: x[2])  # æŒ‰ç›¸å¯¹åå·®æ’åº
                    best_order, _, _ = possible_bonds[0]
                    candidate_bonds.append((i, j, best_order))
            
            # è·å–æ¯ä¸ªåŸå­çš„æœ€å¤§ä»·
            max_valencies = []
            for i in range(n):
                atom_str = atom_decoder[atom_types[i].item()]
                charge = charges[i].item() if charges is not None else 0
                possible_bonds_list = allowed_bonds[atom_str]
                if type(possible_bonds_list) == int:
                    max_val = possible_bonds_list
                elif type(possible_bonds_list) == dict:
                    expected_bonds = possible_bonds_list.get(charge, possible_bonds_list.get(0))
                    if type(expected_bonds) == int:
                        max_val = expected_bonds
                    else:
                        max_val = max(expected_bonds) if expected_bonds else 4
                else:
                    max_val = max(possible_bonds_list) if possible_bonds_list else 4
                max_valencies.append(max_val)
            
            # æŒ‰ç›¸å¯¹åå·®æ’åºå€™é€‰é”®
            candidate_bonds_with_dev = []
            for i, j, order in candidate_bonds:
                possible_bonds = possible_bonds_dict[(i, j)]
                dev = next((d for o, _, d in possible_bonds if o == order), 1.0)
                candidate_bonds_with_dev.append((i, j, order, dev))
            candidate_bonds_with_dev.sort(key=lambda x: x[3])
            
            # ä¸ºæ¯ä¸ªåŸå­è·Ÿè¸ªå·²ä½¿ç”¨çš„ä»·
            used_valencies = [0] * n
            
            # åˆå§‹è§£ï¼šé€‰æ‹©é”®ï¼Œç¡®ä¿æ¯ä¸ªåŸå­çš„æ€»ä»·ä¸è¶…è¿‡æœ€å¤§ä»·
            for i, j, order, _ in candidate_bonds_with_dev:
                if used_valencies[i] + order <= max_valencies[i] and used_valencies[j] + order <= max_valencies[j]:
                    E[i, j] = order
                    E[j, i] = order
                    A[i, j] = 1
                    A[j, i] = 1
                    used_valencies[i] += order
                    used_valencies[j] += order
            
            # ç¬¬äºŒæ­¥ï¼šè¿­ä»£æ”¹è¿›
            # è®¡ç®—ç¨³å®šæ€§åˆ†æ•°çš„å‡½æ•°ï¼ˆè¿”å›ç¨³å®šåŸå­æ•°ï¼‰
            def calculate_stability_score(bond_matrix):
                edge_types = bond_matrix.clone()
                edge_types[edge_types == 4] = 1.5
                edge_types[edge_types < 0] = 0
                valencies = torch.sum(edge_types, dim=-1).long()
                
                stable_count = 0
                for i, (atom_type, valency, charge) in enumerate(zip(atom_types, valencies, charges if charges is not None else torch.zeros(n, dtype=torch.long))):
                    atom_type = atom_type.item()
                    valency = valency.item()
                    charge = charge.item()
                    possible_bonds_list = allowed_bonds[atom_decoder[atom_type]]
                    
                    if type(possible_bonds_list) == int:
                        is_stable = possible_bonds_list == valency
                    elif type(possible_bonds_list) == dict:
                        expected_bonds = possible_bonds_list.get(charge, possible_bonds_list.get(0))
                        if type(expected_bonds) == int:
                            is_stable = expected_bonds == valency
                        else:
                            is_stable = valency in expected_bonds
                    else:
                        is_stable = valency in possible_bonds_list
                    
                    if is_stable:
                        stable_count += 1
                
                return stable_count
            
            # è¿­ä»£æ”¹è¿›å¾ªç¯
            current_score = calculate_stability_score(E)
            initial_score = current_score
            
            for iteration in range(max_iterations):
                improved = False
                
                # å°è¯•æ”¹è¿›æ¯ä¸ªå¯èƒ½çš„é”®
                for (i, j), bonds in possible_bonds_dict.items():
                    if i >= j:  # åªå¤„ç†ä¸Šä¸‰è§’
                        continue
                    
                    if len(bonds) <= 1:
                        continue  # åªæœ‰ä¸€ä¸ªé€‰æ‹©ï¼Œæ— æ³•æ”¹è¿›
                    
                    # å°è¯•æ¯ä¸ªå¯èƒ½çš„é”®ç±»å‹
                    current_order = E[i, j].item()
                    best_order = current_order
                    best_score = current_score
                    
                    for order, _, _ in bonds:
                        if order == current_order:
                            continue
                        
                        # æ£€æŸ¥åŸå­ä»·çº¦æŸ
                        # è®¡ç®—å½“å‰åŸå­ä»·ï¼ˆè€ƒè™‘æ‰€æœ‰é”®ï¼ŒåŒ…æ‹¬å½“å‰é”®ï¼‰
                        edge_types = E.clone()
                        edge_types[edge_types == 4] = 1.5
                        edge_types[edge_types < 0] = 0
                        current_val_i = torch.sum(edge_types[i]).long().item()
                        current_val_j = torch.sum(edge_types[j]).long().item()
                        
                        # è®¡ç®—æ”¹å˜é”®ç±»å‹åçš„åŸå­ä»·
                        # æ³¨æ„ï¼šéœ€è¦å…ˆå‡å»å½“å‰é”®çš„è´¡çŒ®ï¼Œå†åŠ ä¸Šæ–°é”®çš„è´¡çŒ®
                        new_val_i = current_val_i - current_order + order
                        new_val_j = current_val_j - current_order + order
                        
                        # æ£€æŸ¥æ˜¯å¦è¶…å‡ºæœ€å¤§ä»·
                        if new_val_i > max_valencies[i] or new_val_j > max_valencies[j]:
                            continue
                        
                        # å°è¯•è¿™ä¸ªé”®ç±»å‹
                        E[i, j] = order
                        E[j, i] = order
                        new_score = calculate_stability_score(E)
                        
                        if new_score > best_score:
                            best_score = new_score
                            best_order = order
                            improved = True
                        else:
                            # æ¢å¤åŸæ¥çš„é”®ç±»å‹
                            E[i, j] = current_order
                            E[j, i] = current_order
                    
                    # åº”ç”¨æœ€ä½³é€‰æ‹©ï¼ˆå¦‚æœæ”¹è¿›äº†ï¼‰
                    if best_order != current_order:
                        E[i, j] = best_order
                        E[j, i] = best_order
                        A[i, j] = (best_order > 0)
                        A[j, i] = (best_order > 0)
                        current_score = best_score
                
                if not improved:
                    break  # æ²¡æœ‰æ”¹è¿›ï¼Œæ”¶æ•›
            
            # æœ€ç»ˆæ›´æ–°é‚»æ¥çŸ©é˜µ
            A = (E > 0)
            
            # æ›´æ–°é‚»æ¥çŸ©é˜µ
            A = (E > 0)
        else:
            # ä½¿ç”¨çº¯è´ªå¿ƒç®—æ³•ï¼ˆæŒ‰ç›¸å¯¹åå·®æ’åºï¼Œé€‰æ‹©æœ€æ¥è¿‘æ ‡å‡†é”®é•¿çš„é”®ï¼‰
            candidate_bonds = []
            for (i, j), possible_bonds in possible_bonds_dict.items():
                if possible_bonds:
                    possible_bonds.sort(key=lambda x: x[2])  # æŒ‰ç›¸å¯¹åå·®æ’åº
                    best_order, _, _ = possible_bonds[0]
                    candidate_bonds.append((i, j, best_order))
            
            # è·å–æ¯ä¸ªåŸå­çš„æœ€å¤§ä»·
            max_valencies = []
            for i in range(n):
                atom_str = atom_decoder[atom_types[i].item()]
                charge = charges[i].item() if charges is not None else 0
                possible_bonds_list = allowed_bonds[atom_str]
                if type(possible_bonds_list) == int:
                    max_val = possible_bonds_list
                elif type(possible_bonds_list) == dict:
                    expected_bonds = possible_bonds_list.get(charge, possible_bonds_list.get(0))
                    if type(expected_bonds) == int:
                        max_val = expected_bonds
                    else:
                        max_val = max(expected_bonds) if expected_bonds else 4
                else:
                    max_val = max(possible_bonds_list) if possible_bonds_list else 4
                max_valencies.append(max_val)
            
            # æŒ‰ç›¸å¯¹åå·®æ’åºå€™é€‰é”®
            candidate_bonds_with_dev = []
            for i, j, order in candidate_bonds:
                possible_bonds = possible_bonds_dict[(i, j)]
                dev = next((d for o, _, d in possible_bonds if o == order), 1.0)
                candidate_bonds_with_dev.append((i, j, order, dev))
            candidate_bonds_with_dev.sort(key=lambda x: x[3])
            
            # ä¸ºæ¯ä¸ªåŸå­è·Ÿè¸ªå·²ä½¿ç”¨çš„ä»·
            used_valencies = [0] * n
            
            # é€‰æ‹©é”®ï¼Œç¡®ä¿æ¯ä¸ªåŸå­çš„æ€»ä»·ä¸è¶…è¿‡æœ€å¤§ä»·
            for i, j, order, _ in candidate_bonds_with_dev:
                if used_valencies[i] + order <= max_valencies[i] and used_valencies[j] + order <= max_valencies[j]:
                    E[i, j] = order
                    E[j, i] = order
                    A[i, j] = 1
                    A[j, i] = 1
                    used_valencies[i] += order
                    used_valencies[j] += order
    
    return X, A, E


def check_connectivity(bond_types):
    """
    æ£€æŸ¥åˆ†å­çš„è¿é€šæ€§ï¼ˆä½¿ç”¨DFSï¼‰
    
    Args:
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
    
    Returns:
        tuple: (num_components, is_connected)
            - num_components: è¿é€šåˆ†é‡æ•°
            - is_connected: æ˜¯å¦è¿é€šï¼ˆè¿é€šåˆ†é‡æ•°==1ï¼‰
    """
    n_atoms = bond_types.shape[0]
    if n_atoms == 0:
        return 0, False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹
    has_edges = (bond_types > 0).any()
    if not has_edges:
        # æ²¡æœ‰è¾¹ï¼Œæ¯ä¸ªåŸå­éƒ½æ˜¯ç‹¬ç«‹çš„è¿é€šåˆ†é‡
        # å¦‚æœåªæœ‰ä¸€ä¸ªåŸå­ï¼Œå®ƒè¢«è®¤ä¸ºæ˜¯è¿é€šçš„ï¼ˆå•ä¸ªåŸå­æ˜¯ä¸€ä¸ªå®Œæ•´çš„åˆ†å­ï¼‰
        is_connected = (n_atoms == 1)
        return n_atoms, is_connected
    
    # ä½¿ç”¨DFSè®¡ç®—è¿é€šåˆ†é‡
    visited = torch.zeros(n_atoms, dtype=torch.bool)
    num_components = 0
    
    def dfs(node):
        """æ·±åº¦ä¼˜å…ˆæœç´¢"""
        visited[node] = True
        neighbors = torch.nonzero(bond_types[node] > 0, as_tuple=False).squeeze(-1)
        for neighbor in neighbors:
            neighbor_idx = neighbor.item()
            if neighbor_idx != node and not visited[neighbor_idx]:
                dfs(neighbor_idx)
    
    # éå†æ‰€æœ‰æœªè®¿é—®çš„èŠ‚ç‚¹
    for i in range(n_atoms):
        if not visited[i]:
            dfs(i)
            num_components += 1
    
    is_connected = (num_components == 1)
    return num_components, is_connected


def check_connectivity_with_labels(bond_types):
    """
    æ£€æŸ¥åˆ†å­çš„è¿é€šæ€§å¹¶è¿”å›æ¯ä¸ªåŸå­æ‰€å±çš„è¿é€šåˆ†é‡ID
    
    Args:
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        
    Returns:
        tuple: (num_components, component_ids)
            - num_components: è¿é€šåˆ†é‡æ•°
            - component_ids: æ¯ä¸ªåŸå­æ‰€å±çš„è¿é€šåˆ†é‡ID [N]
    """
    n_atoms = bond_types.shape[0]
    if n_atoms == 0:
        return 0, torch.zeros(0, dtype=torch.long)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹
    has_edges = (bond_types > 0).any()
    if not has_edges:
        # æ²¡æœ‰è¾¹ï¼Œæ¯ä¸ªåŸå­éƒ½æ˜¯ç‹¬ç«‹çš„è¿é€šåˆ†é‡
        component_ids = torch.arange(n_atoms, dtype=torch.long)
        return n_atoms, component_ids
    
    # ä½¿ç”¨DFSè®¡ç®—è¿é€šåˆ†é‡å¹¶æ ‡è®°
    visited = torch.zeros(n_atoms, dtype=torch.bool)
    component_ids = torch.zeros(n_atoms, dtype=torch.long)
    current_component = 0
    
    def dfs_label(node, comp_id):
        """æ·±åº¦ä¼˜å…ˆæœç´¢å¹¶æ ‡è®°è¿é€šåˆ†é‡"""
        visited[node] = True
        component_ids[node] = comp_id
        neighbors = torch.nonzero(bond_types[node] > 0, as_tuple=False).squeeze(-1)
        for neighbor in neighbors:
            neighbor_idx = neighbor.item()
            if neighbor_idx != node and not visited[neighbor_idx]:
                dfs_label(neighbor_idx, comp_id)
    
    # éå†æ‰€æœ‰æœªè®¿é—®çš„èŠ‚ç‚¹
    for i in range(n_atoms):
        if not visited[i]:
            dfs_label(i, current_component)
            current_component += 1
    
    num_components = current_component
    return num_components, component_ids


def compute_missing_bond_deviations_strict(positions, atom_types, bond_types, atom_decoder, dataset_info, 
                                            strict_margin1, strict_margin2, strict_margin3):
    """
    è®¡ç®—åº”è¯¥å½¢æˆé”®ä½†æœªå½¢æˆé”®çš„åŸå­å¯¹çš„è·ç¦»åå·®ï¼ˆä½¿ç”¨ä¸¥æ ¼æ ‡å‡†ï¼Œè€ƒè™‘æ‰€æœ‰é”®ç±»å‹ï¼‰
    
    ä¼˜åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨ get_expected_bond_order() æ¥åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹ï¼Œä¸ä»…æ£€æµ‹å•é”®ç¼ºå¤±ï¼Œ
    è¿˜æ£€æµ‹åŒé”®/ä¸‰é”®ç¼ºå¤±ï¼Œä»¥åŠé”®ç±»å‹ä¸åŒ¹é…çš„æƒ…å†µã€‚
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        strict_margin1: ä¸¥æ ¼margin1å€¼ï¼ˆpmå•ä½ï¼‰
        strict_margin2: ä¸¥æ ¼margin2å€¼ï¼ˆpmå•ä½ï¼‰
        strict_margin3: ä¸¥æ ¼margin3å€¼ï¼ˆpmå•ä½ï¼‰
    
    Returns:
        missing_bonds: List of dicts with keys: pair, actual_dist, standard_dist, deviation_pct, 
                      expected_order, actual_order, is_type_mismatch
    """
    n = positions.shape[0]
    dists = torch.cdist(positions, positions, p=2)
    missing_bonds = []
    
    # è®¡ç®—è¿é€šåˆ†é‡ï¼Œç”¨äºæ£€æµ‹è·¨åˆ†é‡çš„ç¼ºå¤±é”®
    _, component_ids = check_connectivity_with_labels(bond_types)
    
    for i in range(n):
        for j in range(i):
            atom1_str = atom_decoder[atom_types[i].item()]
            atom2_str = atom_decoder[atom_types[j].item()]
            
            # æ£€æŸ¥æ ‡å‡†é”®é•¿ï¼ˆéœ€è¦æŒ‰å­—æ¯é¡ºåºæ’åºï¼‰
            pair = sorted([atom1_str, atom2_str])
            atom1_key = pair[0]
            atom2_key = pair[1]
            
            # ä½¿ç”¨ä¼˜åŒ–åçš„å‡½æ•°åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹
            actual_dist = dists[i, j].item()
            expected_order, standard_dist, threshold = get_expected_bond_order(
                atom1_key, atom2_key, actual_dist,
                margin1_val=strict_margin1,
                margin2_val=strict_margin2,
                margin3_val=strict_margin3
            )
            
            if expected_order > 0:  # åº”è¯¥å½¢æˆæŸç§ç±»å‹çš„é”®
                actual_order = bond_types[i, j].item()
                is_cross_component = (component_ids[i] != component_ids[j])
                has_bond = (actual_order > 0)
                deviation_pct = (actual_dist - standard_dist) / standard_dist * 100
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å½¢æˆé”®ä½†æœªå½¢æˆï¼Œæˆ–é”®ç±»å‹ä¸åŒ¹é…
                is_missing = (not has_bond) or is_cross_component
                is_type_mismatch = (has_bond and actual_order != expected_order)
                
                # æƒ…å†µ1ï¼šæ²¡æœ‰é”®æˆ–è·¨åˆ†é‡
                if is_missing:
                    missing_bonds.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'atom1': atom1_str,
                        'atom2': atom2_str,
                        'expected_order': expected_order,
                        'actual_order': actual_order,
                        'is_cross_component': is_cross_component,
                        'is_type_mismatch': False,
                        'has_bond': has_bond
                    })
                # æƒ…å†µ2ï¼šé”®ç±»å‹ä¸åŒ¹é…ï¼ˆä¾‹å¦‚åº”è¯¥å½¢æˆåŒé”®ä½†åªå½¢æˆäº†å•é”®ï¼‰
                elif is_type_mismatch:
                    missing_bonds.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'atom1': atom1_str,
                        'atom2': atom2_str,
                        'expected_order': expected_order,
                        'actual_order': actual_order,
                        'is_cross_component': False,
                        'is_type_mismatch': True,
                        'has_bond': True
                    })
                # æƒ…å†µ3ï¼šæœ‰é”®ä½†è·ç¦»åç¦»æ ‡å‡†å€¼è¶…è¿‡5%ï¼ˆç»“æ„ä¸ç†æƒ³ï¼‰
                elif has_bond and abs(deviation_pct) > 5.0:
                    # ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼æ¥æ£€æµ‹åç¦»æ ‡å‡†å€¼çš„é”®
                    relaxed_threshold = threshold * 1.2  # æ”¾å®½20%
                    if actual_dist < relaxed_threshold:
                        missing_bonds.append({
                            'pair': (i, j),
                            'actual_dist': actual_dist,
                            'standard_dist': standard_dist,
                            'deviation_pct': deviation_pct,
                            'atom1': atom1_str,
                            'atom2': atom2_str,
                            'expected_order': expected_order,
                            'actual_order': actual_order,
                            'is_cross_component': False,
                            'is_type_mismatch': False,
                            'has_bond': True
                        })
    
    return missing_bonds


def compute_bond_type_mismatches(positions, atom_types, bond_types, atom_decoder, dataset_info,
                                  margin1_val=None, margin2_val=None, margin3_val=None):
    """
    æ£€æµ‹é”®ç±»å‹ä¸åŒ¹é…çš„æƒ…å†µï¼ˆå®é™…é”®ç±»å‹ä¸æœŸæœ›é”®ç±»å‹ä¸ä¸€è‡´ï¼‰
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        mismatches: List of dicts with keys: pair, actual_dist, expected_order, actual_order, deviation_pct
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    n = positions.shape[0]
    dists = torch.cdist(positions, positions, p=2)
    mismatches = []
    
    for i in range(n):
        for j in range(i):
            if bond_types[i, j] > 0:  # å½“å‰åˆ¤æ–­ä¸ºæœ‰é”®
                atom1_str = atom_decoder[atom_types[i].item()]
                atom2_str = atom_decoder[atom_types[j].item()]
                pair = sorted([atom1_str, atom2_str])
                atom1_key = pair[0]
                atom2_key = pair[1]
                
                # åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹
                actual_dist = dists[i, j].item()
                expected_order, standard_dist, _ = get_expected_bond_order(
                    atom1_key, atom2_key, actual_dist,
                    margin1_val=margin1_val,
                    margin2_val=margin2_val,
                    margin3_val=margin3_val
                )
                
                actual_order = bond_types[i, j].item()
                
                # å¦‚æœæœŸæœ›é”®ç±»å‹ä¸å®é™…é”®ç±»å‹ä¸åŒ¹é…
                if expected_order > 0 and actual_order != expected_order:
                    deviation_pct = (actual_dist - standard_dist) / standard_dist * 100
                    mismatches.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'atom1': atom1_str,
                        'atom2': atom2_str,
                        'expected_order': expected_order,
                        'actual_order': actual_order
                    })
    
    return mismatches


def compute_excessive_bond_deviations(positions, atom_types, bond_types, atom_decoder, dataset_info, 
                                       margin1_val=None, margin2_val=None, margin3_val=None):
    """
    è®¡ç®—ä¸åº”è¯¥å½¢æˆé”®ä½†å½¢æˆé”®çš„åŸå­å¯¹ï¼ˆè·ç¦»è¿‡è¿œä½†ä»è¢«åˆ¤æ–­ä¸ºæœ‰é”®ï¼‰
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        excessive_bonds: List of dicts with keys: pair, actual_dist, standard_dist, deviation_pct, bond_order
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    n = positions.shape[0]
    dists = torch.cdist(positions, positions, p=2)
    excessive_bonds = []
    
    for i in range(n):
        for j in range(i):
            if bond_types[i, j] > 0:  # å½“å‰åˆ¤æ–­ä¸ºæœ‰é”®
                atom1_str = atom_decoder[atom_types[i].item()]
                atom2_str = atom_decoder[atom_types[j].item()]
                pair = sorted([atom1_str, atom2_str])
                atom1_key = pair[0]
                atom2_key = pair[1]
                
                # åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹
                actual_dist = dists[i, j].item()
                expected_order, standard_dist, threshold = get_expected_bond_order(
                    atom1_key, atom2_key, actual_dist,
                    margin1_val=margin1_val,
                    margin2_val=margin2_val,
                    margin3_val=margin3_val
                )
                
                # å¦‚æœè·ç¦»è¶…è¿‡åº”è¯¥å½¢æˆé”®çš„èŒƒå›´
                if expected_order == 0 or actual_dist > threshold:
                    # ä½¿ç”¨å•é”®æ ‡å‡†ä½œä¸ºå‚è€ƒ
                    if atom1_key in bonds1 and atom2_key in bonds1[atom1_key]:
                        ref_standard_dist = bonds1[atom1_key][atom2_key] / 100.0
                        deviation_pct = (actual_dist - ref_standard_dist) / ref_standard_dist * 100
                        excessive_bonds.append({
                            'pair': (i, j),
                            'actual_dist': actual_dist,
                            'standard_dist': ref_standard_dist,
                            'deviation_pct': deviation_pct,
                            'atom1': atom1_str,
                            'atom2': atom2_str,
                            'bond_order': bond_types[i, j].item()
                        })
    
    return excessive_bonds


def _analyze_bonds_with_standard(positions, atom_types, atom_decoder, dataset_info,
                                  margin1_val, margin2_val, margin3_val):
    """
    ä½¿ç”¨æŒ‡å®šæ ‡å‡†åˆ†æå•ä¸ªåˆ†å­çš„é”®å’Œè¿é€šæ€§
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        atom_decoder: åŸå­è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰
    
    Returns:
        tuple: (num_components, is_connected, missing_bond_deviations)
    """
    # æ„å»ºé”®çŸ©é˜µ
    _, _, bond_types = build_xae_molecule(
        positions=positions,
        atom_types=atom_types,
        dataset_info=dataset_info,
        atom_decoder=atom_decoder,
        margin1_val=margin1_val,
        margin2_val=margin2_val,
        margin3_val=margin3_val
    )
    
    # è®¡ç®—è¿é€šæ€§
    num_components, is_connected = check_connectivity(bond_types)
    
    # è®¡ç®—ç¼ºå¤±é”®åå·®
    missing_bonds = compute_missing_bond_deviations_strict(
        positions, atom_types, bond_types, atom_decoder, dataset_info,
        strict_margin1=margin1_val,
        strict_margin2=margin2_val,
        strict_margin3=margin3_val
    )
    
    missing_deviations = [bond['deviation_pct'] for bond in missing_bonds] if missing_bonds else []
    
    return num_components, is_connected, missing_deviations


def _print_standard_results(standard_name, margin1, margin2, margin3,
                           num_components, is_connected, missing_deviations):
    """
    æ‰“å°å•ä¸ªæ ‡å‡†çš„åˆ†æç»“æœ
    
    Args:
        standard_name: æ ‡å‡†åç§°ï¼ˆå¦‚ 'ä¸¥æ ¼æ ‡å‡†'ï¼‰
        margin1/2/3: marginå€¼
        num_components: è¿é€šåˆ†é‡æ•°æ•°ç»„
        is_connected: è¿é€šæ€§å¸ƒå°”æ•°ç»„
        missing_deviations: ç¼ºå¤±é”®åå·®åˆ—è¡¨
    """
    print(f"\nğŸ”— {standard_name} (margin1={margin1}pm, margin2={margin2}pm, margin3={margin3}pm):")
    print(f"  è¿é€šæ€§:")
    print(f"    è¿é€šåˆ†å­æ•°: {is_connected.sum()}")
    print(f"    éè¿é€šåˆ†å­æ•°: {(~is_connected).sum()}")
    print(f"    è¿é€šåˆ†å­æ¯”ä¾‹: {is_connected.sum() / len(is_connected) * 100:.2f}%")
    print(f"    å¹³å‡è¿é€šåˆ†é‡æ•°: {num_components.mean():.2f}")
    print(f"    æœ€å¤§è¿é€šåˆ†é‡æ•°: {num_components.max()}")
    if len(missing_deviations) > 0:
        print(f"  ç¼ºå¤±é”®åå·®:")
        print(f"    æ€»ç¼ºå¤±é”®æ•°: {len(missing_deviations)}")
        print(f"    å¹³å‡åå·®: {np.mean(missing_deviations):.4f}%")
        print(f"    ä¸­ä½æ•°åå·®: {np.median(missing_deviations):.4f}%")
    else:
        print(f"  ç¼ºå¤±é”®åå·®: æ— ç¼ºå¤±é”®")


def analyze_bonds(molecule_dir,
                 strict_margin1, strict_margin2, strict_margin3,
                 medium_margin1, medium_margin2, medium_margin3,
                 relaxed_margin1, relaxed_margin2, relaxed_margin3,
                 output_dir=None,
                 use_sdf_bonds=True):
    """
    åˆ†æåˆ†å­çš„é”®å’Œè¿é€šæ€§
    
    Args:
        molecule_dir: åŒ…å« .npz æ–‡ä»¶çš„ç›®å½•
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
        strict_margin1/2/3: ä¸¥æ ¼æ ‡å‡†çš„marginå€¼ï¼ˆpmå•ä½ï¼‰
        medium_margin1/2/3: ä¸­ç­‰æ ‡å‡†çš„marginå€¼ï¼ˆpmå•ä½ï¼‰
        relaxed_margin1/2/3: å®½æ¾æ ‡å‡†çš„marginå€¼ï¼ˆpmå•ä½ï¼‰
        use_sdf_bonds: æ˜¯å¦ä½¿ç”¨ SDF æ–‡ä»¶ä¸­çš„é”®ä¿¡æ¯ï¼ˆé»˜è®¤ Trueï¼‰
                      - True: ä½¿ç”¨ SDF æ–‡ä»¶ä¸­çš„é”®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œåªåˆ†æä¸€æ¬¡
                      - False: ä½¿ç”¨ä¸‰ç§ä¸åŒçš„ margin å€¼é‡æ–°æ„å»ºé”®å¹¶åˆ†æ
    
    Returns:
        dict: åŒ…å«é”®å’Œè¿é€šæ€§åˆ†æç»“æœçš„å­—å…¸
    """
    from funcmol.evaluation.quality_evaluation import _extract_bonds_from_sdf
    import re
    
    molecule_dir = Path(molecule_dir)
    npz_files = sorted(molecule_dir.glob("generated_*.npz"))
    
    if use_sdf_bonds:
        print(f"æ‰¾åˆ° {len(npz_files)} ä¸ª .npz åˆ†å­æ–‡ä»¶ï¼ˆå°†ä¼˜å…ˆä½¿ç”¨ SDF æ–‡ä»¶ä¸­çš„é”®ä¿¡æ¯ï¼‰")
    else:
        print(f"æ‰¾åˆ° {len(npz_files)} ä¸ª .npz åˆ†å­æ–‡ä»¶ï¼ˆä½¿ç”¨ä¸‰ç§æ ‡å‡†åˆ†æï¼‰")
    
    atom_decoder = atom_decoder_dict['qm9_with_h']
    dataset_info = {'name': 'qm9'}
    
    # å­˜å‚¨é”®é•¿ç»Ÿè®¡æ•°æ®ï¼ˆä½¿ç”¨relaxed marginæ„å»ºçš„é”®çŸ©é˜µï¼Œç”¨äºé”®é•¿ç»Ÿè®¡ï¼‰
    bond_lengths = []
    
    # ä¸‰ç§æ ‡å‡†çš„ç¼ºå¤±é”®åå·®ç»Ÿè®¡
    all_missing_bond_deviations_strict = []
    all_missing_bond_deviations_medium = []
    all_missing_bond_deviations_relaxed = []
    
    # ä¸‰ç§æ ‡å‡†çš„è¿é€šæ€§ç»Ÿè®¡
    num_components_strict = []
    is_connected_strict = []
    num_components_medium = []
    is_connected_medium = []
    num_components_relaxed = []
    is_connected_relaxed = []
    
    if use_sdf_bonds:
        print("åˆ†æåˆ†å­é”®å’Œè¿é€šæ€§ï¼ˆä½¿ç”¨ SDF æ–‡ä»¶ä¸­çš„é”®ï¼‰...")
    else:
        print("åˆ†æåˆ†å­é”®å’Œè¿é€šæ€§ï¼ˆä½¿ç”¨ä¸‰ç§æ ‡å‡†ï¼‰...")
    
    sdf_count = 0
    fallback_count = 0
    
    for npz_file in tqdm(npz_files, desc="å¤„ç†åˆ†å­"):
        try:
            # åŠ è½½åˆ†å­
            data = np.load(npz_file)
            coords = data['coords']  # (N, 3)
            types = data['types']    # (N,)
            
            # è½¬æ¢ä¸ºtorchå¼ é‡
            positions = torch.tensor(coords, dtype=torch.float32)
            atom_types = torch.tensor(types, dtype=torch.long)
            
            # è¿‡æ»¤æ‰å¡«å……çš„åŸå­
            valid_mask = atom_types != -1
            if not valid_mask.any():
                continue
            
            positions = positions[valid_mask]
            atom_types = atom_types[valid_mask]
            
            distances = torch.cdist(positions, positions, p=2)
            
            if use_sdf_bonds:
                # ä¼˜å…ˆå°è¯•ä» SDF æ–‡ä»¶è¯»å–é”®ä¿¡æ¯
                bond_types_sdf = None
                npz_stem = npz_file.stem
                match = re.search(r'generated_(\d+)_tanh', npz_stem)
                if match:
                    index = match.group(1)
                    sdf_file = molecule_dir / f"genmol_{index}.sdf"
                    
                    if sdf_file.exists():
                        try:
                            with open(sdf_file, 'r', encoding='utf-8') as f:
                                sdf_string = f.read()
                            bond_types_sdf = _extract_bonds_from_sdf(sdf_string, len(atom_types))
                            sdf_count += 1
                        except Exception:
                            bond_types_sdf = None
                
                # å¦‚æœæ‰¾åˆ° SDF é”®ï¼Œä½¿ç”¨å®ƒè¿›è¡Œåˆ†æ
                if bond_types_sdf is not None:
                    # è®¡ç®—è¿é€šæ€§
                    num_components, is_connected = check_connectivity(bond_types_sdf)
                    num_components_strict.append(num_components)
                    is_connected_strict.append(is_connected)
                    # ä½¿ç”¨ relaxed margin è®¡ç®—ç¼ºå¤±é”®åå·®ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
                    missing_bonds = compute_missing_bond_deviations_strict(
                        positions, atom_types, bond_types_sdf, atom_decoder, dataset_info,
                        strict_margin1=relaxed_margin1,
                        strict_margin2=relaxed_margin2,
                        strict_margin3=relaxed_margin3
                    )
                    missing_deviations = [bond['deviation_pct'] for bond in missing_bonds] if missing_bonds else []
                    all_missing_bond_deviations_strict.extend(missing_deviations)
                    # ä¸‰ç§æ ‡å‡†éƒ½ä½¿ç”¨ç›¸åŒçš„ç»“æœ
                    num_components_medium.append(num_components)
                    is_connected_medium.append(is_connected)
                    all_missing_bond_deviations_medium.extend(missing_deviations)
                    num_components_relaxed.append(num_components)
                    is_connected_relaxed.append(is_connected)
                    all_missing_bond_deviations_relaxed.extend(missing_deviations)
                    
                    # è®¡ç®—é”®é•¿
                    triu_mask = torch.triu(torch.ones_like(bond_types_sdf, dtype=torch.bool), diagonal=1)
                    bond_mask = (bond_types_sdf > 0) & triu_mask
                    if bond_mask.any():
                        bond_distances = distances[bond_mask]
                        bond_lengths.extend(bond_distances.cpu().numpy())
                else:
                    # å›é€€åˆ°è·ç¦»æ–¹æ³•
                    fallback_count += 1
                    num_comp_strict, is_conn_strict, missing_devs_strict = _analyze_bonds_with_standard(
                        positions, atom_types, atom_decoder, dataset_info,
                        strict_margin1, strict_margin2, strict_margin3
                    )
                    num_components_strict.append(num_comp_strict)
                    is_connected_strict.append(is_conn_strict)
                    all_missing_bond_deviations_strict.extend(missing_devs_strict)
                    num_components_medium.append(num_comp_strict)
                    is_connected_medium.append(is_conn_strict)
                    all_missing_bond_deviations_medium.extend(missing_devs_strict)
                    num_components_relaxed.append(num_comp_strict)
                    is_connected_relaxed.append(is_conn_strict)
                    all_missing_bond_deviations_relaxed.extend(missing_devs_strict)
                    
                    _, _, bond_types_fallback = build_xae_molecule(
                        positions=positions,
                        atom_types=atom_types,
                        dataset_info=dataset_info,
                        atom_decoder=atom_decoder,
                        margin1_val=relaxed_margin1,
                        margin2_val=relaxed_margin2,
                        margin3_val=relaxed_margin3
                    )
                    triu_mask = torch.triu(torch.ones_like(bond_types_fallback, dtype=torch.bool), diagonal=1)
                    bond_mask = (bond_types_fallback > 0) & triu_mask
                    if bond_mask.any():
                        bond_distances = distances[bond_mask]
                        bond_lengths.extend(bond_distances.cpu().numpy())
            else:
                # ä½¿ç”¨ä¸‰ç§æ ‡å‡†åˆ†æ
                # ä¸¥æ ¼æ ‡å‡†ï¼šåˆ†æé”®å’Œè¿é€šæ€§
                num_comp_strict, is_conn_strict, missing_devs_strict = _analyze_bonds_with_standard(
                    positions, atom_types, atom_decoder, dataset_info,
                    strict_margin1, strict_margin2, strict_margin3
                )
                num_components_strict.append(num_comp_strict)
                is_connected_strict.append(is_conn_strict)
                all_missing_bond_deviations_strict.extend(missing_devs_strict)
                
                # ä¸­ç­‰æ ‡å‡†ï¼šåˆ†æé”®å’Œè¿é€šæ€§
                num_comp_medium, is_conn_medium, missing_devs_medium = _analyze_bonds_with_standard(
                    positions, atom_types, atom_decoder, dataset_info,
                    medium_margin1, medium_margin2, medium_margin3
                )
                num_components_medium.append(num_comp_medium)
                is_connected_medium.append(is_conn_medium)
                all_missing_bond_deviations_medium.extend(missing_devs_medium)
                
                # å®½æ¾æ ‡å‡†ï¼šåˆ†æé”®å’Œè¿é€šæ€§
                num_comp_relaxed, is_conn_relaxed, missing_devs_relaxed = _analyze_bonds_with_standard(
                    positions, atom_types, atom_decoder, dataset_info,
                    relaxed_margin1, relaxed_margin2, relaxed_margin3
                )
                num_components_relaxed.append(num_comp_relaxed)
                is_connected_relaxed.append(is_conn_relaxed)
                all_missing_bond_deviations_relaxed.extend(missing_devs_relaxed)
                
                # è®¡ç®—é”®é•¿ï¼ˆä½¿ç”¨relaxedæ ‡å‡†æ„å»ºçš„é”®çŸ©é˜µï¼Œç”¨äºé”®é•¿ç»Ÿè®¡ï¼‰
                _, _, bond_types_relaxed = build_xae_molecule(
                    positions=positions,
                    atom_types=atom_types,
                    dataset_info=dataset_info,
                    atom_decoder=atom_decoder,
                    margin1_val=relaxed_margin1,
                    margin2_val=relaxed_margin2,
                    margin3_val=relaxed_margin3
                )
                triu_mask = torch.triu(torch.ones_like(bond_types_relaxed, dtype=torch.bool), diagonal=1)
                bond_mask = (bond_types_relaxed > 0) & triu_mask
                
                if bond_mask.any():
                    bond_distances = distances[bond_mask]
                    bond_lengths.extend(bond_distances.cpu().numpy())
            
        except Exception as e:
            print(f"\nå¤„ç†æ–‡ä»¶ {npz_file} æ—¶å‡ºé”™: {e}")
            continue
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    bond_lengths = np.array(bond_lengths) if bond_lengths else np.array([])
    
    num_components_strict = np.array(num_components_strict)
    is_connected_strict = np.array(is_connected_strict)
    num_components_medium = np.array(num_components_medium)
    is_connected_medium = np.array(is_connected_medium)
    num_components_relaxed = np.array(num_components_relaxed)
    is_connected_relaxed = np.array(is_connected_relaxed)
    
    # ä¸‰ç§æ ‡å‡†çš„ç¼ºå¤±é”®åå·®æ•°ç»„
    all_missing_bond_deviations_strict = np.array(all_missing_bond_deviations_strict) if all_missing_bond_deviations_strict else np.array([])
    all_missing_bond_deviations_medium = np.array(all_missing_bond_deviations_medium) if all_missing_bond_deviations_medium else np.array([])
    all_missing_bond_deviations_relaxed = np.array(all_missing_bond_deviations_relaxed) if all_missing_bond_deviations_relaxed else np.array([])
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print("\n" + "="*60)
    print("é”®å’Œè¿é€šæ€§åˆ†æç»“æœ")
    print("="*60)
    
    if use_sdf_bonds:
        print(f"âœ… ä½¿ç”¨ SDF æ–‡ä»¶ä¸­çš„é”®ä¿¡æ¯ï¼ˆæ¥è‡ª OpenBabelï¼‰")
        print(f"  - ä» SDF æ–‡ä»¶è¯»å–é”®ä¿¡æ¯: {sdf_count} ä¸ª")
        print(f"  - ä½¿ç”¨è·ç¦»æ–¹æ³•æ¨æ–­é”®: {fallback_count} ä¸ª")
        # ä½¿ç”¨ SDF æ—¶ï¼Œä¸‰ç§æ ‡å‡†ç»“æœç›¸åŒï¼Œåªæ‰“å°ä¸€æ¬¡
        _print_standard_results("SDF é”®ï¼ˆæ¥è‡ª OpenBabelï¼‰", relaxed_margin1, relaxed_margin2, relaxed_margin3,
                               num_components_strict, is_connected_strict, all_missing_bond_deviations_strict)
    else:
        # æ‰“å°ä¸‰ç§æ ‡å‡†çš„ç»“æœ
        _print_standard_results("ä¸¥æ ¼æ ‡å‡†", strict_margin1, strict_margin2, strict_margin3,
                               num_components_strict, is_connected_strict, all_missing_bond_deviations_strict)
        _print_standard_results("ä¸­ç­‰æ ‡å‡†", medium_margin1, medium_margin2, medium_margin3,
                               num_components_medium, is_connected_medium, all_missing_bond_deviations_medium)
        _print_standard_results("å®½æ¾æ ‡å‡†", relaxed_margin1, relaxed_margin2, relaxed_margin3,
                               num_components_relaxed, is_connected_relaxed, all_missing_bond_deviations_relaxed)
    
    # é”®é•¿ç»Ÿè®¡ï¼ˆä½¿ç”¨relaxedæ ‡å‡†ï¼‰
    print(f"\nğŸ”— é”®é•¿ç»Ÿè®¡ï¼ˆä½¿ç”¨relaxedæ ‡å‡†ï¼‰:")
    if len(bond_lengths) > 0:
        print(f"  æ€»é”®æ•°: {len(bond_lengths)}")
        print(f"  å¹³å‡é”®é•¿: {bond_lengths.mean():.4f} Ã…")
        print(f"  ä¸­ä½æ•°é”®é•¿: {np.median(bond_lengths):.4f} Ã…")
        print(f"  é”®é•¿èŒƒå›´: {bond_lengths.min():.4f} - {bond_lengths.max():.4f} Ã…")
    else:
        print("  æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•é”®ï¼")
    
    print(f"\nè¯´æ˜: ç¼ºå¤±é”®æ˜¯æŒ‡æ ¹æ®åŸå­ç±»å‹å’Œè·ç¦»åˆ¤æ–­åº”è¯¥å½¢æˆé”®ï¼Œä½†å®é™…é”®çŸ©é˜µä¸­æœªè¯†åˆ«å‡ºçš„åŸå­å¯¹")
    
    return {
        'bond_lengths': bond_lengths,
        'strict': {
            'num_components': num_components_strict,
            'is_connected': is_connected_strict,
            'missing_bond_deviations': all_missing_bond_deviations_strict
        },
        'medium': {
            'num_components': num_components_medium,
            'is_connected': is_connected_medium,
            'missing_bond_deviations': all_missing_bond_deviations_medium
        },
        'relaxed': {
            'num_components': num_components_relaxed,
            'is_connected': is_connected_relaxed,
            'missing_bond_deviations': all_missing_bond_deviations_relaxed
        }
    }
