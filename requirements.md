我现在想设计的一个新的架构，与 vecmol 比较类似，但是与 vecmol 里的神经梯度网络不完全相同。
在 vecmol 中，神经网络 f 将潜在码 z (代表某个特定分子) 和空间点 x 映射到原子密度值；但是我现在想设计的网络，输出结果不是标量形式的原子密度，而是三维的矢量场，包含了x,y,z三个方向上梯度大小

要使用一个3D GNN结构！！而不仅仅是把decoder的输出维度变成4维，[batch, n_points, n_atom_types * 3]
- 这里的modulation code z的维度为\(L*L*L*f\)
    实际意义是，在三维空间中有\(L*L*L\)个锚点，每个锚点的信息维度为\(f\)
- 当随机采样一个三维空间的node x时，锚点与采样点共同组成一个图结构，图的顶点\(G=(z,x)\)，边\(E\)使用KNN算法判断。在这里我打算先尝试最基本的EGNN结构
    （这里之所以要用图结构，是因为图才能比较好地保留旋转平移等变等性质，比在vecmol中使用MFN，然后“强行”使用数据增强来学习旋转能力要自然得多，所以效果预计也会好一些）
- 通过这个GNN，可以生成空间中采样点x对应的三维梯度值（在vecmol里，输入x，通过MFN，得到的输出是f(x,z)，也就是近似的密度场值，是一个标量；但是在这里，通过EGNN之后，我期望网络输出的是矢量，矢量的3个维度表征了在3个方向上的梯度大小）


### 我的项目分为三个阶段：

**1、小分子 -> 梯度场表示 & 重建验证** (已完成)：这一步建立了分子和你的目标矢量场之间的映射，并验证了这个表示的有效性和可逆性（能够从场中恢复分子）。这包含了：

- 定义了你的目标矢量场 \(V_{true}(x)\) 是什么（例如，某个化学势场的梯度，或其他有意义的矢量场）。
- 建立了从标准分子表示（原子坐标+类型）到这个 \(V_{true}(x)\) 的转换方法。
- 建立了从 \(V_{true}(x)\) **恢复（解码）**回原子坐标和类型的方法。你的成功意味着这个解码方法是鲁棒和准确的。

**2、学习用神经场表示分子梯度场 & 鲁棒重建**: 在这个阶段，你将利用神经场（具体是你的 EGNN 架构）来**学习参数化**这个梯度场。这类似于 VecMol 用 MFN 参数化密度场。

- 核心是训练你的 EGNN 网络 \(g(z_{grid}, x)\)，使其输出能够逼近真实分子的目标矢量场 \(V_{true}(x)\)。
- 需要学习你的结构化潜在码 \(z_{grid}\) 以及 EGNN 的参数。
- “鲁棒重建”意味着从 EGNN 输出的近似矢量场 \(V_{approx}(x) = g(z_{grid}, x)\) 中解码出来的分子，应该与原始分子非常相似。

在EGNN里做信息传输：
1、一个分子的梯度场可以看成一个空间中的一个矢量方向，也就是空间中每个位置x的矢量e(x)。而neural field就是用神经网络f(x)来学这个函数，所以对一个分子的神经场函数e(x)，然后从这个矢量还原出具体的分子位置。可以训练min RMSD[分子原坐标 - 还原出的分子中原子位置]。但是直接这样做得每一个数据点需要单独训练一个网络f(x)。
2、于是，对于每一个数据点，我们想学一个latent 表示z，作为这个neural field神经网络的condition，使得f(x;z)来可以表示对应z这个数据点的梯度场。在这个项目里，我希望latent 表示z不是一个向量，而是在空间中多采集一些锚点（L*L*L个），这样可以最大程度地保留充足的信息。每个锚点具有f(feature)维度的信息。
3、对应一个分子和它的梯度场e(x)，我们考虑让分子通过一个Encoder 得到latent z，即z = Enc(molecule)，然后Decoder f建模成neural field的形式，即对任意x，f(x;z)= e_molecule(x)。这样就可以把latent z作为这个molecule的表示。

encoder的逻辑是，将分子molecule的图G_M输入，然后学习训练对象是锚点的codes，锚点维度为L*L*L*code_dim，写成符号就是G_L。更具体一些，这个学习的过程是：把G_M和G_L两个图联合学习，但是G_M的信息是不用更新的，因为molecule输入之后是固定的，但是G_L内部以及G_M和G_L之间也是要做信息传递的。这可能可以通过mask实现。

**3、扩散模型生成神经场**: 这意味着你将在**潜在码空间** \(z_{grid}\) 上训练一个**扩散模型**（而不是 VecMol 的 WJS + 单步去噪器）。这个扩散模型学习 \(z_{grid}\) 的分布，并能够生成新的 \(z'_{grid}\)。

- 扩散模型需要一个能够处理 \(z_{grid}\) 结构（\(L \times L \times L \times f\)）的去噪网络（对应 VecMol 的 MLP 去噪器，但结构不同）。



### 对照 VecMol 项目代码需要进行的修改分析：
> VecMol 的代码库是基于其特定的架构和流程构建的。你的项目虽然在理念上相似（表示学习 + 潜在空间生成），但在核心的表示对象（标量密度 vs 矢量场）和网络架构（MFN vs EGNN）上有根本区别。因此，许多部分需要替换或重写，而不是简单修改。

以下是主要的修改点，参考 VecMol 的代码结构（如 Appendix B 中的描述和代码组织）：

**1、数据预处理 (Preprocessing) - 对应 VecMol 的体素化等**:

- VecMol 的任务: 将分子转换为低分辨率体素网格 G，计算连续密度场 \(v(x)\)。
- 你的任务: 需要实现将分子转换为你的目标矢量场 \(V_{true}(x)\) 的代码。这可能涉及在空间中的一系列点 \(x\) 上计算 \(V_{true}(x)\) 值。你已经完成了这第一步，所以这部分代码是现成的，需要集成进来。
- 需要修改/添加:
    - 删除或绕过 VecMol 的体素化和密度场计算逻辑（可能在数据加载和预处理脚本中）。
    - 集成你的“**分子 -> \(V_{true}(x)\)**”**转换函数/类**。
    - 数据加载时，对于训练集中的每个分子，生成或加载预计算好的 \(V_{true}(x)\) 数据。
    - 定义用于训练和评估的空间采样点 \(x\) 的策略（VecMol 在原子附近和均匀网格上采样，Section B）。你也需要类似的策略来获取 EGNN 的查询点 \(x_{query}\)，并计算这些点对应的 \(V_{true}(x_{query})\) 作为监督信号。

**2、网络架构 (Models) - 对应 VecMol 的 fϕ 和 ζψ**：

- VecMol 的 fϕ (Conditional MFN Decoder): 输入 \((x, z_{vector})\)，输出标量。
- 你的 EGNN g: 输入 \((z_{grid}, x_{query})\)，输出矢量。这是完全不同的网络结构。
- VecMol 的 ζψ (3D CNN Encoder): 输入 G，输出 \(z_{vector}\)。
- 你的 \(z_{grid}\) 的来源: 如果 \(z_{grid}\) 是从分子学习得到的（而不是固定的），你需要一个新的编码器 \(\zeta'\) 将分子转换为 \(z_{grid}\)。这个编码器可能也不是 VecMol 的 3D CNN，因为它要输出结构化的网格特征。这可能是一个基于图或者其他机制的网络。**或者，如果你的 \(z_{grid}\) 锚点特征是直接优化的潜在变量，那么就不需要这个编码器网络。**(假设你采用后者，即 \(z_{grid}\) 是直接学习/优化的潜在变量)
- 需要修改/添加:
    - 删除 conditional_mfn.py 文件及其相关的类和函数。
    - 删除 encoder_cnn_3d.py 文件及其相关的类和函数。
    - 添加 egnn_vector_field.py 或类似文件，实现你的等变图神经网络 \(g\)。这个网络将接收锚点信息（坐标+特征）和查询点信息（坐标），并输出查询点处的矢量 \(V(x_{query})\)。需要实现 KNN 图构建、EGNN 消息传递和矢量输出层。

**3、潜在码表示 (Latent Code Representation)**:

- VecMol: 潜在码 \(z\) 是一个简单的低维向量 (1024 或 2048)。
- 你的想法: 潜在码 \(z_{grid}\) 是一个结构化的张量 (\(L \times L \times L \times f\))，并且锚点本身有固定的空间坐标（或者这些坐标也是学习的？通常固定比较简单）。
- 需要修改/添加:
    - 全局潜在码的表示方式需要从 torch.Tensor 的扁平向量改为结构化张量。
    - 如果 \(z_{grid}\) 是直接优化的潜在变量，你需要维护一个针对训练集中每个分子的 \(z_{grid}\) 列表或字典。

**4、训练循环 (Training Loops) - 对应 VecMol 的 Algorithm 1, 2**:

- VecMol 的目标: 重建标量密度场。
- 你的目标: 重建目标矢量场。
- 需要修改/添加:
    - 修改训练损失函数：从 \(\|f_\phi(x, z) - v(x)\|^2\) 变为 \(\|g(z_{grid}, x) - V_{true}(x)\|^2\)。
    - 修改训练数据批次处理：每个批次需要包含分子 ID（或对应的 \(z_{grid}\)）、采样的查询点 \(x_{query}\) 及其对应的 \(V_{true}(x_{query})\) 值。
    - 实现学习 \(z_{grid}\) 的逻辑（如果是直接优化）：在训练循环中，除了更新 EGNN 参数，还需要更新当前批次分子的 \(z_{grid}\) 值。这可能需要类似 Algorithm 1 的优化步骤。

**5、生成模型 (Generative Model) - 对应 VecMol 的 Denoiser ˆzθ 和 Algorithm 3**:

- VecMol: 在低维向量空间训练 MLP 去噪器。
- 你的想法: 在结构化 \(z_{grid}\) 空间训练扩散模型的去噪网络 \(\hat{z}'_\theta(y_{grid}, t)\)。
- 需要修改/添加:
    - 删除 denoiser_mlp.py 文件及其相关的类和函数。
    - 添加 denoiser_diffusion_grid.py 或类似文件，实现处理结构化张量 \(y_{grid}\) 和输出结构化张量 \(\hat{z}'_{grid}\) 的去噪网络。这很可能是一个3D CNN 或者一个处理网格数据的Transformer 或其他架构。
    - 实现扩散模型的正向（加噪）和反向（去噪/采样）过程的代码。这需要引入时间步 \(t\) 的概念，并修改去噪器网络的输入以包含 \(t\)（或其嵌入）。
    - 实现扩散模型的训练损失函数（通常是去噪目标，如 \(\mathbb{E}_{z_{grid}, t, \epsilon} [\|\epsilon - \text{预测的噪声}\|^2]\)预测的噪声）。

**6、采样过程 (Sampling) - 对应 VecMol 的 Algorithm 4**:

- VecMol: 使用 WJS 算法在向量空间采样。
- 你的想法: 使用扩散模型的采样算法（例如 Denoising Diffusion Probabilistic Models - DDPM 或 DDIM 采样器）在结构化 \(z_{grid}\) 空间从噪声开始迭代去噪。
- 需要修改/添加:
    - 实现扩散模型的采样算法。这涉及从随机噪声 \(z_T \sim \mathcal{N}(0, I)\) 开始，迭代应用去噪网络 \(\hat{z}'_\theta\) 和扩散过程的反向步骤，直到时间步 0 得到干净的 \(z'_0 \approx z_{grid}\)。
    - 删除或绕过 VecMol 的 WJS 采样算法。

**7、从潜在码到分子的解码 (Post-processing) - 取代 VecMol 的 Section 3.3 逻辑**:

- VecMol: 基于标量密度峰值检测和连续精炼。
- 你的任务: 应用你已完成的、从矢量场 \(V(x)\) 提取原子坐标的方法。
- 需要修改/添加:
    - 删除 VecMol 的解码后处理代码。
    - 集成你实现好的**“矢量场 -> 原子坐标+类型”的解码代码**。
    - 在采样流程的最后一步，调用你的解码函数，将新生成的 \(z'_{grid}\) 通过 EGNN \(g\) 转化为 \(V_{approx}(x)\)，然后将 \(V_{approx}(x)\) 输入你的解码方法，得到最终的分子结构。

**8、评估指标 (Metrics)**:

- 保留所有 VecMol 使用的基于最终分子结构的化学和几何指标（稳定性、有效性、独特性、键长、键角、环大小、QED, SA, logP 等）。这些是衡量生成质量的标准。
- 你可能还可以添加衡量生成的矢量场 \(V_{approx}(x)\) 与目标 \(V_{true}(x)\) 相似度的指标（例如 MSE），但这主要是用于训练和调试网络 \(g\)。


---

在EGNN里做信息传输：
1、一个分子的梯度场可以看成一个空间中的一个矢量方向，也就是空间中每个位置x的矢量e(x)。而neural field就是用神经网络f(x)来学这个函数，所以对一个分子的神经场函数e(x)，然后从这个矢量还原出具体的分子位置。可以训练min RMSD[分子原坐标 - 还原出的分子中原子位置]。但是直接这样做得每一个数据点需要单独训练一个网络f(x)。
2、于是，对于每一个数据点，我们想学一个latent 表示z，作为这个neural field神经网络的condition，使得f(x;z)来可以表示对应z这个数据点的梯度场。在这个项目里，我希望latent 表示z不是一个向量，而是在空间中多采集一些锚点（L*L*L个），这样可以最大程度地保留充足的信息。每个锚点具有f(feature)维度的信息。
3、对应一个分子和它的梯度场e(x)，我们考虑让分子通过一个Encoder 得到latent z，即z = Enc(molecule)，然后Decoder f建模成neural field的形式，即对任意x，f(x;z)= e_molecule(x)。这样就可以把latent z作为这个molecule的表示。

---

encoder的逻辑是，将分子molecule的图G_M输入，然后学习训练对象是锚点的codes，锚点维度为L*L*L*code_dim，写成符号就是G_L。更具体一些，这个学习的过程是：把G_M和G_L两个图联合学习，但是G_M的信息是不用更新的，因为molecule输入之后是固定的，但是G_L内部以及G_M和G_L之间也是要做信息传递的。这可能可以通过mask实现。