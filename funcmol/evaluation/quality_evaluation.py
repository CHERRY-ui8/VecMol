"""
åˆ†å­è´¨é‡è¯„ä¼°æ¨¡å—
åŒ…å«æœ‰æ•ˆæ€§ã€å”¯ä¸€æ€§ã€æ–°é¢–æ€§ã€ç¨³å®šæ€§ç­‰è´¨é‡æŒ‡æ ‡è¯„ä¼°
"""

import torch
import numpy as np
import os
from pathlib import Path
from tqdm import tqdm
from collections import Counter

from rdkit import Chem

from funcmol.analysis.rdkit_functions import Molecule, check_stability
from funcmol.evaluation.utils_evaluation import atom_decoder_dict
from funcmol.evaluation.bond_evaluation import build_xae_molecule


class SimpleSamplingMetrics:
    """ç®€åŒ–çš„åˆ†å­é‡‡æ ·æŒ‡æ ‡è¯„ä¼°å™¨ï¼Œä¸ä¾èµ–MiDi"""
    
    def __init__(self, train_smiles=None, dataset_infos=None, test=True):
        self.dataset_infos = dataset_infos
        self.atom_decoder = dataset_infos.atom_decoder if dataset_infos else ['H', 'C', 'N', 'O', 'F']
        self.train_smiles = set(train_smiles) if train_smiles else set()
        self.test = test
        
        # åˆå§‹åŒ–æŒ‡æ ‡
        self.atom_stable = 0.0
        self.mol_stable = 0.0
        self.validity_metric = 0.0
        self.uniqueness = 0.0
        self.novelty = 0.0
        self.mean_components = 0.0
        self.max_components = 0.0
        
    def compute_validity(self, generated):
        """è®¡ç®—åˆ†å­æœ‰æ•ˆæ€§"""
        valid = []
        num_components = []
        all_smiles = []
        error_message = Counter()
        
        for i, mol in enumerate(generated):
            rdmol = mol.rdkit_mol
            if rdmol is not None:
                try:
                    mol_frags = Chem.rdmolops.GetMolFrags(rdmol, asMols=True, sanitizeFrags=False)
                    num_components.append(len(mol_frags))
                    if len(mol_frags) > 1:
                        error_message[4] += 1
                    largest_mol = max(mol_frags, default=mol, key=lambda m: m.GetNumAtoms())
                    Chem.SanitizeMol(largest_mol)
                    smiles = Chem.MolToSmiles(largest_mol)
                    valid.append(smiles)
                    all_smiles.append(smiles)
                    error_message[-1] += 1
                except Chem.rdchem.AtomValenceException:
                    error_message[1] += 1
                    try:
                        invalid_smiles = Chem.MolToSmiles(rdmol, sanitize=False)
                        all_smiles.append(f"INVALID_AtomValence: {invalid_smiles}")
                    except:
                        all_smiles.append("INVALID_AtomValence: æ— æ³•ç”ŸæˆSMILES")
                except Chem.rdchem.KekulizeException:
                    error_message[2] += 1
                    try:
                        invalid_smiles = Chem.MolToSmiles(rdmol, sanitize=False)
                        all_smiles.append(f"INVALID_Kekulize: {invalid_smiles}")
                    except:
                        all_smiles.append("INVALID_Kekulize: æ— æ³•ç”ŸæˆSMILES")
                except (Chem.rdchem.AtomKekulizeException, ValueError):
                    error_message[3] += 1
                    try:
                        invalid_smiles = Chem.MolToSmiles(rdmol, sanitize=False)
                        all_smiles.append(f"INVALID_Other: {invalid_smiles}")
                    except:
                        all_smiles.append("INVALID_Other: æ— æ³•ç”ŸæˆSMILES")
            else:
                all_smiles.append("INVALID_NoRDKit: æ— æ³•æ„å»ºRDKitåˆ†å­")
        
        self.validity_metric = len(valid) / len(generated) if generated else 0.0
        if num_components:
            self.mean_components = sum(num_components) / len(num_components)
            self.max_components = max(num_components)
        else:
            self.mean_components = 0.0
            self.max_components = 0.0
            
        not_connected = 100.0 * error_message[4] / len(generated) if generated else 0.0
        connected_components = 100.0 - not_connected
        return valid, connected_components, all_smiles, error_message
    
    def evaluate(self, generated, local_rank):
        """è¯„ä¼°åˆ†å­è´¨é‡"""
        # Validity
        valid, connected_components, all_smiles, error_message = self.compute_validity(generated)
        
        validity = self.validity_metric
        uniqueness, novelty = 0, 0
        mean_components = self.mean_components
        max_components = self.max_components
        
        # Uniqueness
        if len(valid) > 0:
            unique = list(set(valid))
            self.uniqueness = len(unique) / len(valid)
            uniqueness = self.uniqueness
            
            if self.train_smiles:
                novel = []
                for smiles in unique:
                    if smiles not in self.train_smiles:
                        novel.append(smiles)
                self.novelty = len(novel) / len(unique)
            novelty = self.novelty
        
        num_molecules = len(generated)
        print(f"Validity over {num_molecules} molecules: {validity * 100:.2f}%")
        print(f"Number of connected components of {num_molecules} molecules: "
              f"mean:{mean_components:.2f} max:{max_components:.2f}")
        print(f"Connected components of {num_molecules} molecules: {connected_components:.2f}")
        print(f"Uniqueness: {uniqueness * 100:.2f}%")
        print(f"Novelty: {novelty * 100:.2f}%")
        
        return all_smiles
    
    def __call__(self, molecules, name, current_epoch, local_rank):
        """è°ƒç”¨è¯„ä¼°å‡½æ•°"""
        # Atom and molecule stability
        if not self.dataset_infos.remove_h:
            print(f'Analyzing molecule stability on {local_rank}...')
            stable_mols = 0
            stable_atoms = 0
            total_atoms = 0
            
            for i, mol in enumerate(molecules):
                mol_stable, at_stable, num_bonds = check_stability(
                    mol, self.dataset_infos, atom_decoder=self.atom_decoder
                )
                if mol_stable.item() > 0.5:
                    stable_mols += 1
                stable_atoms += at_stable.item()
                total_atoms += num_bonds
            
            self.mol_stable = stable_mols / len(molecules) if molecules else 0.0
            self.atom_stable = stable_atoms / total_atoms if total_atoms > 0 else 0.0
            
            stability_dict = {'mol_stable': self.mol_stable, 'atm_stable': self.atom_stable}
            if local_rank == 0:
                print("Stability metrics:", stability_dict)
        
        # Validity, uniqueness, novelty
        all_generated_smiles = self.evaluate(molecules, local_rank=local_rank)
        
        # Save results
        os.makedirs('graphs', exist_ok=True)
        textfile = open(f'graphs/valid_unique_molecules_e{current_epoch}_GR{local_rank}.txt', "w")
        textfile.writelines([smiles + '\n' for smiles in all_generated_smiles])
        textfile.close()
        
        if self.test:
            filename = f'final_smiles_GR{local_rank}_{0}.txt'
            for i in range(2, 10):
                if os.path.exists(filename):
                    filename = f'final_smiles_GR{local_rank}_{i}.txt'
                else:
                    break
            with open(filename, 'w') as fp:
                for smiles in all_generated_smiles:
                    fp.write("%s\n" % smiles)
                print(f'All smiles saved on rank {local_rank}')


def load_molecules_from_npz(molecule_dir):
    """
    ä» .npz æ–‡ä»¶åŠ è½½åˆ†å­å¯¹è±¡
    
    Args:
        molecule_dir: åŒ…å« .npz æ–‡ä»¶çš„ç›®å½•è·¯å¾„
        
    Returns:
        list: Molecule å¯¹è±¡åˆ—è¡¨
    """
    molecule_dir = Path(molecule_dir)
    npz_files = sorted(molecule_dir.glob("generated_*.npz"))
    
    print(f"æ‰¾åˆ° {len(npz_files)} ä¸ª .npz åˆ†å­æ–‡ä»¶")
    
    atom_decoder = atom_decoder_dict['qm9_with_h']
    molecules = []
    
    for npz_file in tqdm(npz_files, desc="åŠ è½½åˆ†å­æ–‡ä»¶"):
        try:
            # åŠ è½½ npz æ–‡ä»¶
            data = np.load(npz_file)
            coords = data['coords']  # (N, 3) åæ ‡
            types = data['types']    # (N,) åŸå­ç±»å‹
            
            # è½¬æ¢ä¸ºtorchå¼ é‡
            positions = torch.tensor(coords, dtype=torch.float32)
            atom_types = torch.tensor(types, dtype=torch.long)
            
            # è¿‡æ»¤æ‰å¡«å……çš„åŸå­ï¼ˆå€¼ä¸º -1ï¼‰
            valid_mask = atom_types != -1
            if not valid_mask.any():
                continue
            
            positions = positions[valid_mask]
            atom_types = atom_types[valid_mask]
            
            # æ„å»ºé”®ç±»å‹çŸ©é˜µ
            dataset_info = {'name': 'qm9'}
            _, _, bond_types = build_xae_molecule(
                positions=positions,
                atom_types=atom_types,
                dataset_info=dataset_info,
                atom_decoder=atom_decoder
            )
            
            # åˆ›å»ºé›¶ç”µè·
            charges = torch.zeros_like(atom_types)
            
            # åˆ›å»º Molecule å¯¹è±¡
            molecule = Molecule(
                atom_types=atom_types.long(),
                bond_types=bond_types.long(),
                positions=positions.float(),
                charges=charges,
                atom_decoder=atom_decoder
            )
            
            molecules.append(molecule)
            
        except Exception as e:
            print(f"\nåŠ è½½æ–‡ä»¶ {npz_file} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"æˆåŠŸåŠ è½½ {len(molecules)} ä¸ªåˆ†å­")
    return molecules


def evaluate_quality(molecules,
                      strict_margin1, strict_margin2, strict_margin3,
                      medium_margin1, medium_margin2, medium_margin3,
                      relaxed_margin1, relaxed_margin2, relaxed_margin3,
                      output_dir=None):
    """
    è¯„ä¼°åˆ†å­è´¨é‡æŒ‡æ ‡
    
    Args:
        molecules: Molecule å¯¹è±¡åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
        strict_margin1/2/3: ä¸¥æ ¼æ ‡å‡†çš„marginå€¼ï¼ˆpmå•ä½ï¼‰
        medium_margin1/2/3: ä¸­ç­‰æ ‡å‡†çš„marginå€¼ï¼ˆpmå•ä½ï¼‰
        relaxed_margin1/2/3: å®½æ¾æ ‡å‡†çš„marginå€¼ï¼ˆpmå•ä½ï¼‰
    
    Returns:
        dict: åŒ…å«è´¨é‡è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    if not molecules:
        print("æ²¡æœ‰æœ‰æ•ˆçš„åˆ†å­å¯ä»¥è¯„ä¼°ï¼")
        return None
    
    # åˆ›å»ºç®€åŒ–çš„æ•°æ®é›†ä¿¡æ¯
    class SimpleDatasetInfo:
        def __init__(self):
            self.atom_decoder = atom_decoder_dict['qm9_with_h']
            self.remove_h = False
            # æ·»åŠ å¿…è¦çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            self.statistics = {
                'test': type('obj', (object,), {
                    'num_nodes': {i: 1 for i in range(1, 30)},
                    'atom_types': torch.ones(5),
                    'bond_types': torch.ones(5),
                    'charge_types': torch.ones(5),
                    'valencies': {atom: {0: 1, 1: 1, 2: 1, 3: 1, 4: 1} for atom in atom_decoder_dict['qm9_with_h']},
                    'bond_lengths': {1: {1.5: 1}, 2: {1.3: 1}, 3: {1.2: 1}, 4: {1.4: 1}},
                    'bond_angles': torch.ones(5, 1801)
                })()
            }
    
    dataset_infos = SimpleDatasetInfo()
    
    # åˆ›å»ºé‡‡æ ·æŒ‡æ ‡è¯„ä¼°å™¨
    sampling_metrics = SimpleSamplingMetrics(
        train_smiles=[],
        dataset_infos=dataset_infos,
        test=True
    )
    
    # è¯„ä¼°åˆ†å­
    print("\n" + "="*60)
    print(f"å¼€å§‹è¯„ä¼°åˆ†å­è´¨é‡ï¼ˆå…± {len(molecules)} ä¸ªåˆ†å­ï¼‰...")
    print("="*60)
    
    print("æ­£åœ¨è®¡ç®—æœ‰æ•ˆæ€§ã€å”¯ä¸€æ€§å’Œæ–°é¢–æ€§...")
    sampling_metrics(
        molecules=molecules,
        name='generated_molecules',
        current_epoch=0,
        local_rank=0
    )
    print("è¯„ä¼°å®Œæˆï¼")
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("åˆ†å­è´¨é‡è¯„ä¼°ç»“æœ")
    print("="*60)
    
    validity = sampling_metrics.validity_metric
    uniqueness = sampling_metrics.uniqueness
    novelty = sampling_metrics.novelty
    mean_components = sampling_metrics.mean_components
    max_components = sampling_metrics.max_components
    mol_stable = sampling_metrics.mol_stable
    atom_stable = sampling_metrics.atom_stable
    
    # ç»Ÿè®¡æ‰€æœ‰åˆ†å­
    print(f"\nğŸ“Š ç»Ÿè®¡æ‰€æœ‰åˆ†å­ï¼ˆå…± {len(molecules)} ä¸ªï¼‰...")
    total_valid = sum(1 for mol in tqdm(molecules, desc="æ£€æŸ¥æœ‰æ•ˆæ€§", leave=False) if mol.rdkit_mol is not None)
    total_stable = 0
    total_stable_medium = 0
    total_stable_relaxed = 0
    stable_atoms_strict = 0
    total_atoms_strict = 0
    stable_atoms_medium = 0
    total_atoms_medium = 0
    stable_atoms_relaxed = 0
    total_atoms_relaxed = 0
    
    # ä½¿ç”¨ä¸åŒä¸¥æ ¼ç¨‹åº¦çš„marginå€¼é‡æ–°æ„å»ºé”®å¹¶è®¡ç®—ç¨³å®šæ€§
    dataset_info = {'name': 'qm9'}
    atom_decoder = atom_decoder_dict['qm9_with_h']
    
    for mol in tqdm(molecules, desc="æ£€æŸ¥ç¨³å®šæ€§"):
        if mol.rdkit_mol is not None:
            try:
                # ä¸¥æ ¼ç¨³å®šæ€§ï¼ˆä½¿ç”¨ä¸¥æ ¼marginå€¼é‡æ–°æ„å»ºé”®ï¼‰
                _, _, bond_types_strict = build_xae_molecule(
                    positions=mol.positions,
                    atom_types=mol.atom_types,
                    dataset_info=dataset_info,
                    atom_decoder=atom_decoder,
                    margin1_val=strict_margin1,
                    margin2_val=strict_margin2,
                    margin3_val=strict_margin3
                )
                mol_stable_strict, at_stable_strict, num_atoms_strict = check_stability(
                    mol, None, atom_decoder=atom_decoder, bond_types=bond_types_strict
                )
                if mol_stable_strict.item() > 0.5:
                    total_stable += 1
                stable_atoms_strict += at_stable_strict.item()
                total_atoms_strict += num_atoms_strict
                
                # ä¸­ç­‰ç¨³å®šæ€§ï¼ˆä½¿ç”¨ä¸­ç­‰marginå€¼é‡æ–°æ„å»ºé”®ï¼‰
                _, _, bond_types_medium = build_xae_molecule(
                    positions=mol.positions,
                    atom_types=mol.atom_types,
                    dataset_info=dataset_info,
                    atom_decoder=atom_decoder,
                    margin1_val=medium_margin1,
                    margin2_val=medium_margin2,
                    margin3_val=medium_margin3
                )
                mol_stable_medium, at_stable_medium, num_atoms_medium = check_stability(
                    mol, None, atom_decoder=atom_decoder, bond_types=bond_types_medium
                )
                if mol_stable_medium.item() > 0.5:
                    total_stable_medium += 1
                stable_atoms_medium += at_stable_medium.item()
                total_atoms_medium += num_atoms_medium
                
                # å®½æ¾ç¨³å®šæ€§ï¼ˆä½¿ç”¨å®½æ¾marginå€¼é‡æ–°æ„å»ºé”®ï¼‰
                _, _, bond_types_relaxed = build_xae_molecule(
                    positions=mol.positions,
                    atom_types=mol.atom_types,
                    dataset_info=dataset_info,
                    atom_decoder=atom_decoder,
                    margin1_val=relaxed_margin1,
                    margin2_val=relaxed_margin2,
                    margin3_val=relaxed_margin3
                )
                mol_stable_relaxed, at_stable_relaxed, num_atoms = check_stability(
                    mol, None, atom_decoder=atom_decoder, bond_types=bond_types_relaxed
                )
                if mol_stable_relaxed.item() > 0.5:
                    total_stable_relaxed += 1
                stable_atoms_relaxed += at_stable_relaxed.item()
                total_atoms_relaxed += num_atoms
            except Exception:
                pass
    
    # é‡æ–°è®¡ç®—ä¸¥æ ¼ç¨³å®šæ€§ï¼ˆä½¿ç”¨ä¸¥æ ¼marginæ„å»ºçš„é”®çŸ©é˜µï¼‰
    mol_stable = total_stable / len(molecules) if molecules else 0.0
    atom_stable = stable_atoms_strict / total_atoms_strict if total_atoms_strict > 0 else 0.0
    
    mol_stable_medium = total_stable_medium / len(molecules) if molecules else 0.0
    atom_stable_medium = stable_atoms_medium / total_atoms_medium if total_atoms_medium > 0 else 0.0
    mol_stable_relaxed = total_stable_relaxed / len(molecules) if molecules else 0.0
    atom_stable_relaxed = stable_atoms_relaxed / total_atoms_relaxed if total_atoms_relaxed > 0 else 0.0
    
    print(f"\nğŸ“Š æ€»ä½“è´¨é‡æŒ‡æ ‡:")
    print(f"  æœ‰æ•ˆæ€§ (Validity): {validity*100:.2f}%")
    print(f"  å”¯ä¸€æ€§ (Uniqueness): {uniqueness*100:.2f}%")
    print(f"  æ–°é¢–æ€§ (Novelty): {novelty*100:.2f}%")
    print(f"  å¹³å‡è¿é€šåˆ†é‡æ•°: {mean_components:.2f}")
    print(f"  æœ€å¤§è¿é€šåˆ†é‡æ•°: {max_components:.2f}")
    print(f"\n  ç¨³å®šæ€§æŒ‡æ ‡ï¼ˆåŸºäºé”®çŸ©é˜µæ„å»ºçš„marginå€¼ï¼‰:")
    print(f"    ä¸¥æ ¼ (margin1={strict_margin1}pm, margin2={strict_margin2}pm, margin3={strict_margin3}pm):")
    print(f"      åˆ†å­ç¨³å®šæ€§: {float(mol_stable)*100:.2f}%")
    print(f"      åŸå­ç¨³å®šæ€§: {float(atom_stable)*100:.2f}%")
    print(f"    ä¸­ç­‰ (margin1={medium_margin1}pm, margin2={medium_margin2}pm, margin3={medium_margin3}pm):")
    print(f"      åˆ†å­ç¨³å®šæ€§: {float(mol_stable_medium)*100:.2f}%")
    print(f"      åŸå­ç¨³å®šæ€§: {float(atom_stable_medium)*100:.2f}%")
    print(f"    å®½æ¾ (margin1={relaxed_margin1}pm, margin2={relaxed_margin2}pm, margin3={relaxed_margin3}pm):")
    print(f"      åˆ†å­ç¨³å®šæ€§: {float(mol_stable_relaxed)*100:.2f}%")
    print(f"      åŸå­ç¨³å®šæ€§: {float(atom_stable_relaxed)*100:.2f}%")
    
    print(f"\nğŸ“Š ç»Ÿè®¡æ‘˜è¦:")
    print(f"  æ€»åˆ†å­æ•°: {len(molecules)}")
    print(f"  æœ‰æ•ˆåˆ†å­æ•°: {total_valid}")
    print(f"  ç¨³å®šåˆ†å­æ•°ï¼ˆä¸¥æ ¼ï¼‰: {total_stable}")
    print(f"  ç¨³å®šåˆ†å­æ•°ï¼ˆä¸­ç­‰ï¼‰: {total_stable_medium}")
    print(f"  ç¨³å®šåˆ†å­æ•°ï¼ˆå®½æ¾ï¼‰: {total_stable_relaxed}")
    print(f"  æœ‰æ•ˆæ€§: {total_valid/len(molecules)*100:.1f}%")
    print(f"  ç¨³å®šæ€§ï¼ˆä¸¥æ ¼ï¼‰: {total_stable/len(molecules)*100:.1f}%")
    print(f"  ç¨³å®šæ€§ï¼ˆä¸­ç­‰ï¼‰: {total_stable_medium/len(molecules)*100:.1f}%")
    print(f"  ç¨³å®šæ€§ï¼ˆå®½æ¾ï¼‰: {total_stable_relaxed/len(molecules)*100:.1f}%")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šäº†è¾“å‡ºç›®å½•ï¼‰
    if output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        results_file = output_dir / "evaluation_results.txt"
        with open(results_file, 'w', encoding='utf-8') as f:
            f.write("åˆ†å­è´¨é‡è¯„ä¼°ç»“æœ\n")
            f.write("="*60 + "\n\n")
            f.write(f"æ€»åˆ†å­æ•°: {len(molecules)}\n")
            f.write(f"æœ‰æ•ˆåˆ†å­æ•°: {total_valid}\n")
            f.write(f"ç¨³å®šåˆ†å­æ•°ï¼ˆä¸¥æ ¼ï¼‰: {total_stable}\n")
            f.write(f"ç¨³å®šåˆ†å­æ•°ï¼ˆä¸­ç­‰ï¼‰: {total_stable_medium}\n")
            f.write(f"ç¨³å®šåˆ†å­æ•°ï¼ˆå®½æ¾ï¼‰: {total_stable_relaxed}\n")
            f.write(f"æœ‰æ•ˆæ€§: {validity*100:.2f}%\n")
            f.write(f"å”¯ä¸€æ€§: {uniqueness*100:.2f}%\n")
            f.write(f"æ–°é¢–æ€§: {novelty*100:.2f}%\n")
            f.write(f"å¹³å‡è¿é€šåˆ†é‡æ•°: {mean_components:.2f}\n")
            f.write(f"æœ€å¤§è¿é€šåˆ†é‡æ•°: {max_components:.2f}\n")
            f.write(f"åˆ†å­ç¨³å®šæ€§ï¼ˆä¸¥æ ¼ï¼Œmargin1={strict_margin1}pm, margin2={strict_margin2}pm, margin3={strict_margin3}pmï¼‰: {float(mol_stable)*100:.2f}%\n")
            f.write(f"åŸå­ç¨³å®šæ€§ï¼ˆä¸¥æ ¼ï¼Œmargin1={strict_margin1}pm, margin2={strict_margin2}pm, margin3={strict_margin3}pmï¼‰: {float(atom_stable)*100:.2f}%\n")
            f.write(f"åˆ†å­ç¨³å®šæ€§ï¼ˆä¸­ç­‰ï¼Œmargin1={medium_margin1}pm, margin2={medium_margin2}pm, margin3={medium_margin3}pmï¼‰: {float(mol_stable_medium)*100:.2f}%\n")
            f.write(f"åŸå­ç¨³å®šæ€§ï¼ˆä¸­ç­‰ï¼Œmargin1={medium_margin1}pm, margin2={medium_margin2}pm, margin3={medium_margin3}pmï¼‰: {float(atom_stable_medium)*100:.2f}%\n")
            f.write(f"åˆ†å­ç¨³å®šæ€§ï¼ˆå®½æ¾ï¼Œmargin1={relaxed_margin1}pm, margin2={relaxed_margin2}pm, margin3={relaxed_margin3}pmï¼‰: {float(mol_stable_relaxed)*100:.2f}%\n")
            f.write(f"åŸå­ç¨³å®šæ€§ï¼ˆå®½æ¾ï¼Œmargin1={relaxed_margin1}pm, margin2={relaxed_margin2}pm, margin3={relaxed_margin3}pmï¼‰: {float(atom_stable_relaxed)*100:.2f}%\n")
        
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    return {
        'validity': validity,
        'uniqueness': uniqueness,
        'novelty': novelty,
        'mean_components': mean_components,
        'max_components': max_components,
        'mol_stable': mol_stable,
        'atom_stable': atom_stable,
        'mol_stable_medium': mol_stable_medium,
        'atom_stable_medium': atom_stable_medium,
        'mol_stable_relaxed': mol_stable_relaxed,
        'atom_stable_relaxed': atom_stable_relaxed,
        'total_valid': total_valid,
        'total_stable': total_stable,
        'total_stable_medium': total_stable_medium,
        'total_stable_relaxed': total_stable_relaxed,
        'num_molecules': len(molecules),
        'strict_margin1': strict_margin1,
        'strict_margin2': strict_margin2,
        'strict_margin3': strict_margin3,
        'medium_margin1': medium_margin1,
        'medium_margin2': medium_margin2,
        'medium_margin3': medium_margin3,
        'relaxed_margin1': relaxed_margin1,
        'relaxed_margin2': relaxed_margin2,
        'relaxed_margin3': relaxed_margin3
    }

