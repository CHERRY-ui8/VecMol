"""
é”®ç›¸å…³è¯„ä¼°æ¨¡å—
åŒ…å«é”®åˆ¤æ–­ã€é”®é•¿åˆ†æã€ç¼ºå¤±é”®æ£€æµ‹ã€è¿é€šæ€§åˆ†æç­‰åŠŸèƒ½
"""

import torch
import numpy as np
from typing import Tuple, Optional, List, Dict

from funcmol.evaluation.utils_evaluation import (
    bonds1, bonds2, bonds3,
    margin1, margin2, margin3,
    atom_decoder_dict
)


def get_bond_order(atom1, atom2, distance, check_exists=False, 
                   margin1_val=None, margin2_val=None, margin3_val=None):
    """
    åˆ¤æ–­é”®ç±»å‹ï¼ˆå•é”®/åŒé”®/ä¸‰é”®ï¼‰
    
    Args:
        atom1: åŸå­1ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼Œå¦‚ 'C', 'H'ï¼‰
        atom2: åŸå­2ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        distance: åŸå­é—´è·ç¦»ï¼ˆå•ä½ï¼šÃ…ï¼‰
        check_exists: æ˜¯å¦æ£€æŸ¥åŸå­å¯¹æ˜¯å¦å­˜åœ¨æ ‡å‡†é”®é•¿
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        int: é”®ç±»å‹ (0=æ— é”®, 1=å•é”®, 2=åŒé”®, 3=ä¸‰é”®)
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    distance_pm = 100 * distance  # è½¬æ¢ä¸ºpmå•ä½
    
    # æ£€æŸ¥åŸå­å¯¹æ˜¯å¦å­˜åœ¨æ ‡å‡†é”®é•¿
    if check_exists:
        if atom1 not in bonds1:
            return 0
        if atom2 not in bonds1[atom1]:
            return 0
    
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦åœ¨å•é”®èŒƒå›´å†…
    if distance_pm < bonds1[atom1][atom2] + margin1_val:
        # æ£€æŸ¥æ˜¯å¦åœ¨åŒé”®èŒƒå›´å†…
        if atom1 in bonds2 and atom2 in bonds2[atom1]:
            thr_bond2 = bonds2[atom1][atom2] + margin2_val
            if distance_pm < thr_bond2:
                # æ£€æŸ¥æ˜¯å¦åœ¨ä¸‰é”®èŒƒå›´å†…
                if atom1 in bonds3 and atom2 in bonds3[atom1]:
                    thr_bond3 = bonds3[atom1][atom2] + margin3_val
                    if distance_pm < thr_bond3:
                        return 3  # ä¸‰é”®
                return 2  # åŒé”®
        return 1  # å•é”®
    return 0  # æ— é”®


def get_expected_bond_order(atom1, atom2, distance, 
                            margin1_val=None, margin2_val=None, margin3_val=None):
    """
    æ ¹æ®è·ç¦»åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹ï¼ˆç”¨äºæ£€æµ‹ç¼ºå¤±é”®å’Œé”®ç±»å‹ä¸åŒ¹é…ï¼‰
    
    æŒ‰ç…§ä»é«˜åˆ°ä½çš„ä¼˜å…ˆçº§æ£€æŸ¥ï¼šä¸‰é”® -> åŒé”® -> å•é”®
    
    Args:
        atom1: åŸå­1ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        atom2: åŸå­2ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        distance: åŸå­é—´è·ç¦»ï¼ˆå•ä½ï¼šÃ…ï¼‰
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        tuple: (expected_order, standard_dist, threshold)
            - expected_order: æœŸæœ›çš„é”®ç±»å‹ (0/1/2/3)
            - standard_dist: å¯¹åº”çš„æ ‡å‡†é”®é•¿ï¼ˆå•ä½ï¼šÃ…ï¼‰
            - threshold: åˆ¤æ–­é˜ˆå€¼ï¼ˆå•ä½ï¼šÃ…ï¼‰
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    distance_pm = 100 * distance  # è½¬æ¢ä¸ºpmå•ä½
    
    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥ï¼šä¸‰é”® -> åŒé”® -> å•é”®
    # æ£€æŸ¥ä¸‰é”®
    if atom1 in bonds3 and atom2 in bonds3[atom1]:
        standard_dist_pm = bonds3[atom1][atom2]
        threshold_pm = standard_dist_pm + margin3_val
        if distance_pm < threshold_pm:
            return 3, standard_dist_pm / 100.0, threshold_pm / 100.0
    
    # æ£€æŸ¥åŒé”®
    if atom1 in bonds2 and atom2 in bonds2[atom1]:
        standard_dist_pm = bonds2[atom1][atom2]
        threshold_pm = standard_dist_pm + margin2_val
        if distance_pm < threshold_pm:
            return 2, standard_dist_pm / 100.0, threshold_pm / 100.0
    
    # æ£€æŸ¥å•é”®
    if atom1 in bonds1 and atom2 in bonds1[atom1]:
        standard_dist_pm = bonds1[atom1][atom2]
        threshold_pm = standard_dist_pm + margin1_val
        if distance_pm < threshold_pm:
            return 1, standard_dist_pm / 100.0, threshold_pm / 100.0
    
    return 0, None, None


def build_xae_molecule(positions, atom_types, dataset_info, atom_decoder):
    """
    æ„å»ºåˆ†å­é”®çŸ©é˜µ
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
    
    Returns:
        tuple: (X, A, E)
            - X: åŸå­ç±»å‹ [N]
            - A: é‚»æ¥çŸ©é˜µ [N, N] (bool)
            - E: é”®ç±»å‹çŸ©é˜µ [N, N] (int)
    """
    n = positions.shape[0]
    X = atom_types
    A = torch.zeros((n, n), dtype=torch.bool)
    E = torch.zeros((n, n), dtype=torch.int)
    
    pos = positions.unsqueeze(0)
    dists = torch.cdist(pos, pos, p=2).squeeze(0)
    
    for i in range(n):
        for j in range(i):
            pair = sorted([atom_types[i], atom_types[j]])
            if dataset_info['name'] == 'qm9':
                order = get_bond_order(
                    atom_decoder[pair[0]], 
                    atom_decoder[pair[1]], 
                    dists[i, j]
                )
            elif dataset_info['name'] == 'geom':
                # å¯¹äºgeomæ•°æ®é›†ï¼Œä½¿ç”¨limit_bonds_to_one
                order = get_bond_order(
                    atom_decoder[pair[0]], 
                    atom_decoder[pair[1]], 
                    dists[i, j],
                    check_exists=True
                )
                if order > 1:
                    order = 1  # é™åˆ¶ä¸ºå•é”®
            
            if order > 0:
                A[i, j] = 1
                E[i, j] = order
                E[j, i] = order
    
    return X, A, E


def check_connectivity(bond_types):
    """
    æ£€æŸ¥åˆ†å­çš„è¿é€šæ€§ï¼ˆä½¿ç”¨DFSï¼‰
    
    Args:
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
    
    Returns:
        tuple: (num_components, is_connected)
            - num_components: è¿é€šåˆ†é‡æ•°
            - is_connected: æ˜¯å¦è¿é€šï¼ˆè¿é€šåˆ†é‡æ•°==1ï¼‰
    """
    n_atoms = bond_types.shape[0]
    if n_atoms == 0:
        return 0, False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹
    has_edges = (bond_types > 0).any()
    if not has_edges:
        # æ²¡æœ‰è¾¹ï¼Œæ¯ä¸ªåŸå­éƒ½æ˜¯ç‹¬ç«‹çš„è¿é€šåˆ†é‡
        return n_atoms, False
    
    # ä½¿ç”¨DFSè®¡ç®—è¿é€šåˆ†é‡
    visited = torch.zeros(n_atoms, dtype=torch.bool)
    num_components = 0
    
    def dfs(node):
        """æ·±åº¦ä¼˜å…ˆæœç´¢"""
        visited[node] = True
        neighbors = torch.nonzero(bond_types[node] > 0, as_tuple=False).squeeze(-1)
        for neighbor in neighbors:
            if neighbor.item() != node and not visited[neighbor.item()]:
                dfs(neighbor.item())
    
    # éå†æ‰€æœ‰æœªè®¿é—®çš„èŠ‚ç‚¹
    for i in range(n_atoms):
        if not visited[i]:
            dfs(i)
            num_components += 1
    
    is_connected = (num_components == 1)
    return num_components, is_connected


def check_connectivity_with_labels(bond_types):
    """
    æ£€æŸ¥åˆ†å­çš„è¿é€šæ€§å¹¶è¿”å›æ¯ä¸ªåŸå­æ‰€å±çš„è¿é€šåˆ†é‡ID
    
    Args:
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        
    Returns:
        tuple: (num_components, component_ids)
            - num_components: è¿é€šåˆ†é‡æ•°
            - component_ids: æ¯ä¸ªåŸå­æ‰€å±çš„è¿é€šåˆ†é‡ID [N]
    """
    n_atoms = bond_types.shape[0]
    if n_atoms == 0:
        return 0, torch.zeros(0, dtype=torch.long)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹
    has_edges = (bond_types > 0).any()
    if not has_edges:
        # æ²¡æœ‰è¾¹ï¼Œæ¯ä¸ªåŸå­éƒ½æ˜¯ç‹¬ç«‹çš„è¿é€šåˆ†é‡
        component_ids = torch.arange(n_atoms, dtype=torch.long)
        return n_atoms, component_ids
    
    # ä½¿ç”¨DFSè®¡ç®—è¿é€šåˆ†é‡å¹¶æ ‡è®°
    visited = torch.zeros(n_atoms, dtype=torch.bool)
    component_ids = torch.zeros(n_atoms, dtype=torch.long)
    current_component = 0
    
    def dfs_label(node, comp_id):
        """æ·±åº¦ä¼˜å…ˆæœç´¢å¹¶æ ‡è®°è¿é€šåˆ†é‡"""
        visited[node] = True
        component_ids[node] = comp_id
        neighbors = torch.nonzero(bond_types[node] > 0, as_tuple=False).squeeze(-1)
        for neighbor in neighbors:
            if neighbor.item() != node and not visited[neighbor.item()]:
                dfs_label(neighbor.item(), comp_id)
    
    # éå†æ‰€æœ‰æœªè®¿é—®çš„èŠ‚ç‚¹
    for i in range(n_atoms):
        if not visited[i]:
            dfs_label(i, current_component)
            current_component += 1
    
    num_components = current_component
    return num_components, component_ids


def compute_missing_bond_deviations_strict(positions, atom_types, bond_types, atom_decoder, dataset_info, 
                                            strict_margin1=15, strict_margin2=10, strict_margin3=6):
    """
    è®¡ç®—åº”è¯¥å½¢æˆé”®ä½†æœªå½¢æˆé”®çš„åŸå­å¯¹çš„è·ç¦»åå·®ï¼ˆä½¿ç”¨ä¸¥æ ¼æ ‡å‡†ï¼Œè€ƒè™‘æ‰€æœ‰é”®ç±»å‹ï¼‰
    
    ä¼˜åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨ get_expected_bond_order() æ¥åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹ï¼Œä¸ä»…æ£€æµ‹å•é”®ç¼ºå¤±ï¼Œ
    è¿˜æ£€æµ‹åŒé”®/ä¸‰é”®ç¼ºå¤±ï¼Œä»¥åŠé”®ç±»å‹ä¸åŒ¹é…çš„æƒ…å†µã€‚
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        strict_margin1: ä¸¥æ ¼margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤15pm
        strict_margin2: ä¸¥æ ¼margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤10pm
        strict_margin3: ä¸¥æ ¼margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤6pm
    
    Returns:
        missing_bonds: List of dicts with keys: pair, actual_dist, standard_dist, deviation_pct, 
                      expected_order, actual_order, is_type_mismatch
    """
    n = positions.shape[0]
    dists = torch.cdist(positions, positions, p=2)
    missing_bonds = []
    
    # è®¡ç®—è¿é€šåˆ†é‡ï¼Œç”¨äºæ£€æµ‹è·¨åˆ†é‡çš„ç¼ºå¤±é”®
    num_components, component_ids = check_connectivity_with_labels(bond_types)
    
    for i in range(n):
        for j in range(i):
            atom1_str = atom_decoder[atom_types[i].item()]
            atom2_str = atom_decoder[atom_types[j].item()]
            
            # æ£€æŸ¥æ ‡å‡†é”®é•¿ï¼ˆéœ€è¦æŒ‰å­—æ¯é¡ºåºæ’åºï¼‰
            pair = sorted([atom1_str, atom2_str])
            atom1_key = pair[0]
            atom2_key = pair[1]
            
            # ä½¿ç”¨ä¼˜åŒ–åçš„å‡½æ•°åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹
            actual_dist = dists[i, j].item()
            expected_order, standard_dist, threshold = get_expected_bond_order(
                atom1_key, atom2_key, actual_dist,
                margin1_val=strict_margin1,
                margin2_val=strict_margin2,
                margin3_val=strict_margin3
            )
            
            if expected_order > 0:  # åº”è¯¥å½¢æˆæŸç§ç±»å‹çš„é”®
                actual_order = bond_types[i, j].item()
                is_cross_component = (component_ids[i] != component_ids[j])
                has_bond = (actual_order > 0)
                deviation_pct = (actual_dist - standard_dist) / standard_dist * 100
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å½¢æˆé”®ä½†æœªå½¢æˆï¼Œæˆ–é”®ç±»å‹ä¸åŒ¹é…
                is_missing = (not has_bond) or is_cross_component
                is_type_mismatch = (has_bond and actual_order != expected_order)
                
                # æƒ…å†µ1ï¼šæ²¡æœ‰é”®æˆ–è·¨åˆ†é‡
                if is_missing:
                    missing_bonds.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'atom1': atom1_str,
                        'atom2': atom2_str,
                        'expected_order': expected_order,
                        'actual_order': actual_order,
                        'is_cross_component': is_cross_component,
                        'is_type_mismatch': False,
                        'has_bond': has_bond
                    })
                # æƒ…å†µ2ï¼šé”®ç±»å‹ä¸åŒ¹é…ï¼ˆä¾‹å¦‚åº”è¯¥å½¢æˆåŒé”®ä½†åªå½¢æˆäº†å•é”®ï¼‰
                elif is_type_mismatch:
                    missing_bonds.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'atom1': atom1_str,
                        'atom2': atom2_str,
                        'expected_order': expected_order,
                        'actual_order': actual_order,
                        'is_cross_component': False,
                        'is_type_mismatch': True,
                        'has_bond': True
                    })
                # æƒ…å†µ3ï¼šæœ‰é”®ä½†è·ç¦»åç¦»æ ‡å‡†å€¼è¶…è¿‡5%ï¼ˆç»“æ„ä¸ç†æƒ³ï¼‰
                elif has_bond and abs(deviation_pct) > 5.0:
                    # ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼æ¥æ£€æµ‹åç¦»æ ‡å‡†å€¼çš„é”®
                    relaxed_threshold = threshold * 1.2  # æ”¾å®½20%
                    if actual_dist < relaxed_threshold:
                        missing_bonds.append({
                            'pair': (i, j),
                            'actual_dist': actual_dist,
                            'standard_dist': standard_dist,
                            'deviation_pct': deviation_pct,
                            'atom1': atom1_str,
                            'atom2': atom2_str,
                            'expected_order': expected_order,
                            'actual_order': actual_order,
                            'is_cross_component': False,
                            'is_type_mismatch': False,
                            'has_bond': True
                        })
    
    return missing_bonds


def compute_bond_type_mismatches(positions, atom_types, bond_types, atom_decoder, dataset_info,
                                  margin1_val=None, margin2_val=None, margin3_val=None):
    """
    æ£€æµ‹é”®ç±»å‹ä¸åŒ¹é…çš„æƒ…å†µï¼ˆå®é™…é”®ç±»å‹ä¸æœŸæœ›é”®ç±»å‹ä¸ä¸€è‡´ï¼‰
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        mismatches: List of dicts with keys: pair, actual_dist, expected_order, actual_order, deviation_pct
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    n = positions.shape[0]
    dists = torch.cdist(positions, positions, p=2)
    mismatches = []
    
    for i in range(n):
        for j in range(i):
            if bond_types[i, j] > 0:  # å½“å‰åˆ¤æ–­ä¸ºæœ‰é”®
                atom1_str = atom_decoder[atom_types[i].item()]
                atom2_str = atom_decoder[atom_types[j].item()]
                pair = sorted([atom1_str, atom2_str])
                atom1_key = pair[0]
                atom2_key = pair[1]
                
                # åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹
                actual_dist = dists[i, j].item()
                expected_order, standard_dist, _ = get_expected_bond_order(
                    atom1_key, atom2_key, actual_dist,
                    margin1_val=margin1_val,
                    margin2_val=margin2_val,
                    margin3_val=margin3_val
                )
                
                actual_order = bond_types[i, j].item()
                
                # å¦‚æœæœŸæœ›é”®ç±»å‹ä¸å®é™…é”®ç±»å‹ä¸åŒ¹é…
                if expected_order > 0 and actual_order != expected_order:
                    deviation_pct = (actual_dist - standard_dist) / standard_dist * 100
                    mismatches.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'atom1': atom1_str,
                        'atom2': atom2_str,
                        'expected_order': expected_order,
                        'actual_order': actual_order
                    })
    
    return mismatches


def compute_excessive_bond_deviations(positions, atom_types, bond_types, atom_decoder, dataset_info, 
                                       margin1_val=None, margin2_val=None, margin3_val=None):
    """
    è®¡ç®—ä¸åº”è¯¥å½¢æˆé”®ä½†å½¢æˆé”®çš„åŸå­å¯¹ï¼ˆè·ç¦»è¿‡è¿œä½†ä»è¢«åˆ¤æ–­ä¸ºæœ‰é”®ï¼‰
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        excessive_bonds: List of dicts with keys: pair, actual_dist, standard_dist, deviation_pct, bond_order
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    n = positions.shape[0]
    dists = torch.cdist(positions, positions, p=2)
    excessive_bonds = []
    
    for i in range(n):
        for j in range(i):
            if bond_types[i, j] > 0:  # å½“å‰åˆ¤æ–­ä¸ºæœ‰é”®
                atom1_str = atom_decoder[atom_types[i].item()]
                atom2_str = atom_decoder[atom_types[j].item()]
                pair = sorted([atom1_str, atom2_str])
                atom1_key = pair[0]
                atom2_key = pair[1]
                
                # åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹
                actual_dist = dists[i, j].item()
                expected_order, standard_dist, threshold = get_expected_bond_order(
                    atom1_key, atom2_key, actual_dist,
                    margin1_val=margin1_val,
                    margin2_val=margin2_val,
                    margin3_val=margin3_val
                )
                
                # å¦‚æœè·ç¦»è¶…è¿‡åº”è¯¥å½¢æˆé”®çš„èŒƒå›´
                if expected_order == 0 or actual_dist > threshold:
                    # ä½¿ç”¨å•é”®æ ‡å‡†ä½œä¸ºå‚è€ƒ
                    if atom1_key in bonds1 and atom2_key in bonds1[atom1_key]:
                        ref_standard_dist = bonds1[atom1_key][atom2_key] / 100.0
                        deviation_pct = (actual_dist - ref_standard_dist) / ref_standard_dist * 100
                        excessive_bonds.append({
                            'pair': (i, j),
                            'actual_dist': actual_dist,
                            'standard_dist': ref_standard_dist,
                            'deviation_pct': deviation_pct,
                            'atom1': atom1_str,
                            'atom2': atom2_str,
                            'bond_order': bond_types[i, j].item()
                        })
    
    return excessive_bonds


def compute_connectivity_continuity_score(positions, atom_types, bond_types, atom_decoder, dataset_info,
                                          strict_margin1=15, strict_margin2=10, strict_margin3=6):
    """
    è®¡ç®—ç»¼åˆè¿ç»­æ€§è¿é€šæ€§åˆ†æ•°
    
    ä½¿ç”¨æ›´ä¸¥æ ¼çš„æ ‡å‡†æ¥åˆ¤æ–­"åº”è¯¥å½¢æˆé”®"ï¼Œè€ƒè™‘æ‰€æœ‰é”®ç±»å‹ï¼ˆå•/åŒ/ä¸‰é”®ï¼‰ï¼Œ
    è¿™æ ·å¯ä»¥æ£€æµ‹å‡ºå³ä½¿ä½¿ç”¨å®½æ¾marginåˆ¤æ–­ä¸ºæœ‰é”®ï¼Œä½†è·ç¦»ä»ç„¶åç¦»æ ‡å‡†å€¼çš„æƒ…å†µã€‚
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        strict_margin1: ä¸¥æ ¼margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤15pm
        strict_margin2: ä¸¥æ ¼margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤10pm
        strict_margin3: ä¸¥æ ¼margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤6pm
    
    Returns:
        dict: åŒ…å«è¿ç»­æ€§æŒ‡æ ‡çš„å­—å…¸
    """
    n = positions.shape[0]
    dists = torch.cdist(positions, positions, p=2)
    
    missing_bonds = []
    all_potential_bonds = []  # æ‰€æœ‰åº”è¯¥å½¢æˆé”®çš„åŸå­å¯¹ï¼ˆæ— è®ºæ˜¯å¦å·²å½¢æˆé”®ï¼‰
    type_mismatches = []  # é”®ç±»å‹ä¸åŒ¹é…çš„æƒ…å†µ
    
    for i in range(n):
        for j in range(i):
            atom1_str = atom_decoder[atom_types[i].item()]
            atom2_str = atom_decoder[atom_types[j].item()]
            pair = sorted([atom1_str, atom2_str])
            atom1_key = pair[0]
            atom2_key = pair[1]
            
            # ä½¿ç”¨ä¼˜åŒ–åçš„å‡½æ•°åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹
            actual_dist = dists[i, j].item()
            expected_order, standard_dist, threshold = get_expected_bond_order(
                atom1_key, atom2_key, actual_dist,
                margin1_val=strict_margin1,
                margin2_val=strict_margin2,
                margin3_val=strict_margin3
            )
            
            if expected_order > 0:  # åº”è¯¥å½¢æˆæŸç§ç±»å‹çš„é”®
                deviation_pct = (actual_dist - standard_dist) / standard_dist * 100
                actual_order = bond_types[i, j].item()
                
                all_potential_bonds.append({
                    'pair': (i, j),
                    'actual_dist': actual_dist,
                    'standard_dist': standard_dist,
                    'deviation_pct': deviation_pct,
                    'expected_order': expected_order,
                    'actual_order': actual_order,
                    'has_bond': actual_order > 0
                })
                
                # æ£€æŸ¥ç¼ºå¤±é”®
                if actual_order == 0:
                    missing_bonds.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'expected_order': expected_order,
                        'actual_order': 0
                    })
                # æ£€æŸ¥é”®ç±»å‹ä¸åŒ¹é…
                elif actual_order != expected_order:
                    type_mismatches.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'expected_order': expected_order,
                        'actual_order': actual_order
                    })
    
    if len(all_potential_bonds) == 0:
        return {
            'mean_deviation_pct': 0.0,
            'max_deviation_pct': 0.0,
            'missing_bond_count': 0,
            'missing_bond_ratio': 0.0,
            'continuity_score': 1.0,
            'overall_mean_deviation_pct': 0.0,
            'type_mismatch_count': 0,
            'type_mismatch_ratio': 0.0
        }
    
    # è®¡ç®—æ‰€æœ‰åº”è¯¥å½¢æˆé”®çš„åŸå­å¯¹çš„åå·®ï¼ˆåŒ…æ‹¬å·²å½¢æˆé”®çš„ï¼‰
    all_deviations = [bond['deviation_pct'] for bond in all_potential_bonds]
    overall_mean_deviation = np.mean(all_deviations)
    overall_max_deviation = np.max(all_deviations)
    
    # è®¡ç®—ç¼ºå¤±é”®çš„ç»Ÿè®¡ä¿¡æ¯
    if len(missing_bonds) > 0:
        missing_deviations = [bond['deviation_pct'] for bond in missing_bonds]
        mean_deviation = np.mean(missing_deviations)
        max_deviation = np.max(missing_deviations)
    else:
        mean_deviation = 0.0
        max_deviation = 0.0
    
    missing_bond_ratio = len(missing_bonds) / len(all_potential_bonds) if len(all_potential_bonds) > 0 else 0.0
    type_mismatch_ratio = len(type_mismatches) / len(all_potential_bonds) if len(all_potential_bonds) > 0 else 0.0
    
    # è®¡ç®—è¿ç»­æ€§åˆ†æ•°ï¼ˆç»¼åˆè€ƒè™‘æ‰€æœ‰åº”è¯¥å½¢æˆé”®çš„åŸå­å¯¹çš„åå·®ã€ç¼ºå¤±é”®æ¯”ä¾‹ã€é”®ç±»å‹ä¸åŒ¹é…æ¯”ä¾‹ï¼‰
    # ä½¿ç”¨æ•´ä½“å¹³å‡åå·®çš„å½’ä¸€åŒ–ç‰ˆæœ¬
    # å‡è®¾æœ€å¤§åˆç†åå·®ä¸º30%ï¼Œè¶…è¿‡30%è®¤ä¸ºä¸¥é‡åç¦»
    normalized_deviation = min(abs(overall_mean_deviation) / 30.0, 1.0)
    
    # ç»¼åˆè€ƒè™‘åå·®ã€ç¼ºå¤±é”®æ¯”ä¾‹ã€é”®ç±»å‹ä¸åŒ¹é…æ¯”ä¾‹
    continuity_score = 1.0 - (0.4 * normalized_deviation + 0.3 * missing_bond_ratio + 0.3 * type_mismatch_ratio)
    continuity_score = max(0.0, continuity_score)  # ç¡®ä¿åˆ†æ•°åœ¨[0, 1]èŒƒå›´å†…
    
    return {
        'mean_deviation_pct': mean_deviation,
        'max_deviation_pct': max_deviation,
        'missing_bond_count': len(missing_bonds),
        'missing_bond_ratio': missing_bond_ratio,
        'continuity_score': continuity_score,
        'total_potential_bonds': len(all_potential_bonds),
        'overall_mean_deviation_pct': overall_mean_deviation,
        'overall_max_deviation_pct': overall_max_deviation,
        'type_mismatch_count': len(type_mismatches),
        'type_mismatch_ratio': type_mismatch_ratio
    }


def analyze_bonds(molecule_dir, output_dir=None, strict_margin1=15, strict_margin2=10, strict_margin3=6):
    """
    åˆ†æåˆ†å­çš„é”®å’Œè¿é€šæ€§
    
    Args:
        molecule_dir: åŒ…å« .npz æ–‡ä»¶çš„ç›®å½•
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
        strict_margin1: ä¸¥æ ¼margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤15pm
        strict_margin2: ä¸¥æ ¼margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤10pm
        strict_margin3: ä¸¥æ ¼margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤6pm
    
    Returns:
        dict: åŒ…å«é”®å’Œè¿é€šæ€§åˆ†æç»“æœçš„å­—å…¸
    """
    from pathlib import Path
    from tqdm import tqdm
    from funcmol.evaluation.utils_evaluation import load_molecules_from_npz, atom_decoder_dict, margin1
    from funcmol.evaluation.structure_evaluation import compute_min_distances
    
    molecule_dir = Path(molecule_dir)
    npz_files = sorted(molecule_dir.glob("generated_*.npz"))
    
    print(f"æ‰¾åˆ° {len(npz_files)} ä¸ª .npz åˆ†å­æ–‡ä»¶")
    
    atom_decoder = atom_decoder_dict['qm9_with_h']
    dataset_info = {'name': 'qm9'}
    
    # å­˜å‚¨ç»Ÿè®¡æ•°æ®
    num_components_list = []
    is_connected_list = []
    bond_lengths = []
    
    # è¿ç»­æ€§æŒ‡æ ‡ç»Ÿè®¡
    all_missing_bond_deviations = []
    all_continuity_scores = []
    all_missing_bond_ratios = []
    all_mean_deviations = []
    all_max_deviations = []
    all_overall_mean_deviations = []
    all_overall_max_deviations = []
    all_type_mismatch_counts = []
    all_type_mismatch_ratios = []
    
    print("åˆ†æåˆ†å­é”®å’Œè¿é€šæ€§...")
    for npz_file in tqdm(npz_files, desc="å¤„ç†åˆ†å­"):
        try:
            # åŠ è½½åˆ†å­
            data = np.load(npz_file)
            coords = data['coords']  # (N, 3)
            types = data['types']    # (N,)
            
            # è½¬æ¢ä¸ºtorchå¼ é‡
            positions = torch.tensor(coords, dtype=torch.float32)
            atom_types = torch.tensor(types, dtype=torch.long)
            
            # è¿‡æ»¤æ‰å¡«å……çš„åŸå­
            valid_mask = atom_types != -1
            if not valid_mask.any():
                continue
            
            positions = positions[valid_mask]
            atom_types = atom_types[valid_mask]
            
            # æ„å»ºé”®ç±»å‹çŸ©é˜µ
            _, _, bond_types = build_xae_molecule(
                positions=positions,
                atom_types=atom_types,
                dataset_info=dataset_info,
                atom_decoder=atom_decoder
            )
            
            # æ£€æŸ¥è¿é€šæ€§
            num_components, is_connected = check_connectivity(bond_types)
            num_components_list.append(num_components)
            is_connected_list.append(is_connected)
            
            # è®¡ç®—è¿ç»­æ€§æŒ‡æ ‡ï¼ˆä½¿ç”¨ä¸¥æ ¼æ ‡å‡†ï¼‰
            continuity_metrics = compute_connectivity_continuity_score(
                positions, atom_types, bond_types, atom_decoder, dataset_info,
                strict_margin1=strict_margin1,
                strict_margin2=strict_margin2,
                strict_margin3=strict_margin3
            )
            all_continuity_scores.append(continuity_metrics['continuity_score'])
            all_missing_bond_ratios.append(continuity_metrics['missing_bond_ratio'])
            all_mean_deviations.append(continuity_metrics['mean_deviation_pct'])
            all_max_deviations.append(continuity_metrics['max_deviation_pct'])
            all_overall_mean_deviations.append(continuity_metrics['overall_mean_deviation_pct'])
            all_overall_max_deviations.append(continuity_metrics['overall_max_deviation_pct'])
            all_type_mismatch_counts.append(continuity_metrics['type_mismatch_count'])
            all_type_mismatch_ratios.append(continuity_metrics['type_mismatch_ratio'])
            
            # æ”¶é›†ç¼ºå¤±é”®çš„åå·®
            missing_bonds = compute_missing_bond_deviations_strict(
                positions, atom_types, bond_types, atom_decoder, dataset_info,
                strict_margin1=strict_margin1,
                strict_margin2=strict_margin2,
                strict_margin3=strict_margin3
            )
            if missing_bonds:
                missing_deviations = [bond['deviation_pct'] for bond in missing_bonds]
                all_missing_bond_deviations.extend(missing_deviations)
            
            # è®¡ç®—é”®é•¿ï¼ˆåªè®¡ç®—æœ‰é”®çš„åŸå­å¯¹ï¼‰
            distances = torch.cdist(positions, positions, p=2)
            triu_mask = torch.triu(torch.ones_like(bond_types, dtype=torch.bool), diagonal=1)
            bond_mask = (bond_types > 0) & triu_mask
            
            if bond_mask.any():
                bond_distances = distances[bond_mask]
                bond_lengths.extend(bond_distances.cpu().numpy())
            
        except Exception as e:
            print(f"\nå¤„ç†æ–‡ä»¶ {npz_file} æ—¶å‡ºé”™: {e}")
            continue
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    num_components_list = np.array(num_components_list)
    is_connected_list = np.array(is_connected_list)
    bond_lengths = np.array(bond_lengths) if bond_lengths else np.array([])
    
    # è¿ç»­æ€§æŒ‡æ ‡æ•°ç»„
    all_continuity_scores = np.array(all_continuity_scores) if all_continuity_scores else np.array([])
    all_missing_bond_ratios = np.array(all_missing_bond_ratios) if all_missing_bond_ratios else np.array([])
    all_mean_deviations = np.array(all_mean_deviations) if all_mean_deviations else np.array([])
    all_max_deviations = np.array(all_max_deviations) if all_max_deviations else np.array([])
    all_missing_bond_deviations = np.array(all_missing_bond_deviations) if all_missing_bond_deviations else np.array([])
    all_overall_mean_deviations = np.array(all_overall_mean_deviations) if all_overall_mean_deviations else np.array([])
    all_overall_max_deviations = np.array(all_overall_max_deviations) if all_overall_max_deviations else np.array([])
    all_type_mismatch_counts = np.array(all_type_mismatch_counts) if all_type_mismatch_counts else np.array([])
    all_type_mismatch_ratios = np.array(all_type_mismatch_ratios) if all_type_mismatch_ratios else np.array([])
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print("\n" + "="*60)
    print("é”®å’Œè¿é€šæ€§åˆ†æç»“æœ")
    print("="*60)
    
    print(f"\nğŸ”— é”®é•¿ç»Ÿè®¡:")
    if len(bond_lengths) > 0:
        print(f"  æ€»é”®æ•°: {len(bond_lengths)}")
        print(f"  å¹³å‡é”®é•¿: {bond_lengths.mean():.4f} Ã…")
        print(f"  ä¸­ä½æ•°é”®é•¿: {np.median(bond_lengths):.4f} Ã…")
        print(f"  é”®é•¿èŒƒå›´: {bond_lengths.min():.4f} - {bond_lengths.max():.4f} Ã…")
    else:
        print("  æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•é”®ï¼")
    
    print(f"\nğŸŒ åˆ†å­è¿é€šæ€§ç»Ÿè®¡:")
    print(f"  è¿é€šåˆ†å­æ•°ï¼ˆè¿é€šåˆ†é‡=1ï¼‰: {is_connected_list.sum()}")
    print(f"  éè¿é€šåˆ†å­æ•°ï¼ˆè¿é€šåˆ†é‡>1ï¼‰: {(~is_connected_list).sum()}")
    print(f"  è¿é€šåˆ†å­æ¯”ä¾‹: {is_connected_list.sum() / len(is_connected_list) * 100:.2f}%")
    print(f"  å¹³å‡è¿é€šåˆ†é‡æ•°: {num_components_list.mean():.2f}")
    print(f"  æœ€å¤§è¿é€šåˆ†é‡æ•°: {num_components_list.max()}")
    
    print(f"\nğŸ”— è¿ç»­æ€§è¿é€šæ€§æŒ‡æ ‡ (ä½¿ç”¨ä¸¥æ ¼æ ‡å‡†: margin1={strict_margin1}pm, margin2={strict_margin2}pm, margin3={strict_margin3}pm):")
    if len(all_continuity_scores) > 0:
        print(f"  å¹³å‡è¿ç»­æ€§åˆ†æ•°: {all_continuity_scores.mean():.4f} (1.0=å®Œç¾è¿é€š)")
        print(f"  ä¸­ä½æ•°è¿ç»­æ€§åˆ†æ•°: {np.median(all_continuity_scores):.4f}")
        print(f"  è¿ç»­æ€§åˆ†æ•°èŒƒå›´: {all_continuity_scores.min():.4f} - {all_continuity_scores.max():.4f}")
        print(f"  è¯´æ˜: åˆ†æ•°åŸºäºæ‰€æœ‰åº”è¯¥å½¢æˆé”®çš„åŸå­å¯¹çš„æ•´ä½“åå·®ã€ç¼ºå¤±é”®æ¯”ä¾‹å’Œé”®ç±»å‹ä¸åŒ¹é…æ¯”ä¾‹è®¡ç®—")
        
        print(f"\n  æ•´ä½“åå·®ç»Ÿè®¡ï¼ˆæ‰€æœ‰åº”è¯¥å½¢æˆé”®çš„åŸå­å¯¹ï¼Œæ— è®ºæ˜¯å¦å·²å½¢æˆé”®ï¼‰:")
        if len(all_overall_mean_deviations) > 0:
            print(f"    å¹³å‡æ•´ä½“åå·®ç™¾åˆ†æ¯”: {all_overall_mean_deviations.mean():.4f}%")
            print(f"    ä¸­ä½æ•°æ•´ä½“åå·®ç™¾åˆ†æ¯”: {np.median(all_overall_mean_deviations):.4f}%")
        
        print(f"\n  ç¼ºå¤±é”®ç»Ÿè®¡ï¼ˆåº”è¯¥å½¢æˆé”®ä½†æœªå½¢æˆé”®çš„åŸå­å¯¹ï¼‰:")
        if len(all_missing_bond_ratios) > 0:
            print(f"    å¹³å‡ç¼ºå¤±é”®æ¯”ä¾‹: {all_missing_bond_ratios.mean():.4f} ({all_missing_bond_ratios.mean()*100:.2f}%)")
            print(f"    ä¸­ä½æ•°ç¼ºå¤±é”®æ¯”ä¾‹: {np.median(all_missing_bond_ratios):.4f} ({np.median(all_missing_bond_ratios)*100:.2f}%)")
        
        if len(all_missing_bond_deviations) > 0:
            print(f"    æ‰€æœ‰ç¼ºå¤±é”®çš„åå·®åˆ†å¸ƒ:")
            print(f"      æ€»ç¼ºå¤±é”®æ•°: {len(all_missing_bond_deviations)}")
            print(f"      å¹³å‡åå·®: {all_missing_bond_deviations.mean():.4f}%")
            print(f"      ä¸­ä½æ•°åå·®: {np.median(all_missing_bond_deviations):.4f}%")
        
        print(f"\n  é”®ç±»å‹ä¸åŒ¹é…ç»Ÿè®¡:")
        if len(all_type_mismatch_counts) > 0:
            print(f"    å¹³å‡é”®ç±»å‹ä¸åŒ¹é…æ•°: {all_type_mismatch_counts.mean():.2f}")
            print(f"    å¹³å‡é”®ç±»å‹ä¸åŒ¹é…æ¯”ä¾‹: {all_type_mismatch_ratios.mean():.4f} ({all_type_mismatch_ratios.mean()*100:.2f}%)")
    
    return {
        'bond_lengths': bond_lengths,
        'num_components': num_components_list,
        'is_connected': is_connected_list,
        'continuity_scores': all_continuity_scores,
        'missing_bond_ratios': all_missing_bond_ratios,
        'mean_deviations': all_mean_deviations,
        'max_deviations': all_max_deviations,
        'missing_bond_deviations': all_missing_bond_deviations,
        'overall_mean_deviations': all_overall_mean_deviations,
        'overall_max_deviations': all_overall_max_deviations,
        'type_mismatch_counts': all_type_mismatch_counts,
        'type_mismatch_ratios': all_type_mismatch_ratios
    }

