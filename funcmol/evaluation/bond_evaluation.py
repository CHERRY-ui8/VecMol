"""
é”®ç›¸å…³è¯„ä¼°æ¨¡å—
åŒ…å«é”®åˆ¤æ–­ã€é”®é•¿åˆ†æã€ç¼ºå¤±é”®æ£€æµ‹ã€è¿é€šæ€§åˆ†æç­‰åŠŸèƒ½
"""

import torch
import numpy as np
from pathlib import Path
from tqdm import tqdm

from funcmol.evaluation.utils_evaluation import (
    bonds1, bonds2, bonds3,
    margin1, margin2, margin3,
    atom_decoder_dict
)


def get_bond_order(atom1, atom2, distance, check_exists=False, 
                   margin1_val=None, margin2_val=None, margin3_val=None):
    """
    åˆ¤æ–­é”®ç±»å‹ï¼ˆå•é”®/åŒé”®/ä¸‰é”®ï¼‰
    
    Args:
        atom1: åŸå­1ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼Œå¦‚ 'C', 'H'ï¼‰
        atom2: åŸå­2ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        distance: åŸå­é—´è·ç¦»ï¼ˆå•ä½ï¼šÃ…ï¼‰
        check_exists: æ˜¯å¦æ£€æŸ¥åŸå­å¯¹æ˜¯å¦å­˜åœ¨æ ‡å‡†é”®é•¿
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        int: é”®ç±»å‹ (0=æ— é”®, 1=å•é”®, 2=åŒé”®, 3=ä¸‰é”®)
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    distance_pm = 100 * distance  # è½¬æ¢ä¸ºpmå•ä½
    
    # æ£€æŸ¥åŸå­å¯¹æ˜¯å¦å­˜åœ¨æ ‡å‡†é”®é•¿
    if check_exists:
        if atom1 not in bonds1:
            return 0
        if atom2 not in bonds1[atom1]:
            return 0
    
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦åœ¨å•é”®èŒƒå›´å†…
    if distance_pm < bonds1[atom1][atom2] + margin1_val:
        # æ£€æŸ¥æ˜¯å¦åœ¨åŒé”®èŒƒå›´å†…
        if atom1 in bonds2 and atom2 in bonds2[atom1]:
            thr_bond2 = bonds2[atom1][atom2] + margin2_val
            if distance_pm < thr_bond2:
                # æ£€æŸ¥æ˜¯å¦åœ¨ä¸‰é”®èŒƒå›´å†…
                if atom1 in bonds3 and atom2 in bonds3[atom1]:
                    thr_bond3 = bonds3[atom1][atom2] + margin3_val
                    if distance_pm < thr_bond3:
                        return 3  # ä¸‰é”®
                return 2  # åŒé”®
        return 1  # å•é”®
    return 0  # æ— é”®


def get_expected_bond_order(atom1, atom2, distance, 
                            margin1_val=None, margin2_val=None, margin3_val=None):
    """
    æ ¹æ®è·ç¦»åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹ï¼ˆç”¨äºæ£€æµ‹ç¼ºå¤±é”®å’Œé”®ç±»å‹ä¸åŒ¹é…ï¼‰
    
    æŒ‰ç…§ä»é«˜åˆ°ä½çš„ä¼˜å…ˆçº§æ£€æŸ¥ï¼šä¸‰é”® -> åŒé”® -> å•é”®
    
    Args:
        atom1: åŸå­1ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        atom2: åŸå­2ç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        distance: åŸå­é—´è·ç¦»ï¼ˆå•ä½ï¼šÃ…ï¼‰
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        tuple: (expected_order, standard_dist, threshold)
            - expected_order: æœŸæœ›çš„é”®ç±»å‹ (0/1/2/3)
            - standard_dist: å¯¹åº”çš„æ ‡å‡†é”®é•¿ï¼ˆå•ä½ï¼šÃ…ï¼‰
            - threshold: åˆ¤æ–­é˜ˆå€¼ï¼ˆå•ä½ï¼šÃ…ï¼‰
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    distance_pm = 100 * distance  # è½¬æ¢ä¸ºpmå•ä½
    
    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥ï¼šä¸‰é”® -> åŒé”® -> å•é”®
    # æ£€æŸ¥ä¸‰é”®
    if atom1 in bonds3 and atom2 in bonds3[atom1]:
        standard_dist_pm = bonds3[atom1][atom2]
        threshold_pm = standard_dist_pm + margin3_val
        if distance_pm < threshold_pm:
            return 3, standard_dist_pm / 100.0, threshold_pm / 100.0
    
    # æ£€æŸ¥åŒé”®
    if atom1 in bonds2 and atom2 in bonds2[atom1]:
        standard_dist_pm = bonds2[atom1][atom2]
        threshold_pm = standard_dist_pm + margin2_val
        if distance_pm < threshold_pm:
            return 2, standard_dist_pm / 100.0, threshold_pm / 100.0
    
    # æ£€æŸ¥å•é”®
    if atom1 in bonds1 and atom2 in bonds1[atom1]:
        standard_dist_pm = bonds1[atom1][atom2]
        threshold_pm = standard_dist_pm + margin1_val
        if distance_pm < threshold_pm:
            return 1, standard_dist_pm / 100.0, threshold_pm / 100.0
    
    return 0, None, None


def build_xae_molecule(positions, atom_types, dataset_info, atom_decoder, 
                       margin1_val=None, margin2_val=None, margin3_val=None):
    """
    æ„å»ºåˆ†å­é”®çŸ©é˜µ
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        tuple: (X, A, E)
            - X: åŸå­ç±»å‹ [N]
            - A: é‚»æ¥çŸ©é˜µ [N, N] (bool)
            - E: é”®ç±»å‹çŸ©é˜µ [N, N] (int)
    """
    n = positions.shape[0]
    X = atom_types
    A = torch.zeros((n, n), dtype=torch.bool)
    E = torch.zeros((n, n), dtype=torch.int)
    
    pos = positions.unsqueeze(0)
    dists = torch.cdist(pos, pos, p=2).squeeze(0)
    
    for i in range(n):
        for j in range(i):
            pair = sorted([atom_types[i], atom_types[j]])
            if dataset_info['name'] == 'qm9':
                order = get_bond_order(
                    atom_decoder[pair[0]], 
                    atom_decoder[pair[1]], 
                    dists[i, j],
                    margin1_val=margin1_val,
                    margin2_val=margin2_val,
                    margin3_val=margin3_val
                )
            elif dataset_info['name'] == 'geom':
                # å¯¹äºgeomæ•°æ®é›†ï¼Œä½¿ç”¨limit_bonds_to_one
                order = get_bond_order(
                    atom_decoder[pair[0]], 
                    atom_decoder[pair[1]], 
                    dists[i, j],
                    check_exists=True,
                    margin1_val=margin1_val,
                    margin2_val=margin2_val,
                    margin3_val=margin3_val
                )
                if order > 1:
                    order = 1  # é™åˆ¶ä¸ºå•é”®
            
            if order > 0:
                A[i, j] = 1
                A[j, i] = 1  # ç¡®ä¿é‚»æ¥çŸ©é˜µå¯¹ç§°
                E[i, j] = order
                E[j, i] = order  # ç¡®ä¿é”®ç±»å‹çŸ©é˜µå¯¹ç§°
    
    return X, A, E


def check_connectivity(bond_types):
    """
    æ£€æŸ¥åˆ†å­çš„è¿é€šæ€§ï¼ˆä½¿ç”¨DFSï¼‰
    
    Args:
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
    
    Returns:
        tuple: (num_components, is_connected)
            - num_components: è¿é€šåˆ†é‡æ•°
            - is_connected: æ˜¯å¦è¿é€šï¼ˆè¿é€šåˆ†é‡æ•°==1ï¼‰
    """
    n_atoms = bond_types.shape[0]
    if n_atoms == 0:
        return 0, False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹
    has_edges = (bond_types > 0).any()
    if not has_edges:
        # æ²¡æœ‰è¾¹ï¼Œæ¯ä¸ªåŸå­éƒ½æ˜¯ç‹¬ç«‹çš„è¿é€šåˆ†é‡
        # å¦‚æœåªæœ‰ä¸€ä¸ªåŸå­ï¼Œå®ƒè¢«è®¤ä¸ºæ˜¯è¿é€šçš„ï¼ˆå•ä¸ªåŸå­æ˜¯ä¸€ä¸ªå®Œæ•´çš„åˆ†å­ï¼‰
        is_connected = (n_atoms == 1)
        return n_atoms, is_connected
    
    # ä½¿ç”¨DFSè®¡ç®—è¿é€šåˆ†é‡
    visited = torch.zeros(n_atoms, dtype=torch.bool)
    num_components = 0
    
    def dfs(node):
        """æ·±åº¦ä¼˜å…ˆæœç´¢"""
        visited[node] = True
        neighbors = torch.nonzero(bond_types[node] > 0, as_tuple=False).squeeze(-1)
        for neighbor in neighbors:
            neighbor_idx = neighbor.item()
            if neighbor_idx != node and not visited[neighbor_idx]:
                dfs(neighbor_idx)
    
    # éå†æ‰€æœ‰æœªè®¿é—®çš„èŠ‚ç‚¹
    for i in range(n_atoms):
        if not visited[i]:
            dfs(i)
            num_components += 1
    
    is_connected = (num_components == 1)
    return num_components, is_connected


def check_connectivity_with_labels(bond_types):
    """
    æ£€æŸ¥åˆ†å­çš„è¿é€šæ€§å¹¶è¿”å›æ¯ä¸ªåŸå­æ‰€å±çš„è¿é€šåˆ†é‡ID
    
    Args:
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        
    Returns:
        tuple: (num_components, component_ids)
            - num_components: è¿é€šåˆ†é‡æ•°
            - component_ids: æ¯ä¸ªåŸå­æ‰€å±çš„è¿é€šåˆ†é‡ID [N]
    """
    n_atoms = bond_types.shape[0]
    if n_atoms == 0:
        return 0, torch.zeros(0, dtype=torch.long)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹
    has_edges = (bond_types > 0).any()
    if not has_edges:
        # æ²¡æœ‰è¾¹ï¼Œæ¯ä¸ªåŸå­éƒ½æ˜¯ç‹¬ç«‹çš„è¿é€šåˆ†é‡
        component_ids = torch.arange(n_atoms, dtype=torch.long)
        return n_atoms, component_ids
    
    # ä½¿ç”¨DFSè®¡ç®—è¿é€šåˆ†é‡å¹¶æ ‡è®°
    visited = torch.zeros(n_atoms, dtype=torch.bool)
    component_ids = torch.zeros(n_atoms, dtype=torch.long)
    current_component = 0
    
    def dfs_label(node, comp_id):
        """æ·±åº¦ä¼˜å…ˆæœç´¢å¹¶æ ‡è®°è¿é€šåˆ†é‡"""
        visited[node] = True
        component_ids[node] = comp_id
        neighbors = torch.nonzero(bond_types[node] > 0, as_tuple=False).squeeze(-1)
        for neighbor in neighbors:
            neighbor_idx = neighbor.item()
            if neighbor_idx != node and not visited[neighbor_idx]:
                dfs_label(neighbor_idx, comp_id)
    
    # éå†æ‰€æœ‰æœªè®¿é—®çš„èŠ‚ç‚¹
    for i in range(n_atoms):
        if not visited[i]:
            dfs_label(i, current_component)
            current_component += 1
    
    num_components = current_component
    return num_components, component_ids


def compute_missing_bond_deviations_strict(positions, atom_types, bond_types, atom_decoder, dataset_info, 
                                            strict_margin1, strict_margin2, strict_margin3):
    """
    è®¡ç®—åº”è¯¥å½¢æˆé”®ä½†æœªå½¢æˆé”®çš„åŸå­å¯¹çš„è·ç¦»åå·®ï¼ˆä½¿ç”¨ä¸¥æ ¼æ ‡å‡†ï¼Œè€ƒè™‘æ‰€æœ‰é”®ç±»å‹ï¼‰
    
    ä¼˜åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨ get_expected_bond_order() æ¥åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹ï¼Œä¸ä»…æ£€æµ‹å•é”®ç¼ºå¤±ï¼Œ
    è¿˜æ£€æµ‹åŒé”®/ä¸‰é”®ç¼ºå¤±ï¼Œä»¥åŠé”®ç±»å‹ä¸åŒ¹é…çš„æƒ…å†µã€‚
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        strict_margin1: ä¸¥æ ¼margin1å€¼ï¼ˆpmå•ä½ï¼‰
        strict_margin2: ä¸¥æ ¼margin2å€¼ï¼ˆpmå•ä½ï¼‰
        strict_margin3: ä¸¥æ ¼margin3å€¼ï¼ˆpmå•ä½ï¼‰
    
    Returns:
        missing_bonds: List of dicts with keys: pair, actual_dist, standard_dist, deviation_pct, 
                      expected_order, actual_order, is_type_mismatch
    """
    n = positions.shape[0]
    dists = torch.cdist(positions, positions, p=2)
    missing_bonds = []
    
    # è®¡ç®—è¿é€šåˆ†é‡ï¼Œç”¨äºæ£€æµ‹è·¨åˆ†é‡çš„ç¼ºå¤±é”®
    _, component_ids = check_connectivity_with_labels(bond_types)
    
    for i in range(n):
        for j in range(i):
            atom1_str = atom_decoder[atom_types[i].item()]
            atom2_str = atom_decoder[atom_types[j].item()]
            
            # æ£€æŸ¥æ ‡å‡†é”®é•¿ï¼ˆéœ€è¦æŒ‰å­—æ¯é¡ºåºæ’åºï¼‰
            pair = sorted([atom1_str, atom2_str])
            atom1_key = pair[0]
            atom2_key = pair[1]
            
            # ä½¿ç”¨ä¼˜åŒ–åçš„å‡½æ•°åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹
            actual_dist = dists[i, j].item()
            expected_order, standard_dist, threshold = get_expected_bond_order(
                atom1_key, atom2_key, actual_dist,
                margin1_val=strict_margin1,
                margin2_val=strict_margin2,
                margin3_val=strict_margin3
            )
            
            if expected_order > 0:  # åº”è¯¥å½¢æˆæŸç§ç±»å‹çš„é”®
                actual_order = bond_types[i, j].item()
                is_cross_component = (component_ids[i] != component_ids[j])
                has_bond = (actual_order > 0)
                deviation_pct = (actual_dist - standard_dist) / standard_dist * 100
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å½¢æˆé”®ä½†æœªå½¢æˆï¼Œæˆ–é”®ç±»å‹ä¸åŒ¹é…
                is_missing = (not has_bond) or is_cross_component
                is_type_mismatch = (has_bond and actual_order != expected_order)
                
                # æƒ…å†µ1ï¼šæ²¡æœ‰é”®æˆ–è·¨åˆ†é‡
                if is_missing:
                    missing_bonds.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'atom1': atom1_str,
                        'atom2': atom2_str,
                        'expected_order': expected_order,
                        'actual_order': actual_order,
                        'is_cross_component': is_cross_component,
                        'is_type_mismatch': False,
                        'has_bond': has_bond
                    })
                # æƒ…å†µ2ï¼šé”®ç±»å‹ä¸åŒ¹é…ï¼ˆä¾‹å¦‚åº”è¯¥å½¢æˆåŒé”®ä½†åªå½¢æˆäº†å•é”®ï¼‰
                elif is_type_mismatch:
                    missing_bonds.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'atom1': atom1_str,
                        'atom2': atom2_str,
                        'expected_order': expected_order,
                        'actual_order': actual_order,
                        'is_cross_component': False,
                        'is_type_mismatch': True,
                        'has_bond': True
                    })
                # æƒ…å†µ3ï¼šæœ‰é”®ä½†è·ç¦»åç¦»æ ‡å‡†å€¼è¶…è¿‡5%ï¼ˆç»“æ„ä¸ç†æƒ³ï¼‰
                elif has_bond and abs(deviation_pct) > 5.0:
                    # ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼æ¥æ£€æµ‹åç¦»æ ‡å‡†å€¼çš„é”®
                    relaxed_threshold = threshold * 1.2  # æ”¾å®½20%
                    if actual_dist < relaxed_threshold:
                        missing_bonds.append({
                            'pair': (i, j),
                            'actual_dist': actual_dist,
                            'standard_dist': standard_dist,
                            'deviation_pct': deviation_pct,
                            'atom1': atom1_str,
                            'atom2': atom2_str,
                            'expected_order': expected_order,
                            'actual_order': actual_order,
                            'is_cross_component': False,
                            'is_type_mismatch': False,
                            'has_bond': True
                        })
    
    return missing_bonds


def compute_bond_type_mismatches(positions, atom_types, bond_types, atom_decoder, dataset_info,
                                  margin1_val=None, margin2_val=None, margin3_val=None):
    """
    æ£€æµ‹é”®ç±»å‹ä¸åŒ¹é…çš„æƒ…å†µï¼ˆå®é™…é”®ç±»å‹ä¸æœŸæœ›é”®ç±»å‹ä¸ä¸€è‡´ï¼‰
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        mismatches: List of dicts with keys: pair, actual_dist, expected_order, actual_order, deviation_pct
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    n = positions.shape[0]
    dists = torch.cdist(positions, positions, p=2)
    mismatches = []
    
    for i in range(n):
        for j in range(i):
            if bond_types[i, j] > 0:  # å½“å‰åˆ¤æ–­ä¸ºæœ‰é”®
                atom1_str = atom_decoder[atom_types[i].item()]
                atom2_str = atom_decoder[atom_types[j].item()]
                pair = sorted([atom1_str, atom2_str])
                atom1_key = pair[0]
                atom2_key = pair[1]
                
                # åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹
                actual_dist = dists[i, j].item()
                expected_order, standard_dist, _ = get_expected_bond_order(
                    atom1_key, atom2_key, actual_dist,
                    margin1_val=margin1_val,
                    margin2_val=margin2_val,
                    margin3_val=margin3_val
                )
                
                actual_order = bond_types[i, j].item()
                
                # å¦‚æœæœŸæœ›é”®ç±»å‹ä¸å®é™…é”®ç±»å‹ä¸åŒ¹é…
                if expected_order > 0 and actual_order != expected_order:
                    deviation_pct = (actual_dist - standard_dist) / standard_dist * 100
                    mismatches.append({
                        'pair': (i, j),
                        'actual_dist': actual_dist,
                        'standard_dist': standard_dist,
                        'deviation_pct': deviation_pct,
                        'atom1': atom1_str,
                        'atom2': atom2_str,
                        'expected_order': expected_order,
                        'actual_order': actual_order
                    })
    
    return mismatches


def compute_excessive_bond_deviations(positions, atom_types, bond_types, atom_decoder, dataset_info, 
                                       margin1_val=None, margin2_val=None, margin3_val=None):
    """
    è®¡ç®—ä¸åº”è¯¥å½¢æˆé”®ä½†å½¢æˆé”®çš„åŸå­å¯¹ï¼ˆè·ç¦»è¿‡è¿œä½†ä»è¢«åˆ¤æ–­ä¸ºæœ‰é”®ï¼‰
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        atom_decoder: åŸå­ç±»å‹è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin1
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin2
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€margin3
    
    Returns:
        excessive_bonds: List of dicts with keys: pair, actual_dist, standard_dist, deviation_pct, bond_order
    """
    if margin1_val is None:
        margin1_val = margin1
    if margin2_val is None:
        margin2_val = margin2
    if margin3_val is None:
        margin3_val = margin3
    
    n = positions.shape[0]
    dists = torch.cdist(positions, positions, p=2)
    excessive_bonds = []
    
    for i in range(n):
        for j in range(i):
            if bond_types[i, j] > 0:  # å½“å‰åˆ¤æ–­ä¸ºæœ‰é”®
                atom1_str = atom_decoder[atom_types[i].item()]
                atom2_str = atom_decoder[atom_types[j].item()]
                pair = sorted([atom1_str, atom2_str])
                atom1_key = pair[0]
                atom2_key = pair[1]
                
                # åˆ¤æ–­æœŸæœ›çš„é”®ç±»å‹
                actual_dist = dists[i, j].item()
                expected_order, standard_dist, threshold = get_expected_bond_order(
                    atom1_key, atom2_key, actual_dist,
                    margin1_val=margin1_val,
                    margin2_val=margin2_val,
                    margin3_val=margin3_val
                )
                
                # å¦‚æœè·ç¦»è¶…è¿‡åº”è¯¥å½¢æˆé”®çš„èŒƒå›´
                if expected_order == 0 or actual_dist > threshold:
                    # ä½¿ç”¨å•é”®æ ‡å‡†ä½œä¸ºå‚è€ƒ
                    if atom1_key in bonds1 and atom2_key in bonds1[atom1_key]:
                        ref_standard_dist = bonds1[atom1_key][atom2_key] / 100.0
                        deviation_pct = (actual_dist - ref_standard_dist) / ref_standard_dist * 100
                        excessive_bonds.append({
                            'pair': (i, j),
                            'actual_dist': actual_dist,
                            'standard_dist': ref_standard_dist,
                            'deviation_pct': deviation_pct,
                            'atom1': atom1_str,
                            'atom2': atom2_str,
                            'bond_order': bond_types[i, j].item()
                        })
    
    return excessive_bonds


def _analyze_bonds_with_standard(positions, atom_types, atom_decoder, dataset_info,
                                  margin1_val, margin2_val, margin3_val):
    """
    ä½¿ç”¨æŒ‡å®šæ ‡å‡†åˆ†æå•ä¸ªåˆ†å­çš„é”®å’Œè¿é€šæ€§
    
    Args:
        positions: [N, 3] åŸå­åæ ‡
        atom_types: [N] åŸå­ç±»å‹ç´¢å¼•
        atom_decoder: åŸå­è§£ç å™¨åˆ—è¡¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸
        margin1_val: margin1å€¼ï¼ˆpmå•ä½ï¼‰
        margin2_val: margin2å€¼ï¼ˆpmå•ä½ï¼‰
        margin3_val: margin3å€¼ï¼ˆpmå•ä½ï¼‰
    
    Returns:
        tuple: (num_components, is_connected, missing_bond_deviations)
    """
    # æ„å»ºé”®çŸ©é˜µ
    _, _, bond_types = build_xae_molecule(
        positions=positions,
        atom_types=atom_types,
        dataset_info=dataset_info,
        atom_decoder=atom_decoder,
        margin1_val=margin1_val,
        margin2_val=margin2_val,
        margin3_val=margin3_val
    )
    
    # è®¡ç®—è¿é€šæ€§
    num_components, is_connected = check_connectivity(bond_types)
    
    # è®¡ç®—ç¼ºå¤±é”®åå·®
    missing_bonds = compute_missing_bond_deviations_strict(
        positions, atom_types, bond_types, atom_decoder, dataset_info,
        strict_margin1=margin1_val,
        strict_margin2=margin2_val,
        strict_margin3=margin3_val
    )
    
    missing_deviations = [bond['deviation_pct'] for bond in missing_bonds] if missing_bonds else []
    
    return num_components, is_connected, missing_deviations


def _print_standard_results(standard_name, margin1, margin2, margin3,
                           num_components, is_connected, missing_deviations):
    """
    æ‰“å°å•ä¸ªæ ‡å‡†çš„åˆ†æç»“æœ
    
    Args:
        standard_name: æ ‡å‡†åç§°ï¼ˆå¦‚ 'ä¸¥æ ¼æ ‡å‡†'ï¼‰
        margin1/2/3: marginå€¼
        num_components: è¿é€šåˆ†é‡æ•°æ•°ç»„
        is_connected: è¿é€šæ€§å¸ƒå°”æ•°ç»„
        missing_deviations: ç¼ºå¤±é”®åå·®åˆ—è¡¨
    """
    print(f"\nğŸ”— {standard_name} (margin1={margin1}pm, margin2={margin2}pm, margin3={margin3}pm):")
    print(f"  è¿é€šæ€§:")
    print(f"    è¿é€šåˆ†å­æ•°: {is_connected.sum()}")
    print(f"    éè¿é€šåˆ†å­æ•°: {(~is_connected).sum()}")
    print(f"    è¿é€šåˆ†å­æ¯”ä¾‹: {is_connected.sum() / len(is_connected) * 100:.2f}%")
    print(f"    å¹³å‡è¿é€šåˆ†é‡æ•°: {num_components.mean():.2f}")
    print(f"    æœ€å¤§è¿é€šåˆ†é‡æ•°: {num_components.max()}")
    if len(missing_deviations) > 0:
        print(f"  ç¼ºå¤±é”®åå·®:")
        print(f"    æ€»ç¼ºå¤±é”®æ•°: {len(missing_deviations)}")
        print(f"    å¹³å‡åå·®: {np.mean(missing_deviations):.4f}%")
        print(f"    ä¸­ä½æ•°åå·®: {np.median(missing_deviations):.4f}%")
    else:
        print(f"  ç¼ºå¤±é”®åå·®: æ— ç¼ºå¤±é”®")


def analyze_bonds(molecule_dir,
                 strict_margin1, strict_margin2, strict_margin3,
                 medium_margin1, medium_margin2, medium_margin3,
                 relaxed_margin1, relaxed_margin2, relaxed_margin3,
                 output_dir=None):
    """
    åˆ†æåˆ†å­çš„é”®å’Œè¿é€šæ€§ï¼ˆä½¿ç”¨ä¸‰ç§æ ‡å‡†ï¼šstrict, medium, relaxedï¼‰
    
    Args:
        molecule_dir: åŒ…å« .npz æ–‡ä»¶çš„ç›®å½•
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
        strict_margin1/2/3: ä¸¥æ ¼æ ‡å‡†çš„marginå€¼ï¼ˆpmå•ä½ï¼‰
        medium_margin1/2/3: ä¸­ç­‰æ ‡å‡†çš„marginå€¼ï¼ˆpmå•ä½ï¼‰
        relaxed_margin1/2/3: å®½æ¾æ ‡å‡†çš„marginå€¼ï¼ˆpmå•ä½ï¼‰
    
    Returns:
        dict: åŒ…å«é”®å’Œè¿é€šæ€§åˆ†æç»“æœçš„å­—å…¸ï¼ˆåŒ…å«ä¸‰ç§æ ‡å‡†çš„ç»“æœï¼‰
    """
    molecule_dir = Path(molecule_dir)
    npz_files = sorted(molecule_dir.glob("generated_*.npz"))
    
    print(f"æ‰¾åˆ° {len(npz_files)} ä¸ª .npz åˆ†å­æ–‡ä»¶")
    
    atom_decoder = atom_decoder_dict['qm9_with_h']
    dataset_info = {'name': 'qm9'}
    
    # å­˜å‚¨é”®é•¿ç»Ÿè®¡æ•°æ®ï¼ˆä½¿ç”¨relaxed marginæ„å»ºçš„é”®çŸ©é˜µï¼Œç”¨äºé”®é•¿ç»Ÿè®¡ï¼‰
    bond_lengths = []
    
    # ä¸‰ç§æ ‡å‡†çš„ç¼ºå¤±é”®åå·®ç»Ÿè®¡
    all_missing_bond_deviations_strict = []
    all_missing_bond_deviations_medium = []
    all_missing_bond_deviations_relaxed = []
    
    # ä¸‰ç§æ ‡å‡†çš„è¿é€šæ€§ç»Ÿè®¡
    num_components_strict = []
    is_connected_strict = []
    num_components_medium = []
    is_connected_medium = []
    num_components_relaxed = []
    is_connected_relaxed = []
    
    print("åˆ†æåˆ†å­é”®å’Œè¿é€šæ€§ï¼ˆä½¿ç”¨ä¸‰ç§æ ‡å‡†ï¼‰...")
    for npz_file in tqdm(npz_files, desc="å¤„ç†åˆ†å­"):
        try:
            # åŠ è½½åˆ†å­
            data = np.load(npz_file)
            coords = data['coords']  # (N, 3)
            types = data['types']    # (N,)
            
            # è½¬æ¢ä¸ºtorchå¼ é‡
            positions = torch.tensor(coords, dtype=torch.float32)
            atom_types = torch.tensor(types, dtype=torch.long)
            
            # è¿‡æ»¤æ‰å¡«å……çš„åŸå­
            valid_mask = atom_types != -1
            if not valid_mask.any():
                continue
            
            positions = positions[valid_mask]
            atom_types = atom_types[valid_mask]
            
            distances = torch.cdist(positions, positions, p=2)
            
            # ä¸¥æ ¼æ ‡å‡†ï¼šåˆ†æé”®å’Œè¿é€šæ€§
            num_comp_strict, is_conn_strict, missing_devs_strict = _analyze_bonds_with_standard(
                positions, atom_types, atom_decoder, dataset_info,
                strict_margin1, strict_margin2, strict_margin3
            )
            num_components_strict.append(num_comp_strict)
            is_connected_strict.append(is_conn_strict)
            all_missing_bond_deviations_strict.extend(missing_devs_strict)
            
            # ä¸­ç­‰æ ‡å‡†ï¼šåˆ†æé”®å’Œè¿é€šæ€§
            num_comp_medium, is_conn_medium, missing_devs_medium = _analyze_bonds_with_standard(
                positions, atom_types, atom_decoder, dataset_info,
                medium_margin1, medium_margin2, medium_margin3
            )
            num_components_medium.append(num_comp_medium)
            is_connected_medium.append(is_conn_medium)
            all_missing_bond_deviations_medium.extend(missing_devs_medium)
            
            # å®½æ¾æ ‡å‡†ï¼šåˆ†æé”®å’Œè¿é€šæ€§
            num_comp_relaxed, is_conn_relaxed, missing_devs_relaxed = _analyze_bonds_with_standard(
                positions, atom_types, atom_decoder, dataset_info,
                relaxed_margin1, relaxed_margin2, relaxed_margin3
            )
            num_components_relaxed.append(num_comp_relaxed)
            is_connected_relaxed.append(is_conn_relaxed)
            all_missing_bond_deviations_relaxed.extend(missing_devs_relaxed)
            
            # è®¡ç®—é”®é•¿ï¼ˆä½¿ç”¨relaxedæ ‡å‡†æ„å»ºçš„é”®çŸ©é˜µï¼Œç”¨äºé”®é•¿ç»Ÿè®¡ï¼‰
            _, _, bond_types_relaxed = build_xae_molecule(
                positions=positions,
                atom_types=atom_types,
                dataset_info=dataset_info,
                atom_decoder=atom_decoder,
                margin1_val=relaxed_margin1,
                margin2_val=relaxed_margin2,
                margin3_val=relaxed_margin3
            )
            triu_mask = torch.triu(torch.ones_like(bond_types_relaxed, dtype=torch.bool), diagonal=1)
            bond_mask = (bond_types_relaxed > 0) & triu_mask
            
            if bond_mask.any():
                bond_distances = distances[bond_mask]
                bond_lengths.extend(bond_distances.cpu().numpy())
            
        except Exception as e:
            print(f"\nå¤„ç†æ–‡ä»¶ {npz_file} æ—¶å‡ºé”™: {e}")
            continue
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    bond_lengths = np.array(bond_lengths) if bond_lengths else np.array([])
    
    num_components_strict = np.array(num_components_strict)
    is_connected_strict = np.array(is_connected_strict)
    num_components_medium = np.array(num_components_medium)
    is_connected_medium = np.array(is_connected_medium)
    num_components_relaxed = np.array(num_components_relaxed)
    is_connected_relaxed = np.array(is_connected_relaxed)
    
    # ä¸‰ç§æ ‡å‡†çš„ç¼ºå¤±é”®åå·®æ•°ç»„
    all_missing_bond_deviations_strict = np.array(all_missing_bond_deviations_strict) if all_missing_bond_deviations_strict else np.array([])
    all_missing_bond_deviations_medium = np.array(all_missing_bond_deviations_medium) if all_missing_bond_deviations_medium else np.array([])
    all_missing_bond_deviations_relaxed = np.array(all_missing_bond_deviations_relaxed) if all_missing_bond_deviations_relaxed else np.array([])
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print("\n" + "="*60)
    print("é”®å’Œè¿é€šæ€§åˆ†æç»“æœ")
    print("="*60)
    
    # æ‰“å°ä¸‰ç§æ ‡å‡†çš„ç»“æœ
    _print_standard_results("ä¸¥æ ¼æ ‡å‡†", strict_margin1, strict_margin2, strict_margin3,
                           num_components_strict, is_connected_strict, all_missing_bond_deviations_strict)
    _print_standard_results("ä¸­ç­‰æ ‡å‡†", medium_margin1, medium_margin2, medium_margin3,
                           num_components_medium, is_connected_medium, all_missing_bond_deviations_medium)
    _print_standard_results("å®½æ¾æ ‡å‡†", relaxed_margin1, relaxed_margin2, relaxed_margin3,
                           num_components_relaxed, is_connected_relaxed, all_missing_bond_deviations_relaxed)
    
    # é”®é•¿ç»Ÿè®¡ï¼ˆä½¿ç”¨relaxedæ ‡å‡†ï¼‰
    print(f"\nğŸ”— é”®é•¿ç»Ÿè®¡ï¼ˆä½¿ç”¨relaxedæ ‡å‡†ï¼‰:")
    if len(bond_lengths) > 0:
        print(f"  æ€»é”®æ•°: {len(bond_lengths)}")
        print(f"  å¹³å‡é”®é•¿: {bond_lengths.mean():.4f} Ã…")
        print(f"  ä¸­ä½æ•°é”®é•¿: {np.median(bond_lengths):.4f} Ã…")
        print(f"  é”®é•¿èŒƒå›´: {bond_lengths.min():.4f} - {bond_lengths.max():.4f} Ã…")
    else:
        print("  æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•é”®ï¼")
    
    print(f"\nè¯´æ˜: ç¼ºå¤±é”®æ˜¯æŒ‡æ ¹æ®åŸå­ç±»å‹å’Œè·ç¦»åˆ¤æ–­åº”è¯¥å½¢æˆé”®ï¼Œä½†å®é™…é”®çŸ©é˜µä¸­æœªè¯†åˆ«å‡ºçš„åŸå­å¯¹")
    
    return {
        'bond_lengths': bond_lengths,
        'strict': {
            'num_components': num_components_strict,
            'is_connected': is_connected_strict,
            'missing_bond_deviations': all_missing_bond_deviations_strict
        },
        'medium': {
            'num_components': num_components_medium,
            'is_connected': is_connected_medium,
            'missing_bond_deviations': all_missing_bond_deviations_medium
        },
        'relaxed': {
            'num_components': num_components_relaxed,
            'is_connected': is_connected_relaxed,
            'missing_bond_deviations': all_missing_bond_deviations_relaxed
        }
    }

