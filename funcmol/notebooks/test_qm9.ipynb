{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a52041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/funcmol/notebooks\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/funcmol/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbf18ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield\n",
      "Python path: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from lightning import Fabric\n",
    "\n",
    "# 设置 torch.compile 兼容性\n",
    "try:\n",
    "    import torch._dynamo\n",
    "    torch._dynamo.config.suppress_errors = True\n",
    "except ImportError:\n",
    "    # PyTorch 版本 < 2.0 不支持 torch._dynamo\n",
    "    print(\"Warning: torch._dynamo not available in this PyTorch version\")\n",
    "\n",
    "## set up environment\n",
    "# 当前目录是 funcmol/notebooks，需要将 funcmol 的父目录添加到路径中\n",
    "# 这样 funcmol 才能作为包被正确导入\n",
    "notebook_dir = Path(os.getcwd())  # funcmol/notebooks\n",
    "project_root = notebook_dir.parent.parent  # funcmol 的父目录\n",
    "sys.path.insert(0, str(project_root))\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path: {sys.path[0]}\")\n",
    "\n",
    "from funcmol.dataset.dataset_field import create_gnf_converter, prepare_data_with_sample_idx\n",
    "from funcmol.utils.utils_nf import load_neural_field\n",
    "from funcmol.utils.utils_fm import load_checkpoint_fm\n",
    "from funcmol.utils.constants import PADDING_INDEX\n",
    "from funcmol.utils.gnf_visualizer import (\n",
    "    visualize_1d_gradient_field_comparison, \n",
    "    GNFVisualizer,\n",
    "    visualize_generation_step,\n",
    "    visualize_generated_molecule\n",
    ")\n",
    "from funcmol.utils.misc import load_nf_config, load_funcmol_config, create_field_function\n",
    "\n",
    "# 模型根目录\n",
    "model_root = \"/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/neural_field\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23544d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option: denoiser_only\n",
      "FuncMol model directory: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111\n",
      "FuncMol checkpoint: model-epoch=399\n",
      "Neural Field checkpoint: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/model-epoch=409.ckpt\n",
      "Output directory: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399\n"
     ]
    }
   ],
   "source": [
    "# TODO：手动指定是 gt_only、gt_pred 还是 denoiser_only 模式\n",
    "option = 'denoiser_only'  # 'gt_only', 'gt_pred', 'denoiser_only'\n",
    "\n",
    "# TODO：手动指定 checkpoint 文件路径，会根据ckpt_path自动提取exp_name\n",
    "nf_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/model-epoch=409.ckpt'\n",
    "fm_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/lightning_logs/version_0/checkpoints/model-epoch=399.ckpt'\n",
    "# nf_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20250911/lightning_logs/version_1/checkpoints/model-epoch=39.ckpt'\n",
    "# fm_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20250917/lightning_logs/version_22/checkpoints/model-epoch=144.ckpt'\n",
    "\n",
    "# TODO：手动指定 sample_idx（仅用于 gt_only 和 gt_pred 模式）\n",
    "sample_idx = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，使用 FuncMol 的路径\n",
    "    ckpt_parts = Path(fm_ckpt_path).parts\n",
    "    funcmol_idx = ckpt_parts.index('funcmol')\n",
    "    exp_name = f\"{ckpt_parts[funcmol_idx + 1]}/{ckpt_parts[funcmol_idx + 2]}\"  # fm_qm9/20250912\n",
    "    ckpt_name = Path(fm_ckpt_path).stem  # funcmol-epoch=319\n",
    "    model_dir = os.path.join(\"/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol\", exp_name)\n",
    "    output_dir = os.path.join(model_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Option: {option}\")\n",
    "    print(f\"FuncMol model directory: {model_dir}\")\n",
    "    print(f\"FuncMol checkpoint: {ckpt_name}\")\n",
    "    print(f\"Neural Field checkpoint: {nf_ckpt_path}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "else:\n",
    "    # 对于 gt_only 和 gt_pred 模式，使用 Neural Field 的路径\n",
    "    ckpt_parts = Path(nf_ckpt_path).parts\n",
    "    neural_field_idx = ckpt_parts.index('neural_field')\n",
    "    exp_name = f\"{ckpt_parts[neural_field_idx + 1]}/{ckpt_parts[neural_field_idx + 2]}\"  # nf_qm9/20250911\n",
    "    ckpt_name = Path(nf_ckpt_path).stem  # model-epoch=39\n",
    "    model_dir = os.path.join(model_root, exp_name)\n",
    "    output_dir = os.path.join(model_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Option: {option}\")\n",
    "    print(f\"Model directory: {model_dir}\")\n",
    "    print(f\"Checkpoint: {ckpt_name}\")\n",
    "    print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceafdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/funcmol/dataset/data\n",
      "Config loaded successfully: train_nf_qm9\n",
      "n_iter from converter config: 2000\n",
      "Denoiser-only mode: No dataset loading required\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "fabric = Fabric(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    precision=\"32-true\",\n",
    "    strategy=\"auto\"\n",
    ")\n",
    "fabric.launch()\n",
    "\n",
    "# 使用 load_nf_config 函数从 configs 目录加载配置\n",
    "config = load_nf_config(\"train_nf_qm9\")\n",
    "\n",
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，不需要加载数据集\n",
    "    batch, gt_coords, gt_types = None, None, None\n",
    "    print(\"Denoiser-only mode: No dataset loading required\")\n",
    "else:\n",
    "    # 准备包含特定样本的数据\n",
    "    batch, gt_coords, gt_types = prepare_data_with_sample_idx(config, device, sample_idx)\n",
    "    print(f\"Data loaded for sample {sample_idx}: {gt_coords.shape}, {gt_types.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1c8d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing model from: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111\n",
      "Loading Neural Field model from: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/model-epoch=409.ckpt\n",
      "Loading Lightning checkpoint from: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/model-epoch=409.ckpt\n",
      ">> loaded dec\n",
      ">> loaded enc\n",
      "Model loaded successfully!\n",
      "Loading configuration from YAML: train_fm_qm9\n",
      ">> Using diffusion_method: new_x0\n",
      ">> DDPM config: {'hidden_dim': 128, 'num_layers': 4, 'time_emb_dim': 64, 'dropout': 0.1, 'num_timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02, 'schedule': 'linear', 's1': 0.008, 'sT': 0.008, 'w': 1.0}\n",
      ">> loaded denoiser\n",
      ">> loaded model trained for 399 epochs\n",
      ">> FuncMol model loaded successfully!\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# 修复后的模型加载代码 - 使用YAML配置文件加载参数\n",
    "print(f\"\\nProcessing model from: {model_dir}\")\n",
    "\n",
    "## Load model\n",
    "if option == 'denoiser_only':\n",
    "    # 加载 Neural Field 模型和 FuncMol 模型\n",
    "    from funcmol.models.funcmol import FuncMol\n",
    "    \n",
    "    # 加载 Neural Field 模型\n",
    "    print(f\"Loading Neural Field model from: {nf_ckpt_path}\")\n",
    "    encoder, decoder = load_neural_field(nf_ckpt_path, config)\n",
    "    # 确保模型在正确的设备上\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # 使用YAML配置文件加载FuncMol配置\n",
    "    funcmol_config = load_funcmol_config(\"train_fm_qm9\", config)\n",
    "    \n",
    "    # 创建FuncMol模型\n",
    "    funcmol = FuncMol(funcmol_config)\n",
    "    funcmol = funcmol.cuda()\n",
    "    \n",
    "    # 加载checkpoint\n",
    "    funcmol, _ = load_checkpoint_fm(funcmol, fm_ckpt_path, fabric=fabric)\n",
    "    funcmol.eval()\n",
    "    \n",
    "    print(\">> FuncMol model loaded successfully!\")\n",
    "    \n",
    "    # 使用统一的场计算函数\n",
    "    field_func = create_field_function(\n",
    "        mode='denoiser',\n",
    "        decoder=decoder,\n",
    "        funcmol=funcmol,\n",
    "        config=config\n",
    "    )\n",
    "    codes = None  # denoiser 模式不需要预计算的 codes\n",
    "    \n",
    "elif option == 'gt_pred':\n",
    "    # 使用手动指定的 checkpoint 文件路径\n",
    "    if not os.path.exists(nf_ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {nf_ckpt_path}\")\n",
    "    \n",
    "    print(f\"Loading model from: {nf_ckpt_path}\")\n",
    "    encoder, decoder = load_neural_field(nf_ckpt_path, config)\n",
    "    \n",
    "    # 确保模型在正确的设备上\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # 生成 codes\n",
    "    print(f\"Batch device: {batch.pos.device}\")\n",
    "    print(f\"Encoder device: {next(encoder.parameters()).device}\")\n",
    "    with torch.no_grad():\n",
    "        codes = encoder(batch)\n",
    "    # 使用统一的场计算函数\n",
    "    field_func = create_field_function(\n",
    "        mode='predicted',\n",
    "        decoder=decoder,\n",
    "        codes=codes\n",
    "    )\n",
    "else:  # gt only\n",
    "    encoder, decoder = None, None\n",
    "    codes = None\n",
    "\n",
    "converter = create_gnf_converter(config)\n",
    "\n",
    "# 创建场函数（在converter定义之后）\n",
    "if option == 'gt_only':\n",
    "    field_func = create_field_function(\n",
    "        mode='gt',\n",
    "        converter=converter,\n",
    "        gt_coords=gt_coords,\n",
    "        gt_types=gt_types\n",
    "    )\n",
    "print(f\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7f452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> loaded denoiser\n",
      ">> loaded model trained for 399 epochs\n",
      "\n",
      "=== Converter 配置信息（用于验证） ===\n",
      "n_iter: 2000\n",
      "全局 eps: None, min_samples: None\n",
      "方法特定配置 (tanh):\n",
      "  eps: 0.15\n",
      "  min_samples: 30\n",
      "  n_query_points: 1000\n",
      "  step_size: 0.1\n",
      "==================================================\n",
      "\n",
      "=== Codes 加载配置信息 ===\n",
      "codes_source: load\n",
      "codes_file_path: None\n",
      "codes_idx: 0\n",
      "field_method: tanh\n",
      "model_dir: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111\n",
      "根据索引自动构建路径:\n",
      "  mol_save_dir: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/molecule\n",
      "  文件名格式: code_0000_tanh.pt\n",
      "\n",
      "最终使用的codes路径: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/molecule/code_0000_tanh.pt\n",
      "路径是否存在: True\n",
      "Loading codes from: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/molecule/code_0000_tanh.pt\n",
      "Loaded codes shape: torch.Size([1, 729, 128])\n",
      "Codes loaded/sampled and field_func set.\n"
     ]
    }
   ],
   "source": [
    "if option == 'denoiser_only':\n",
    "    from funcmol.models.funcmol import FuncMol\n",
    "    from funcmol.utils.utils_fm import load_checkpoint_fm\n",
    "    from omegaconf import OmegaConf\n",
    "\n",
    "    # ========== 配置codes加载方式 ==========\n",
    "    codes_source = 'load'  # 'load' 或 'sample'，'load' 表示从保存的文件加载，'sample' 表示随机采样\n",
    "    \n",
    "    # 如果选择 'load'，可以通过以下两种方式指定：\n",
    "    # 方式1：指定codes文件索引（0, 1, 2, 3, 4等），会自动构建路径\n",
    "    codes_idx = 0  # 例如：0 表示 code_0000_tanh.pt, 1 表示 code_0001_tanh.pt\n",
    "    \n",
    "    # 方式2：直接指定codes文件的完整路径（如果指定了，会优先使用此路径）\n",
    "    codes_file_path = None  # 例如：'/path/to/code_0000_tanh.pt' 或 None\n",
    "    \n",
    "    # field_method 需要与 sample_fm.py 中保存codes时使用的field_method一致\n",
    "    field_method = 'tanh'  # 与 sample_fm.py 中的 field_methods = ['tanh'] 一致\n",
    "    # ======================================\n",
    "\n",
    "    # 确保与当前NF配置一致（保持decoder/encoder/dset对齐）\n",
    "    funcmol_config[\"encoder\"] = OmegaConf.to_container(config.encoder, resolve=True)\n",
    "    funcmol_config[\"decoder\"] = OmegaConf.to_container(config.decoder, resolve=True)\n",
    "    funcmol_config[\"dset\"] = OmegaConf.to_container(config.dset, resolve=True)\n",
    "\n",
    "    funcmol_ddpm = FuncMol(funcmol_config)\n",
    "    funcmol_ddpm = funcmol_ddpm.cuda()\n",
    "    funcmol_ddpm, code_stats = load_checkpoint_fm(funcmol_ddpm, fm_ckpt_path)\n",
    "    funcmol_ddpm.eval()\n",
    "\n",
    "    # 同步 code_stats 到 decoder，保证数值尺度一致\n",
    "    try:\n",
    "        decoder.set_code_stats(code_stats)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 使用与 sample_fm.py 完全一致的配置加载方式\n",
    "    # 关键：使用 Hydra 加载 sample_fm.yaml 配置，确保和 sample_fm.py 完全一致\n",
    "    import hydra\n",
    "    from omegaconf import DictConfig\n",
    "    \n",
    "    # 使用 Hydra 加载 sample_fm.yaml 配置（与 sample_fm.py 完全相同的方式）\n",
    "    configs_dir = project_root / \"funcmol\" / \"configs\"\n",
    "    with hydra.initialize_config_dir(config_dir=str(configs_dir), version_base=None):\n",
    "        sample_fm_config = hydra.compose(config_name=\"sample_fm\")\n",
    "    \n",
    "    # 转换为字典格式（与 sample_fm.py 第51行完全一致）\n",
    "    config_dict = OmegaConf.to_container(sample_fm_config, resolve=True)\n",
    "    \n",
    "    # 构建与 sample_fm.py 完全相同的配置结构（第149-150行）\n",
    "    method_config = config_dict.copy()\n",
    "    method_config['converter']['gradient_field_method'] = field_method\n",
    "    \n",
    "    # 创建 converter（与 sample_fm.py 第151行完全一致）\n",
    "    converter = create_gnf_converter(method_config)\n",
    "    \n",
    "    # 打印配置信息以便调试和验证\n",
    "    converter_config = method_config['converter']\n",
    "    print(f\"\\n=== Converter 配置信息（用于验证） ===\")\n",
    "    print(f\"n_iter: {converter_config.get('n_iter')}\")\n",
    "    print(f\"全局 eps: {converter_config.get('eps')}, min_samples: {converter_config.get('min_samples')}\")\n",
    "    if 'method_configs' in converter_config and field_method in converter_config['method_configs']:\n",
    "        method_specific = converter_config['method_configs'][field_method]\n",
    "        print(f\"方法特定配置 ({field_method}):\")\n",
    "        print(f\"  eps: {method_specific.get('eps', 'N/A')}\")\n",
    "        print(f\"  min_samples: {method_specific.get('min_samples', 'N/A')}\")\n",
    "        print(f\"  n_query_points: {method_specific.get('n_query_points', 'N/A')}\")\n",
    "        print(f\"  step_size: {method_specific.get('step_size', 'N/A')}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # 获取 codes 的维度信息\n",
    "    grid_size = method_config.get('dset', {}).get('grid_size', 9)  # 与 sample_fm.py 一致\n",
    "    code_dim = method_config.get('encoder', {}).get('code_dim', 128)  # 与 sample_fm.py 一致\n",
    "    \n",
    "    # 根据配置加载或采样 codes\n",
    "    print(f\"\\n=== Codes 加载配置信息 ===\")\n",
    "    print(f\"codes_source: {codes_source}\")\n",
    "    print(f\"codes_file_path: {codes_file_path}\")\n",
    "    print(f\"codes_idx: {codes_idx}\")\n",
    "    print(f\"field_method: {field_method}\")\n",
    "    print(f\"model_dir: {model_dir}\")\n",
    "    \n",
    "    if codes_source == 'load':\n",
    "        # 从保存的codes文件加载\n",
    "        if codes_file_path is not None:\n",
    "            # 使用直接指定的路径\n",
    "            code_path = Path(codes_file_path)\n",
    "            print(f\"使用直接指定的codes文件路径\")\n",
    "        else:\n",
    "            # 根据索引自动构建路径\n",
    "            # sample_fm.py 保存codes的路径格式：{model_dir}/molecule/code_{generated_idx:04d}_{field_method}.pt\n",
    "            mol_save_dir = Path(model_dir) / \"molecule\"\n",
    "            code_path = mol_save_dir / f\"code_{codes_idx:04d}_{field_method}.pt\"\n",
    "            print(f\"根据索引自动构建路径:\")\n",
    "            print(f\"  mol_save_dir: {mol_save_dir}\")\n",
    "            print(f\"  文件名格式: code_{codes_idx:04d}_{field_method}.pt\")\n",
    "        \n",
    "        print(f\"\\n最终使用的codes路径: {code_path}\")\n",
    "        print(f\"路径是否存在: {code_path.exists()}\")\n",
    "        \n",
    "        if not code_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Codes file not found: {code_path}\\n\"\n",
    "                f\"Please check if the file exists or run sample_fm.py first to generate codes.\"\n",
    "            )\n",
    "        \n",
    "        print(f\"Loading codes from: {code_path}\")\n",
    "        codes = torch.load(code_path, map_location='cuda')\n",
    "        # 确保codes的形状正确 [1, grid_size^3, code_dim]\n",
    "        if codes.dim() == 2:\n",
    "            # 如果是 [grid_size^3, code_dim]，添加batch维度\n",
    "            codes = codes.unsqueeze(0)\n",
    "        print(f\"Loaded codes shape: {codes.shape}\")\n",
    "        \n",
    "    else:\n",
    "        # 随机采样 codes\n",
    "        print(\"Sampling codes using DDPM...\")\n",
    "        with torch.no_grad():\n",
    "            codes = funcmol_ddpm.sample_ddpm(shape=(1, grid_size**3, code_dim), progress=False)\n",
    "        print(f\"Sampled codes shape: {codes.shape}\")\n",
    "\n",
    "    # 使用统一的场计算函数\n",
    "    field_func = create_field_function(\n",
    "        mode='ddpm',\n",
    "        decoder=decoder,\n",
    "        codes=codes\n",
    "    )\n",
    "    print(\"Codes loaded/sampled and field_func set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b35856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 可视化1D梯度场（仅预测） ===\n",
      "使用默认 x 轴范围: (-11.0, 11.0)\n",
      "Field 1D comparison (atom_type=C) saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/field_1d_sample_0_atom_C.png\n",
      "Field 1D comparison (atom_type=H) saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/field_1d_sample_0_atom_H.png\n",
      "Field 1D comparison (atom_type=O) saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/field_1d_sample_0_atom_O.png\n",
      "Field 1D comparison (atom_type=N) saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/field_1d_sample_0_atom_N.png\n",
      "Field 1D comparison (atom_type=F) saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/field_1d_sample_0_atom_F.png\n",
      "Gradient field visualization (generation mode):\n",
      "  Available atom types: [0, 1, 2, 3, 4]\n",
      "  C:\n",
      "    Magnitude: Mean=0.584004, Std=0.355694\n",
      "    Saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/field_1d_sample_0_atom_C.png\n",
      "  H:\n",
      "    Magnitude: Mean=0.586147, Std=0.440680\n",
      "    Saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/field_1d_sample_0_atom_H.png\n",
      "  O:\n",
      "    Magnitude: Mean=0.636305, Std=0.418765\n",
      "    Saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/field_1d_sample_0_atom_O.png\n",
      "  N:\n",
      "    Magnitude: Mean=0.102335, Std=0.134060\n",
      "    Saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/field_1d_sample_0_atom_N.png\n",
      "  F:\n",
      "    Magnitude: Mean=0.125440, Std=0.164007\n",
      "    Saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/field_1d_sample_0_atom_F.png\n"
     ]
    }
   ],
   "source": [
    "if option != 'denoiser_only':\n",
    "    # 可视化一维梯度场对比（所有原子类型）\n",
    "    atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
    "    save_path = os.path.join(output_dir, f\"field1d_sample_{sample_idx}\")\n",
    "\n",
    "    gradient_results = visualize_1d_gradient_field_comparison(\n",
    "        gt_coords=gt_coords,\n",
    "        gt_types=gt_types,\n",
    "        converter=converter,\n",
    "        field_func=field_func,\n",
    "        sample_idx=0,  # 数据中只有1个样本，所以用索引0\n",
    "        atom_types=atom_types,  # 传入列表，不需要循环\n",
    "        x_range=None,\n",
    "        y_coord=0.0,\n",
    "        z_coord=0.0,\n",
    "        save_path=save_path,  # save_path已经包含了正确的sample_idx (14441)\n",
    "        display_sample_idx=sample_idx,  # 用于文件名和显示的原始样本索引\n",
    "    )\n",
    "\n",
    "    if gradient_results:\n",
    "        print(f\"Gradient field comparison (model: {model_dir}):\")\n",
    "        print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
    "        \n",
    "        # 打印每个原子类型的统计信息\n",
    "        for atom_name, stats in gradient_results['all_results'].items():\n",
    "            print(f\"  {atom_name}: MSE={stats['mse']:.6f}, MAE={stats['mae']:.6f}\")\n",
    "            print(f\"    Saved to: {stats['save_path']}\")\n",
    "\n",
    "elif option == 'denoiser_only':\n",
    "    # 可视化denoiser生成的codes对应的梯度场在1维上的变化曲线\n",
    "    print(\"\\n=== 可视化1D梯度场（仅预测） ===\")\n",
    "    \n",
    "    # 使用统一的场计算函数\n",
    "    atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
    "    save_path = os.path.join(output_dir, f\"field1d_gen_sample_0\")\n",
    "    \n",
    "    # 调用修改后的函数，不传入gt_coords和gt_types，只绘制预测的梯度场\n",
    "    gradient_results = visualize_1d_gradient_field_comparison(\n",
    "        gt_coords=None,  # 无ground truth\n",
    "        gt_types=None,   # 无ground truth\n",
    "        converter=None,  # 无ground truth时converter可以为None\n",
    "        field_func=field_func,\n",
    "        sample_idx=0,\n",
    "        atom_types=atom_types,\n",
    "        x_range=None,  # 使用默认范围(-5.0, 5.0)\n",
    "        y_coord=0.0,\n",
    "        z_coord=0.0,\n",
    "        save_path=save_path,\n",
    "        display_sample_idx=0,\n",
    "    )\n",
    "    \n",
    "    if gradient_results:\n",
    "        print(f\"Gradient field visualization (generation mode):\")\n",
    "        print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
    "        \n",
    "        # 打印每个原子类型的统计信息\n",
    "        for atom_name, stats in gradient_results['all_results'].items():\n",
    "            print(f\"  {atom_name}:\")\n",
    "            print(f\"    Magnitude: Mean={stats.get('magnitude_mean', 'N/A'):.6f}, Std={stats.get('magnitude_std', 'N/A'):.6f}\")\n",
    "            print(f\"    Saved to: {stats['save_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927131ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 执行 DDPM(new) 分子生成 ===\n",
      "Generating molecular field and reconstructing molecule (loaded codes)...\n",
      ">>     Memory status at iteration 0: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 50: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 100: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 150: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 200: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 250: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 300: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 350: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 400: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 450: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 500: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 550: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 600: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 650: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 700: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 750: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 800: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 850: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 900: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 950: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1000: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1050: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1100: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1150: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1200: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1250: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1300: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1350: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1400: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1450: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1500: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1550: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1600: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1650: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1700: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1750: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1800: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1850: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1900: Allocated=0.02GB, Reserved=0.75GB\n",
      ">>     Memory status at iteration 1950: Allocated=0.02GB, Reserved=0.75GB\n",
      "[DBSCAN] Total points: 1000, Clusters found: 1, Noise points: 12\n",
      "[DBSCAN] Total points: 1000, Clusters found: 4, Noise points: 12\n",
      "[DBSCAN] Total points: 1000, Clusters found: 3, Noise points: 40\n",
      "[DBSCAN] Total points: 1000, Clusters found: 5, Noise points: 724\n",
      "[DBSCAN] Total points: 1000, Clusters found: 7, Noise points: 637\n",
      "Generated molecule: 20 atoms\n",
      "Atom types: [0, 1, 2, 3, 4]\n",
      "Creating generation process animation from saved frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2950493/3564755995.py:83: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  frame = imageio.imread(frame_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DDPM Field 生成结果 ===\n",
      "Generated atoms: 20\n",
      "Atom type distribution: {tensor(0, device='cuda:0'): tensor(1, device='cuda:0'), tensor(1, device='cuda:0'): tensor(4, device='cuda:0'), tensor(2, device='cuda:0'): tensor(3, device='cuda:0'), tensor(3, device='cuda:0'): tensor(5, device='cuda:0'), tensor(4, device='cuda:0'): tensor(7, device='cuda:0')}\n",
      "最终分子图: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/funcmol_gen_sample_0_final.png\n",
      "生成过程动画: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251111/model-epoch=399/funcmol_gen_sample_0.gif\n"
     ]
    }
   ],
   "source": [
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，使用DDPM采样得到固定codes并可视化\n",
    "    print(\"\\n=== 执行 DDPM 分子生成 ===\")\n",
    "\n",
    "    grid_size = config.dset.grid_size\n",
    "    code_dim = config.encoder.code_dim\n",
    "\n",
    "    # 用于存储动画帧的列表和固定坐标轴限制\n",
    "    frame_paths = []\n",
    "    fixed_axis_limits_dict = {'limits': None}\n",
    "    \n",
    "    # 定义可视化回调函数\n",
    "    def visualization_callback(iter_idx, all_points_dict, batch_idx):\n",
    "        \"\"\"在每次迭代时保存可视化帧\"\"\"\n",
    "        # 合并所有原子类型的点\n",
    "        all_points = []\n",
    "        all_types = []\n",
    "        for atom_type in range(5):  # C, H, O, N, F\n",
    "            if atom_type in all_points_dict and len(all_points_dict[atom_type]) > 0:\n",
    "                points = all_points_dict[atom_type]\n",
    "                all_points.append(points)\n",
    "                all_types.extend([atom_type] * len(points))\n",
    "        \n",
    "        if all_points:\n",
    "            current_points = torch.cat(all_points, dim=0)\n",
    "            current_types = torch.tensor(all_types, device=current_points.device)\n",
    "        else:\n",
    "            current_points = torch.empty((0, 3), device=codes.device)\n",
    "            current_types = torch.empty((0,), device=codes.device, dtype=torch.long)\n",
    "        \n",
    "        # 如果是第一帧，确定固定坐标轴范围\n",
    "        if iter_idx == 0 and len(current_points) > 0:\n",
    "            points_np = current_points.detach().cpu().numpy()\n",
    "            margin = 1.0\n",
    "            fixed_axis_limits_dict['limits'] = {\n",
    "                'x_min': points_np[:, 0].min() - margin,\n",
    "                'x_max': points_np[:, 0].max() + margin,\n",
    "                'y_min': points_np[:, 1].min() - margin,\n",
    "                'y_max': points_np[:, 1].max() + margin,\n",
    "                'z_min': points_np[:, 2].min() - margin,\n",
    "                'z_max': points_np[:, 2].max() + margin\n",
    "            }\n",
    "        \n",
    "        # 保存帧\n",
    "        frame_path = os.path.join(output_dir, f\"frame_gen_sample_0_{iter_idx:04d}.png\")\n",
    "        visualize_generation_step(\n",
    "            current_points, iter_idx, frame_path, current_types, fixed_axis_limits_dict['limits']\n",
    "        )\n",
    "        frame_paths.append(frame_path)\n",
    "\n",
    "    # 使用上一个单元已加载的 codes，重建分子，使用可视化\n",
    "    print(\"Generating molecular field and reconstructing molecule (loaded codes)...\")\n",
    "    save_interval = 100\n",
    "    recon_coords, recon_types = converter.gnf2mol(\n",
    "        decoder,\n",
    "        codes,\n",
    "        fabric=fabric,\n",
    "        save_interval = save_interval,\n",
    "        visualization_callback = visualization_callback\n",
    "    )\n",
    "    \n",
    "    print(f\"Generated molecule: {recon_coords[0].shape[0]} atoms\")\n",
    "    print(f\"Atom types: {recon_types[0].unique().tolist()}\")\n",
    "\n",
    "    # 创建 GIF 动画\n",
    "    print(\"Creating generation process animation from saved frames...\")\n",
    "    import imageio\n",
    "    gif_path = os.path.join(output_dir, f\"funcmol_gen_sample_0.gif\")\n",
    "    with imageio.get_writer(gif_path, mode='I', duration=0.1, fps=15, loop=1) as writer:\n",
    "        for frame_path in frame_paths:\n",
    "            try:\n",
    "                if not os.path.exists(frame_path):\n",
    "                    print(f\"Warning: Frame file {frame_path} does not exist, skipping...\")\n",
    "                    continue\n",
    "                \n",
    "                import time\n",
    "                time.sleep(0.01)  # 短暂等待确保文件写入完成\n",
    "                \n",
    "                if os.path.getsize(frame_path) == 0:\n",
    "                    print(f\"Warning: Frame file {frame_path} is empty, skipping...\")\n",
    "                    continue\n",
    "                \n",
    "                frame = imageio.imread(frame_path)\n",
    "                writer.append_data(frame)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to read frame {frame_path}: {e}\")\n",
    "                continue\n",
    "            finally:\n",
    "                # 清理临时帧文件\n",
    "                try:\n",
    "                    if os.path.exists(frame_path):\n",
    "                        os.remove(frame_path)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    # 保存最终生成的分子\n",
    "    final_path = os.path.join(output_dir, f\"funcmol_gen_sample_0_final.png\")\n",
    "    # 过滤掉填充的原子（类型为-1的原子）\n",
    "    valid_mask = recon_types[0] != -1\n",
    "    if valid_mask.any():\n",
    "        final_coords_valid = recon_coords[0][valid_mask]\n",
    "        final_types_valid = recon_types[0][valid_mask]\n",
    "        visualize_generated_molecule(\n",
    "            final_coords_valid, final_types_valid, save_path=final_path\n",
    "        )\n",
    "    else:\n",
    "        print(\"Warning: No valid atoms generated\")\n",
    "\n",
    "    print(f\"\\n=== DDPM Field 生成结果 ===\")\n",
    "    print(f\"Generated atoms: {recon_coords[0].shape[0]}\")\n",
    "    print(f\"Atom type distribution: {dict(zip(*torch.unique(recon_types[0], return_counts=True)))}\")\n",
    "    print(f\"最终分子图: {final_path}\")\n",
    "    print(f\"生成过程动画: {gif_path}\")\n",
    "    \n",
    "else:\n",
    "    # 根据option设置重建列表\n",
    "    if option == 'gt_only':\n",
    "        rec_list = ['gt_field']\n",
    "    else:\n",
    "        rec_list = ['predicted_field', 'gt_field']\n",
    "\n",
    "    # 创建可视化器\n",
    "    visualizer = GNFVisualizer(output_dir)\n",
    "\n",
    "    # 为每种重建类型执行可视化\n",
    "    for rec_type in rec_list:\n",
    "        print(f\"\\n=== 执行 {rec_type} 重建 ===\")\n",
    "        \n",
    "        # 根据重建类型设置场函数\n",
    "        if rec_type == 'gt_field':\n",
    "            # 使用统一的场计算函数\n",
    "            field_func = create_field_function(\n",
    "                mode='gt',\n",
    "                converter=converter,\n",
    "                gt_coords=gt_coords,\n",
    "                gt_types=gt_types\n",
    "            )\n",
    "        else:  # predicted_field\n",
    "            # 使用统一的场计算函数\n",
    "            field_func = create_field_function(\n",
    "                mode='predicted',\n",
    "                decoder=decoder,\n",
    "                codes=codes\n",
    "            )\n",
    "        \n",
    "        # 执行重建可视化\n",
    "        results = visualizer.create_reconstruction_animation(\n",
    "            gt_coords=gt_coords,\n",
    "            gt_types=gt_types,\n",
    "            converter=converter,\n",
    "            field_func=field_func,\n",
    "            save_interval=100,\n",
    "            animation_name=f\"recon_sample_{sample_idx}_{rec_type}\",\n",
    "            sample_idx=0\n",
    "        )\n",
    "\n",
    "        print(f\"\\n=== {rec_type} 重建结果 ===\")\n",
    "        print(f\"RMSD: {results['final_rmsd']:.4f}\")\n",
    "        print(f\"Reconstruction Loss: {results['final_loss']:.4f}\")\n",
    "        print(f\"KL Divergence (orig->recon): {results['final_kl_1to2']:.4f}\")\n",
    "        print(f\"KL Divergence (recon->orig): {results['final_kl_2to1']:.4f}\")\n",
    "        print(f\"GIF动画: {results['gif_path']}\")\n",
    "        print(f\"对比图: {results['comparison_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funcmol_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
