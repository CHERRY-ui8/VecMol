{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a52041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbf18ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This integration is tested and supported for lightning Fabric 2.1.3.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.\n",
      "Fabric will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Fabric(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import hydra\n",
    "from pathlib import Path\n",
    "from lightning import Fabric\n",
    "\n",
    "# 设置 torch.compile 兼容性\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "## set up environment\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from funcmol.utils.constants import PADDING_INDEX\n",
    "from gnf_visualizer import (\n",
    "    load_config_from_exp_dir, load_model, \n",
    "    create_converter, prepare_data, visualize_1d_gradient_field_comparison,\n",
    "    GNFVisualizer\n",
    ")\n",
    "\n",
    "# 模型根目录\n",
    "model_root = \"/home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23544d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option: gt_pred\n",
      "Model directory: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945\n",
      "Output directory: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945\n"
     ]
    }
   ],
   "source": [
    "# TODO：只需要修改这里的就好，会根据exp_name判断gradient_field_method\n",
    "exp_name = 'nf_qm9_20250803_150822_593945'\n",
    "sample_idx = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 判断是gt_only还是gt_pred模式\n",
    "if '2025' in exp_name:  # gt + predicted field\n",
    "    option = 'gt_pred'\n",
    "    model_dir = os.path.join(model_root, exp_name)\n",
    "else:  # gt only. exp_name is the name of field (e.g., gaussian_mag)\n",
    "    option = 'gt_only'\n",
    "    model_dir = os.path.join(model_root, exp_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "output_dir = model_dir\n",
    "print(f\"Option: {option}\")\n",
    "print(f\"Model directory: {model_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceafdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /home/huayuchen/funcmol-main-neuralfield/funcmol/dataset/data\n",
      ">> val set size: 20042\n",
      "Data loaded: torch.Size([128, 18, 3]), torch.Size([128, 18])\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "fabric = Fabric(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    precision=\"32-true\",\n",
    "    strategy=\"auto\"\n",
    ")\n",
    "fabric.launch()\n",
    "\n",
    "# 从实验目录加载配置\n",
    "config = load_config_from_exp_dir(model_dir)\n",
    "\n",
    "# 准备数据\n",
    "batch, gt_coords, gt_types = prepare_data(fabric, config, device)\n",
    "print(f\"Data loaded: {gt_coords.shape}, {gt_types.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b023b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing model from: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945\n",
      "Loading model from: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/model.pt\n",
      ">> loaded dec\n",
      ">> loaded enc\n",
      ">> loaded dec\n",
      ">> loaded enc\n",
      "Model loaded successfully!\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nProcessing model from: {model_dir}\")\n",
    "\n",
    "## Load model\n",
    "if option == 'gt_pred':\n",
    "    encoder, decoder = load_model(fabric, config, model_dir=model_dir)\n",
    "    # 生成 codes\n",
    "    with torch.no_grad():\n",
    "        codes = encoder(batch)\n",
    "    # 定义预测场函数\n",
    "    def predicted_field_func(points):\n",
    "        # 确保 points 是正确的形状\n",
    "        if points.dim() == 2:  # [n_points, 3]\n",
    "            points = points.unsqueeze(0)  # [1, n_points, 3]\n",
    "        elif points.dim() == 3:  # [batch, n_points, 3]\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "        \n",
    "        result = decoder(points, codes[sample_idx:sample_idx+1])\n",
    "        # 确保返回 [n_points, n_atom_types, 3] 形状\n",
    "        if result.dim() == 4:  # [batch, n_points, n_atom_types, 3]\n",
    "            return result[0]  # 取第一个batch\n",
    "        else:\n",
    "            return result\n",
    "    field_func = predicted_field_func\n",
    "else:  # gt only\n",
    "    encoder, decoder = None, None\n",
    "    # 定义真实场函数\n",
    "    def gt_field_func(points):\n",
    "        gt_mask = (gt_types[sample_idx] != PADDING_INDEX)\n",
    "        gt_valid_coords = gt_coords[sample_idx][gt_mask]\n",
    "        gt_valid_types = gt_types[sample_idx][gt_mask]\n",
    "        \n",
    "        # 确保 points 是正确的形状\n",
    "        if points.dim() == 2:  # [n_points, 3]\n",
    "            points = points.unsqueeze(0)  # [1, n_points, 3]\n",
    "        elif points.dim() == 3:  # [batch, n_points, 3]\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "        \n",
    "        result = converter.mol2gnf(\n",
    "            gt_valid_coords.unsqueeze(0),\n",
    "            gt_valid_types.unsqueeze(0),\n",
    "            points\n",
    "        )\n",
    "        # 确保返回 [n_points, n_atom_types, 3] 形状\n",
    "        if result.dim() == 4:  # [batch, n_points, n_atom_types, 3]\n",
    "            return result[0]  # 取第一个batch\n",
    "        else:\n",
    "            return result\n",
    "    field_func = gt_field_func\n",
    "\n",
    "converter = create_converter(config, device)\n",
    "print(f\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b35856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] Graph break from `Tensor.item()`, consider setting:\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     torch._dynamo.config.capture_scalar_outputs = True\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] or:\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] to include these operations in the captured graph.\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] \n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] Graph break: from user code at:\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]   File \"/home/huayuchen/funcmol-main-neuralfield/funcmol/models/decoder.py\", line 47, in forward\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     vector_field = self.net(x, codes)\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]   File \"/home/huayuchen/funcmol-main-neuralfield/funcmol/models/egnn.py\", line 197, in forward\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     edge_grid_query = knn(\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_geometric/nn/pool/__init__.py\", line 117, in knn\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     return torch_cluster.knn(x, y, k, batch_x, batch_y, cosine, num_workers,\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_cluster/knn.py\", line 66, in knn\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     batch_size = int(batch_x.max()) + 1\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] \n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告：样本 20 中没有类型为 N 的原子\n",
      "警告：样本 20 中没有类型为 F 的原子\n",
      "自动计算 x 轴范围: (-2.382029986381531, 2.382029986381531)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] WON'T CONVERT torch_dynamo_resume_in_knn_at_69 /home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_cluster/knn.py line 69 \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] due to: \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return _compile(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     tracer.run()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     super().run()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     while self.step():\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 582, in wrapper\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return inner_fn(self, inst)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 1602, in CALL_FUNCTION\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.call_function(fn, args, {})\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 830, in call_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/torch.py\", line 897, in call_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     tensor_variable = wrap_fx_proxy(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/builder.py\", line 2037, in wrap_fx_proxy\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/builder.py\", line 2124, in wrap_fx_proxy_cls\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2082, in get_fake_value\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     raise TorchRuntimeError(str(e)).with_traceback(e.__traceback__) from None\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2017, in get_fake_value\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     ret_val = wrap_fake_exception(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 1574, in wrap_fake_exception\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return fn()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2018, in <lambda>\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     lambda: run_node(tx.output, node, args, kwargs, nnmodule)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2150, in run_node\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(make_error_message(e)).with_traceback(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2132, in run_node\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return node.target(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_ops.py\", line 1116, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return self._op(*args, **(kwargs or {}))\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.TorchRuntimeError: Failed running call_function torch_cluster.knn(*(FakeTensor(..., device='cuda:0', size=(729, 3)), FakeTensor(..., device='cuda:0', size=(3000, 3)), None, None, 16, False, 1), **{}):\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] The tensor has a non-zero number of elements, but its data is not allocated yet.\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] If you're using torch.compile/export/fx, it is likely that we are erroneously tracing into a custom kernel. To fix this, please wrap the custom kernel into an opaque custom op. Please see the following for details: https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] If you're using Caffe2, Caffe2 uses a lazy allocation, so you will need to call mutable_data() or raw_mutable_data() to actually allocate memory.\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] from user code:\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]    File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_cluster/knn.py\", line 81, in torch_dynamo_resume_in_knn_at_69\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return torch.ops.torch_cluster.knn(x, y, ptr_x, ptr_y, k, cosine,\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return _compile(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     tracer.run()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     super().run()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     while self.step():\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 582, in wrapper\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return inner_fn(self, inst)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 1602, in CALL_FUNCTION\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.call_function(fn, args, {})\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 830, in call_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/torch.py\", line 897, in call_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     tensor_variable = wrap_fx_proxy(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/builder.py\", line 2037, in wrap_fx_proxy\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/builder.py\", line 2124, in wrap_fx_proxy_cls\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2082, in get_fake_value\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     raise TorchRuntimeError(str(e)).with_traceback(e.__traceback__) from None\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2017, in get_fake_value\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     ret_val = wrap_fake_exception(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 1574, in wrap_fake_exception\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return fn()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2018, in <lambda>\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     lambda: run_node(tx.output, node, args, kwargs, nnmodule)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2150, in run_node\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(make_error_message(e)).with_traceback(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2132, in run_node\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return node.target(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_ops.py\", line 1116, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return self._op(*args, **(kwargs or {}))\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.TorchRuntimeError: Failed running call_function torch_cluster.knn(*(FakeTensor(..., device='cuda:0', size=(729, 3)), FakeTensor(..., device='cuda:0', size=(3000, 3)), None, None, 16, False, 1), **{}):\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] The tensor has a non-zero number of elements, but its data is not allocated yet.\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] If you're using torch.compile/export/fx, it is likely that we are erroneously tracing into a custom kernel. To fix this, please wrap the custom kernel into an opaque custom op. Please see the following for details: https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] If you're using Caffe2, Caffe2 uses a lazy allocation, so you will need to call mutable_data() or raw_mutable_data() to actually allocate memory.\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] from user code:\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]    File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_cluster/knn.py\", line 81, in torch_dynamo_resume_in_knn_at_69\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return torch.ops.torch_cluster.knn(x, y, ptr_x, ptr_y, k, cosine,\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 1D comparison (atom_type=C) saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_C.png\n",
      "Field 1D comparison (atom_type=H) saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_H.png\n",
      "Field 1D comparison (atom_type=O) saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_O.png\n",
      "Gradient field comparison (model: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945):\n",
      "  Available atom types: [0, 1, 2]\n",
      "  C: MSE=0.000050, MAE=0.005117\n",
      "    Saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_C.png\n",
      "  H: MSE=0.000038, MAE=0.004623\n",
      "    Saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_H.png\n",
      "  O: MSE=0.000002, MAE=0.001188\n",
      "    Saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_O.png\n"
     ]
    }
   ],
   "source": [
    "# 可视化一维梯度场对比（所有原子类型）\n",
    "atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
    "save_path = os.path.join(output_dir, \"recon\", f\"field1d_sample_{sample_idx}\")\n",
    "\n",
    "gradient_results = visualize_1d_gradient_field_comparison(\n",
    "    gt_coords=gt_coords,\n",
    "    gt_types=gt_types,\n",
    "    converter=converter,\n",
    "    field_func=field_func,\n",
    "    sample_idx=sample_idx,\n",
    "    atom_types=atom_types,  # 传入列表，不需要循环\n",
    "    x_range=None,\n",
    "    y_coord=0.0,\n",
    "    z_coord=0.0,\n",
    "    save_path=save_path,\n",
    ")\n",
    "\n",
    "if gradient_results:\n",
    "    print(f\"Gradient field comparison (model: {model_dir}):\")\n",
    "    print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
    "    \n",
    "    # 打印每个原子类型的统计信息\n",
    "    for atom_name, stats in gradient_results['all_results'].items():\n",
    "        print(f\"  {atom_name}: MSE={stats['mse']:.6f}, MAE={stats['mae']:.6f}\")\n",
    "        print(f\"    Saved to: {stats['save_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927131ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 执行 predicted_field 重建 ===\n",
      "\n",
      "Starting reconstruction for molecule 20\n",
      "Ground truth atoms: 9\n",
      "[DBSCAN] Total points: 3000, Clusters found: 3, Noise points: 2636\n",
      "[DBSCAN] Total points: 3000, Clusters found: 4, Noise points: 2545\n",
      "[DBSCAN] Total points: 3000, Clusters found: 2, Noise points: 2758\n",
      "[DBSCAN] Total points: 3000, Clusters found: 0, Noise points: 3000\n",
      "[DBSCAN] Total points: 3000, Clusters found: 0, Noise points: 3000\n",
      "\n",
      "=== predicted_field 重建结果 ===\n",
      "RMSD: 0.7993\n",
      "Reconstruction Loss: 0.5683\n",
      "KL Divergence (orig->recon): 9.5590\n",
      "KL Divergence (recon->orig): -2.9384\n",
      "GIF动画: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/recon_sample_20_predicted_field.gif\n",
      "对比图: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/recon_sample_20_predicted_field_final.png\n",
      "\n",
      "=== 执行 gt_field 重建 ===\n",
      "\n",
      "Starting reconstruction for molecule 20\n",
      "Ground truth atoms: 9\n",
      "[DBSCAN] Total points: 3000, Clusters found: 3, Noise points: 2677\n",
      "[DBSCAN] Total points: 3000, Clusters found: 4, Noise points: 2544\n",
      "[DBSCAN] Total points: 3000, Clusters found: 2, Noise points: 2740\n",
      "[DBSCAN] Total points: 3000, Clusters found: 0, Noise points: 3000\n",
      "[DBSCAN] Total points: 3000, Clusters found: 0, Noise points: 3000\n",
      "\n",
      "=== gt_field 重建结果 ===\n",
      "RMSD: 0.7924\n",
      "Reconstruction Loss: 0.5679\n",
      "KL Divergence (orig->recon): 9.5609\n",
      "KL Divergence (recon->orig): -2.9736\n",
      "GIF动画: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/recon_sample_20_gt_field.gif\n",
      "对比图: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/recon_sample_20_gt_field_final.png\n"
     ]
    }
   ],
   "source": [
    "# 根据option设置重建列表\n",
    "if option == 'gt_only':\n",
    "    rec_list = ['gt_field']\n",
    "else:\n",
    "    rec_list = ['predicted_field', 'gt_field']\n",
    "\n",
    "# 创建可视化器\n",
    "visualizer = GNFVisualizer(output_dir)\n",
    "\n",
    "# 为每种重建类型执行可视化\n",
    "for rec_type in rec_list:\n",
    "    print(f\"\\n=== 执行 {rec_type} 重建 ===\")\n",
    "    \n",
    "    # 根据重建类型设置场函数\n",
    "    if rec_type == 'gt_field':\n",
    "        # 定义真实场函数\n",
    "        def gt_field_func(points):\n",
    "            gt_mask = (gt_types[sample_idx] != PADDING_INDEX)\n",
    "            gt_valid_coords = gt_coords[sample_idx][gt_mask]\n",
    "            gt_valid_types = gt_types[sample_idx][gt_mask]\n",
    "            return converter.mol2gnf(\n",
    "                gt_valid_coords.unsqueeze(0),\n",
    "                gt_valid_types.unsqueeze(0),\n",
    "                points\n",
    "            )\n",
    "        field_func = gt_field_func\n",
    "    else:  # predicted_field\n",
    "        # 定义预测场函数\n",
    "        def predicted_field_func(points):\n",
    "            if points.dim() == 2:\n",
    "                points = points.unsqueeze(0)\n",
    "            elif points.dim() == 3:\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "            result = decoder(points, codes[sample_idx:sample_idx+1])\n",
    "            return result[0] if result.dim() == 4 else result\n",
    "        field_func = predicted_field_func\n",
    "    \n",
    "    # 执行重建可视化\n",
    "    results = visualizer.create_reconstruction_animation(\n",
    "        gt_coords=gt_coords,\n",
    "        gt_types=gt_types,\n",
    "        converter=converter,\n",
    "        field_func=field_func,\n",
    "        save_interval=100,\n",
    "        animation_name=f\"recon_sample_{sample_idx}_{rec_type}\",\n",
    "        sample_idx=sample_idx\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== {rec_type} 重建结果 ===\")\n",
    "    print(f\"RMSD: {results['final_rmsd']:.4f}\")\n",
    "    print(f\"Reconstruction Loss: {results['final_loss']:.4f}\")\n",
    "    print(f\"KL Divergence (orig->recon): {results['final_kl_1to2']:.4f}\")\n",
    "    print(f\"KL Divergence (recon->orig): {results['final_kl_2to1']:.4f}\")\n",
    "    print(f\"GIF动画: {results['gif_path']}\")\n",
    "    print(f\"对比图: {results['comparison_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funcmol_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
