{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a52041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7dbf18ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from lightning import Fabric\n",
    "\n",
    "# 设置 torch.compile 兼容性\n",
    "try:\n",
    "    import torch._dynamo\n",
    "    torch._dynamo.config.suppress_errors = True\n",
    "except ImportError:\n",
    "    # PyTorch 版本 < 2.0 不支持 torch._dynamo\n",
    "    print(\"Warning: torch._dynamo not available in this PyTorch version\")\n",
    "\n",
    "## set up environment\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from dataset.dataset_field import create_gnf_converter, prepare_data_with_sample_idx\n",
    "from funcmol.utils.utils_nf import load_neural_field\n",
    "from funcmol.utils.utils_fm import load_checkpoint_fm\n",
    "from funcmol.utils.constants import PADDING_INDEX\n",
    "from funcmol.utils.gnf_visualizer import visualize_1d_gradient_field_comparison, GNFVisualizer\n",
    "from funcmol.utils.misc import load_nf_config, load_funcmol_config, create_field_function\n",
    "\n",
    "# 模型根目录\n",
    "model_root = \"/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/neural_field\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23544d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option: denoiser_only\n",
      "FuncMol model directory: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101\n",
      "FuncMol checkpoint: model-epoch=39\n",
      "Neural Field checkpoint: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/model-epoch=409.ckpt\n",
      "Output directory: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39\n"
     ]
    }
   ],
   "source": [
    "# TODO：手动指定是 gt_only、gt_pred 还是 denoiser_only 模式\n",
    "option = 'denoiser_only'  # 'gt_only', 'gt_pred', 'denoiser_only'\n",
    "\n",
    "# TODO：手动指定 checkpoint 文件路径，会根据ckpt_path自动提取exp_name\n",
    "nf_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/model-epoch=409.ckpt'\n",
    "fm_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/lightning_logs/version_0/checkpoints/model-epoch=39.ckpt'\n",
    "# nf_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20250911/lightning_logs/version_1/checkpoints/model-epoch=39.ckpt'\n",
    "# fm_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20250917/lightning_logs/version_22/checkpoints/model-epoch=144.ckpt'\n",
    "\n",
    "# TODO：手动指定 sample_idx（仅用于 gt_only 和 gt_pred 模式）\n",
    "sample_idx = 4000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，使用 FuncMol 的路径\n",
    "    ckpt_parts = Path(fm_ckpt_path).parts\n",
    "    funcmol_idx = ckpt_parts.index('funcmol')\n",
    "    exp_name = f\"{ckpt_parts[funcmol_idx + 1]}/{ckpt_parts[funcmol_idx + 2]}\"  # fm_qm9/20250912\n",
    "    ckpt_name = Path(fm_ckpt_path).stem  # funcmol-epoch=319\n",
    "    model_dir = os.path.join(\"/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol\", exp_name)\n",
    "    output_dir = os.path.join(model_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Option: {option}\")\n",
    "    print(f\"FuncMol model directory: {model_dir}\")\n",
    "    print(f\"FuncMol checkpoint: {ckpt_name}\")\n",
    "    print(f\"Neural Field checkpoint: {nf_ckpt_path}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "else:\n",
    "    # 对于 gt_only 和 gt_pred 模式，使用 Neural Field 的路径\n",
    "    ckpt_parts = Path(nf_ckpt_path).parts\n",
    "    neural_field_idx = ckpt_parts.index('neural_field')\n",
    "    exp_name = f\"{ckpt_parts[neural_field_idx + 1]}/{ckpt_parts[neural_field_idx + 2]}\"  # nf_qm9/20250911\n",
    "    ckpt_name = Path(nf_ckpt_path).stem  # model-epoch=39\n",
    "    model_dir = os.path.join(model_root, exp_name)\n",
    "    output_dir = os.path.join(model_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Option: {option}\")\n",
    "    print(f\"Model directory: {model_dir}\")\n",
    "    print(f\"Checkpoint: {ckpt_name}\")\n",
    "    print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceafdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/funcmol/dataset/data\n",
      "Config loaded successfully: train_nf_qm9\n",
      "n_iter from converter config: 3000\n",
      "Denoiser-only mode: No dataset loading required\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "fabric = Fabric(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    precision=\"32-true\",\n",
    "    strategy=\"auto\"\n",
    ")\n",
    "fabric.launch()\n",
    "\n",
    "# 使用 load_nf_config 函数从 configs 目录加载配置\n",
    "config = load_nf_config(\"train_nf_qm9\")\n",
    "\n",
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，不需要加载数据集\n",
    "    batch, gt_coords, gt_types = None, None, None\n",
    "    print(\"Denoiser-only mode: No dataset loading required\")\n",
    "else:\n",
    "    # 准备包含特定样本的数据\n",
    "    batch, gt_coords, gt_types = prepare_data_with_sample_idx(config, device, sample_idx)\n",
    "    print(f\"Data loaded for sample {sample_idx}: {gt_coords.shape}, {gt_types.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de1c8d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing model from: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101\n",
      "Loading Neural Field model from: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/model-epoch=409.ckpt\n",
      "Loading Lightning checkpoint from: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/model-epoch=409.ckpt\n",
      ">> loaded dec\n",
      ">> loaded enc\n",
      "Model loaded successfully!\n",
      "Loading configuration from YAML: train_fm_qm9\n",
      ">> Using diffusion_method: new\n",
      ">> DDPM config: {'hidden_dim': 128, 'num_layers': 4, 'time_emb_dim': 64, 'dropout': 0.1, 'beta_start': 0.0005, 'beta_end': 0.05, 'num_timesteps': 100, 'schedule': 'linear', 's1': 0.008, 'sT': 0.008, 'w': 1.0}\n",
      ">> loaded denoiser\n",
      ">> loaded model trained for 39 epochs\n",
      ">> FuncMol model loaded successfully!\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# 修复后的模型加载代码 - 使用YAML配置文件加载参数\n",
    "print(f\"\\nProcessing model from: {model_dir}\")\n",
    "\n",
    "## Load model\n",
    "if option == 'denoiser_only':\n",
    "    # 加载 Neural Field 模型和 FuncMol 模型\n",
    "    from funcmol.models.funcmol import FuncMol\n",
    "    \n",
    "    # 加载 Neural Field 模型\n",
    "    print(f\"Loading Neural Field model from: {nf_ckpt_path}\")\n",
    "    encoder, decoder = load_neural_field(nf_ckpt_path, config)\n",
    "    # 确保模型在正确的设备上\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # 使用YAML配置文件加载FuncMol配置\n",
    "    funcmol_config = load_funcmol_config(\"train_fm_qm9\", config)\n",
    "    \n",
    "    # 创建FuncMol模型\n",
    "    funcmol = FuncMol(funcmol_config)\n",
    "    funcmol = funcmol.cuda()\n",
    "    \n",
    "    # 加载checkpoint\n",
    "    funcmol, _ = load_checkpoint_fm(funcmol, fm_ckpt_path, fabric=fabric)\n",
    "    funcmol.eval()\n",
    "    \n",
    "    print(\">> FuncMol model loaded successfully!\")\n",
    "    \n",
    "    # 使用统一的场计算函数\n",
    "    field_func = create_field_function(\n",
    "        mode='denoiser',\n",
    "        decoder=decoder,\n",
    "        funcmol=funcmol,\n",
    "        config=config\n",
    "    )\n",
    "    codes = None  # denoiser 模式不需要预计算的 codes\n",
    "    \n",
    "elif option == 'gt_pred':\n",
    "    # 使用手动指定的 checkpoint 文件路径\n",
    "    if not os.path.exists(nf_ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {nf_ckpt_path}\")\n",
    "    \n",
    "    print(f\"Loading model from: {nf_ckpt_path}\")\n",
    "    encoder, decoder = load_neural_field(nf_ckpt_path, config)\n",
    "    \n",
    "    # 确保模型在正确的设备上\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # 生成 codes\n",
    "    print(f\"Batch device: {batch.pos.device}\")\n",
    "    print(f\"Encoder device: {next(encoder.parameters()).device}\")\n",
    "    with torch.no_grad():\n",
    "        codes = encoder(batch)\n",
    "    # 使用统一的场计算函数\n",
    "    field_func = create_field_function(\n",
    "        mode='predicted',\n",
    "        decoder=decoder,\n",
    "        codes=codes\n",
    "    )\n",
    "else:  # gt only\n",
    "    encoder, decoder = None, None\n",
    "    codes = None\n",
    "\n",
    "converter = create_gnf_converter(config)\n",
    "\n",
    "# 创建场函数（在converter定义之后）\n",
    "if option == 'gt_only':\n",
    "    field_func = create_field_function(\n",
    "        mode='gt',\n",
    "        converter=converter,\n",
    "        gt_coords=gt_coords,\n",
    "        gt_types=gt_types\n",
    "    )\n",
    "print(f\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dae7f452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> loaded denoiser\n",
      ">> loaded model trained for 39 epochs\n",
      "DDPM fixed codes sampled and field_func set.\n"
     ]
    }
   ],
   "source": [
    "# 使用DDPM(new)方式预采样固定codes并设置场函数\n",
    "if option == 'denoiser_only':\n",
    "    from funcmol.models.funcmol import FuncMol\n",
    "    from funcmol.utils.utils_fm import load_checkpoint_fm\n",
    "    from omegaconf import OmegaConf\n",
    "\n",
    "    # 确保与当前NF配置一致（保持decoder/encoder/dset对齐）\n",
    "    funcmol_config[\"encoder\"] = OmegaConf.to_container(config.encoder, resolve=True)\n",
    "    funcmol_config[\"decoder\"] = OmegaConf.to_container(config.decoder, resolve=True)\n",
    "    funcmol_config[\"dset\"] = OmegaConf.to_container(config.dset, resolve=True)\n",
    "\n",
    "    funcmol_ddpm = FuncMol(funcmol_config)\n",
    "    funcmol_ddpm = funcmol_ddpm.cuda()\n",
    "    funcmol_ddpm, code_stats = load_checkpoint_fm(funcmol_ddpm, fm_ckpt_path)\n",
    "    funcmol_ddpm.eval()\n",
    "\n",
    "    # 同步 code_stats 到 decoder，保证数值尺度一致\n",
    "    try:\n",
    "        decoder.set_code_stats(code_stats)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 使用与 sample_fm.py 完全一致的 converter 配置方式\n",
    "    \n",
    "    # 由于 sample_fm.yaml 使用 Hydra defaults，我们需要手动构建完整配置\n",
    "    # 加载 converter 配置\n",
    "    converter_cfg = OmegaConf.load(str(project_root / 'configs' / 'converter' / 'gnf_converter_qm9.yaml'))\n",
    "    converter_config = OmegaConf.to_container(converter_cfg, resolve=True)\n",
    "    \n",
    "    # 关键：动态设置 gradient_field_method，与 sample_fm.py 保持一致\n",
    "    field_method = 'tanh'  # 与 sample_fm.py 中的 field_methods = ['tanh'] 一致\n",
    "    converter_config['gradient_field_method'] = field_method\n",
    "    \n",
    "    # 构建与 sample_fm.py 完全相同的配置结构\n",
    "    method_config = {\n",
    "        'converter': converter_config,\n",
    "        'dset': OmegaConf.to_container(config.dset, resolve=True),\n",
    "        'encoder': OmegaConf.to_container(config.encoder, resolve=True),\n",
    "        'decoder': OmegaConf.to_container(config.decoder, resolve=True)\n",
    "    }\n",
    "    \n",
    "    converter = create_gnf_converter(method_config)\n",
    "\n",
    "    # 采样 codes，grid/code_dim 与 sample_fm.py 完全一致\n",
    "    grid_size = method_config.get('dset', {}).get('grid_size', 9)  # 与 sample_fm.py 一致\n",
    "    code_dim = method_config.get('encoder', {}).get('code_dim', 128)  # 与 sample_fm.py 一致\n",
    "    with torch.no_grad():\n",
    "        codes = funcmol_ddpm.sample_ddpm(shape=(1, grid_size**3, code_dim), progress=False)\n",
    "\n",
    "    # 使用统一的场计算函数\n",
    "    field_func = create_field_function(\n",
    "        mode='ddpm',\n",
    "        decoder=decoder,\n",
    "        codes=codes\n",
    "    )\n",
    "    print(\"DDPM fixed codes sampled and field_func set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47b35856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 可视化1D梯度场（仅预测） ===\n",
      "使用默认 x 轴范围: (-5.0, 5.0)\n",
      "Field 1D comparison (atom_type=C) saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39/field_1d_sample_0_atom_C.png\n",
      "Field 1D comparison (atom_type=H) saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39/field_1d_sample_0_atom_H.png\n",
      "Field 1D comparison (atom_type=O) saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39/field_1d_sample_0_atom_O.png\n",
      "Field 1D comparison (atom_type=N) saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39/field_1d_sample_0_atom_N.png\n",
      "Field 1D comparison (atom_type=F) saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39/field_1d_sample_0_atom_F.png\n",
      "Gradient field visualization (generation mode):\n",
      "  Available atom types: [0, 1, 2, 3, 4]\n",
      "  C:\n",
      "    Magnitude: Mean=0.516730, Std=0.219757\n",
      "    Saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39/field_1d_sample_0_atom_C.png\n",
      "  H:\n",
      "    Magnitude: Mean=0.636047, Std=0.222101\n",
      "    Saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39/field_1d_sample_0_atom_H.png\n",
      "  O:\n",
      "    Magnitude: Mean=0.831528, Std=0.447681\n",
      "    Saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39/field_1d_sample_0_atom_O.png\n",
      "  N:\n",
      "    Magnitude: Mean=0.540592, Std=0.241827\n",
      "    Saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39/field_1d_sample_0_atom_N.png\n",
      "  F:\n",
      "    Magnitude: Mean=0.528057, Std=0.280481\n",
      "    Saved to: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251101/model-epoch=39/field_1d_sample_0_atom_F.png\n"
     ]
    }
   ],
   "source": [
    "if option != 'denoiser_only':\n",
    "    # 可视化一维梯度场对比（所有原子类型）\n",
    "    atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
    "    save_path = os.path.join(output_dir, f\"field1d_sample_{sample_idx}\")\n",
    "\n",
    "    gradient_results = visualize_1d_gradient_field_comparison(\n",
    "        gt_coords=gt_coords,\n",
    "        gt_types=gt_types,\n",
    "        converter=converter,\n",
    "        field_func=field_func,\n",
    "        sample_idx=0,  # 数据中只有1个样本，所以用索引0\n",
    "        atom_types=atom_types,  # 传入列表，不需要循环\n",
    "        x_range=None,\n",
    "        y_coord=0.0,\n",
    "        z_coord=0.0,\n",
    "        save_path=save_path,  # save_path已经包含了正确的sample_idx (14441)\n",
    "        display_sample_idx=sample_idx,  # 用于文件名和显示的原始样本索引\n",
    "    )\n",
    "\n",
    "    if gradient_results:\n",
    "        print(f\"Gradient field comparison (model: {model_dir}):\")\n",
    "        print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
    "        \n",
    "        # 打印每个原子类型的统计信息\n",
    "        for atom_name, stats in gradient_results['all_results'].items():\n",
    "            print(f\"  {atom_name}: MSE={stats['mse']:.6f}, MAE={stats['mae']:.6f}\")\n",
    "            print(f\"    Saved to: {stats['save_path']}\")\n",
    "\n",
    "elif option == 'denoiser_only':\n",
    "    # 可视化denoiser生成的codes对应的梯度场在1维上的变化曲线\n",
    "    print(\"\\n=== 可视化1D梯度场（仅预测） ===\")\n",
    "    \n",
    "    # 使用统一的场计算函数\n",
    "    atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
    "    save_path = os.path.join(output_dir, f\"field1d_gen_sample_0\")\n",
    "    \n",
    "    # 调用修改后的函数，不传入gt_coords和gt_types，只绘制预测的梯度场\n",
    "    gradient_results = visualize_1d_gradient_field_comparison(\n",
    "        gt_coords=None,  # 无ground truth\n",
    "        gt_types=None,   # 无ground truth\n",
    "        converter=None,  # 无ground truth时converter可以为None\n",
    "        field_func=field_func,\n",
    "        sample_idx=0,\n",
    "        atom_types=atom_types,\n",
    "        x_range=None,  # 使用默认范围(-5.0, 5.0)\n",
    "        y_coord=0.0,\n",
    "        z_coord=0.0,\n",
    "        save_path=save_path,\n",
    "        display_sample_idx=0,\n",
    "    )\n",
    "    \n",
    "    if gradient_results:\n",
    "        print(f\"Gradient field visualization (generation mode):\")\n",
    "        print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
    "        \n",
    "        # 打印每个原子类型的统计信息\n",
    "        for atom_name, stats in gradient_results['all_results'].items():\n",
    "            print(f\"  {atom_name}:\")\n",
    "            print(f\"    Magnitude: Mean={stats.get('magnitude_mean', 'N/A'):.6f}, Std={stats.get('magnitude_std', 'N/A'):.6f}\")\n",
    "            print(f\"    Saved to: {stats['save_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927131ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 执行 DDPM(new) 分子生成 ===\n",
      "Generating molecular field and reconstructing molecule (fixed DDPM codes)...\n",
      ">>     Memory status at iteration 0: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 50: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 100: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 150: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 200: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 250: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 300: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 350: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 400: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 450: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 500: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 550: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 600: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 650: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 700: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 750: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 800: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 850: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 900: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 950: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1000: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1050: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1100: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1150: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1200: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1250: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1300: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1350: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1400: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1450: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1500: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1550: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1600: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1650: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1700: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1750: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1800: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1850: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1900: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 1950: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2000: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2050: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2100: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2150: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2200: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2250: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2300: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2350: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2400: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2450: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2500: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2550: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2600: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2650: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2700: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2750: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2800: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2850: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2900: Allocated=0.02GB, Reserved=0.77GB\n",
      ">>     Memory status at iteration 2950: Allocated=0.02GB, Reserved=0.77GB\n",
      "[DBSCAN] Total points: 1000, Clusters found: 20, Noise points: 303\n",
      "[DBSCAN] Total points: 1000, Clusters found: 18, Noise points: 212\n",
      "[DBSCAN] Total points: 1000, Clusters found: 18, Noise points: 345\n",
      "[DBSCAN] Total points: 1000, Clusters found: 19, Noise points: 212\n",
      "[DBSCAN] Total points: 1000, Clusters found: 16, Noise points: 440\n",
      "Generated molecule: 91 atoms\n",
      "Atom types: [0, 1, 2, 3, 4]\n",
      "Creating generation process animation with fixed DDPM codes...\n",
      "\n",
      "Starting generation for molecule 0\n",
      "Using intelligent sampling method...\n"
     ]
    }
   ],
   "source": [
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，使用DDPM采样得到固定codes并可视化\n",
    "    print(\"\\n=== 执行 DDPM(new) 分子生成 ===\")\n",
    "\n",
    "    grid_size = config.dset.grid_size\n",
    "    code_dim = config.encoder.code_dim\n",
    "\n",
    "    # 使用上一个单元已采样的固定 codes\n",
    "    print(\"Generating molecular field and reconstructing molecule (fixed DDPM codes)...\")\n",
    "    recon_coords, recon_types = converter.gnf2mol(\n",
    "        decoder,\n",
    "        codes,\n",
    "        fabric=fabric\n",
    "    )\n",
    "\n",
    "    print(f\"Generated molecule: {recon_coords[0].shape[0]} atoms\")\n",
    "    print(f\"Atom types: {recon_types[0].unique().tolist()}\")\n",
    "\n",
    "    # 创建生成过程动画（固定 codes，避免每帧变化）\n",
    "    print(\"Creating generation process animation with fixed DDPM codes...\")\n",
    "    visualizer = GNFVisualizer(output_dir)\n",
    "\n",
    "    # 使用Cell 5中已创建的场计算函数，避免重复创建\n",
    "    # fixed_generation_field_func 作为别名用于代码可读性\n",
    "    fixed_generation_field_func = field_func\n",
    "\n",
    "    results = visualizer.create_generation_animation(\n",
    "        converter=converter,\n",
    "        field_func=field_func,\n",
    "        sample_idx=0,\n",
    "        save_interval=100,\n",
    "        create_1d_plots=False,\n",
    "        use_recon_dir=False,\n",
    "        fixed_axis=True,\n",
    "        use_intelligent_sampling=True,\n",
    "        decoder=decoder,\n",
    "        codes=codes,\n",
    "        fabric=fabric\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== DDPM Field 生成结果 ===\")\n",
    "    print(f\"Generated atoms: {recon_coords[0].shape[0]}\")\n",
    "    print(f\"Atom type distribution: {dict(zip(*torch.unique(recon_types[0], return_counts=True)))}\")\n",
    "    print(f\"最终分子图: {results['final_path']}\")\n",
    "    print(f\"最终分子图: {results['final_path']}\")\n",
    "    print(f\"生成过程动画: {results['gif_path']}\")\n",
    "    \n",
    "else:\n",
    "    # 根据option设置重建列表\n",
    "    if option == 'gt_only':\n",
    "        rec_list = ['gt_field']\n",
    "    else:\n",
    "        rec_list = ['predicted_field', 'gt_field']\n",
    "\n",
    "    # 创建可视化器\n",
    "    visualizer = GNFVisualizer(output_dir)\n",
    "\n",
    "    # 为每种重建类型执行可视化\n",
    "    for rec_type in rec_list:\n",
    "        print(f\"\\n=== 执行 {rec_type} 重建 ===\")\n",
    "        \n",
    "        # 根据重建类型设置场函数\n",
    "        if rec_type == 'gt_field':\n",
    "            # 使用统一的场计算函数\n",
    "            field_func = create_field_function(\n",
    "                mode='gt',\n",
    "                converter=converter,\n",
    "                gt_coords=gt_coords,\n",
    "                gt_types=gt_types\n",
    "            )\n",
    "        else:  # predicted_field\n",
    "            # 使用统一的场计算函数\n",
    "            field_func = create_field_function(\n",
    "                mode='predicted',\n",
    "                decoder=decoder,\n",
    "                codes=codes\n",
    "            )\n",
    "        \n",
    "        # 执行重建可视化\n",
    "        results = visualizer.create_reconstruction_animation(\n",
    "            gt_coords=gt_coords,\n",
    "            gt_types=gt_types,\n",
    "            converter=converter,\n",
    "            field_func=field_func,\n",
    "            save_interval=100,\n",
    "            animation_name=f\"recon_sample_{sample_idx}_{rec_type}\",\n",
    "            sample_idx=0\n",
    "        )\n",
    "\n",
    "        print(f\"\\n=== {rec_type} 重建结果 ===\")\n",
    "        print(f\"RMSD: {results['final_rmsd']:.4f}\")\n",
    "        print(f\"Reconstruction Loss: {results['final_loss']:.4f}\")\n",
    "        print(f\"KL Divergence (orig->recon): {results['final_kl_1to2']:.4f}\")\n",
    "        print(f\"KL Divergence (recon->orig): {results['final_kl_2to1']:.4f}\")\n",
    "        print(f\"GIF动画: {results['gif_path']}\")\n",
    "        print(f\"对比图: {results['comparison_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funcmol_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
