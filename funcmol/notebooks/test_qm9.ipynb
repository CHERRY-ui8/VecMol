{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "2a52041c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/funcmol/notebooks\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# %cd /home/huayuchen/Neurl-voxel/funcmol/notebooks\n",
        "%cd /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/funcmol/notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "7dbf18ae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield\n",
            "Python path: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield\n",
            "Dataset directory: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/funcmol/dataset/data\n",
            "Config loaded successfully: train_nf_qm9\n",
            "n_iter from converter config: 400\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
        "\n",
        "import torch\n",
        "import hydra\n",
        "import numpy as np\n",
        "import random\n",
        "from pathlib import Path\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "# 设置 torch.compile 兼容性\n",
        "try:\n",
        "    import torch._dynamo\n",
        "    torch._dynamo.config.suppress_errors = True\n",
        "except ImportError:\n",
        "    # PyTorch 版本 < 2.0 不支持 torch._dynamo\n",
        "    print(\"Warning: torch._dynamo not available in this PyTorch version\")\n",
        "\n",
        "## set up environment\n",
        "# 使用硬编码的项目根目录，确保路径一致性\n",
        "# 所有路径都基于 /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield\n",
        "project_root = Path(\"/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield\")\n",
        "sys.path.insert(0, str(project_root))\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Python path: {sys.path[0]}\")\n",
        "\n",
        "from funcmol.dataset.dataset_field import create_gnf_converter, prepare_data_with_sample_idx\n",
        "from funcmol.utils.utils_nf import load_neural_field\n",
        "from funcmol.utils.utils_fm import load_checkpoint_fm\n",
        "from funcmol.utils.constants import PADDING_INDEX\n",
        "from funcmol.utils.gnf_visualizer import (\n",
        "    visualize_1d_gradient_field_comparison, \n",
        "    GNFVisualizer,\n",
        "    visualize_generated_molecule,\n",
        "    create_visualization_callback,\n",
        "    create_gif_from_frames\n",
        ")\n",
        "from funcmol.utils.misc import load_nf_config, load_funcmol_config, create_field_function\n",
        "from funcmol.models.funcmol import FuncMol\n",
        "\n",
        "seed = 1234\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# 模型根目录（与项目根目录保持一致）\n",
        "model_root = str(project_root / \"exps\" / \"neural_field\")\n",
        "config = load_nf_config(\"train_nf_qm9\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "91676465",
      "metadata": {},
      "outputs": [],
      "source": [
        "##### SETTINGS #####\n",
        "# TODO：手动指定是 gt_only、gt_pred 还是 denoiser_only 模式\n",
        "option = 'denoiser_only'  # 'gt_only', 'gt_pred', 'denoiser_only'\n",
        "\n",
        "# TODO：手动指定 checkpoint 文件路径，会根据ckpt_path自动提取exp_name\n",
        "nf_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251121/lightning_logs/version_1/checkpoints/model-epoch=999.ckpt'\n",
        "fm_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/lightning_logs/version_1/checkpoints/last.ckpt'\n",
        "# nf_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/model-epoch=409.ckpt'\n",
        "# fm_ckpt_path = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251108/lightning_logs/version_1/checkpoints/last.ckpt'\n",
        "# nf_ckpt_path = '/home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20250911/lightning_logs/version_1/checkpoints/model-epoch=39.ckpt'\n",
        "# fm_ckpt_path = '/home/huayuchen/Neurl-voxel/exps/funcmol/fm_qm9/20250917/lightning_logs/version_22/checkpoints/model-epoch=144.ckpt'\n",
        "\n",
        "# TODO：手动指定 sample_idx（仅用于 gt_only 和 gt_pred 模式）\n",
        "sample_idx = 30  # 2,7,74,83,108,158,186,375,404,433\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# TODO：手动指定 codes 编号 （仅用于 denoiser_only 模式）\n",
        "# codes_source = 'load'  # 'load' 或 'sample' \n",
        "codes_source = 'load'  # 'load' 或 'sample' \n",
        "\n",
        "# TODO：手动指定 codes 目录（仅用于 denoiser_only 模式且 codes_source='load'）\n",
        "# 例如：'/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251223/samples/20251223_version_2_last/molecule'\n",
        "codes_idx = 0  # 例如：0 表示 code_0000_tanh.pt\n",
        "codes_dir = '/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251223/samples/20251223_version_2_last/molecule'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "23544d3c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Option: denoiser_only\n",
            "FuncMol model directory: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225\n",
            "FuncMol checkpoint: last\n",
            "Neural Field checkpoint: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251121/lightning_logs/version_1/checkpoints/model-epoch=999.ckpt\n",
            "Output directory: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last\n"
          ]
        }
      ],
      "source": [
        "if option == 'denoiser_only':\n",
        "    # 对于 denoiser_only 模式，使用 FuncMol 的路径\n",
        "    ckpt_parts = Path(fm_ckpt_path).parts\n",
        "    funcmol_idx = ckpt_parts.index('funcmol')\n",
        "    exp_name = f\"{ckpt_parts[funcmol_idx + 1]}/{ckpt_parts[funcmol_idx + 2]}\"  # fm_qm9/20250912\n",
        "    ckpt_name = Path(fm_ckpt_path).stem  # funcmol-epoch=319\n",
        "    model_dir = os.path.join(\"/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol\", exp_name)\n",
        "    output_dir = os.path.join(model_dir, \"visualize\", f\"{Path(fm_ckpt_path).parent.parent.name}_{Path(fm_ckpt_path).parent.name}_{ckpt_name}\")\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"Option: {option}\")\n",
        "    print(f\"FuncMol model directory: {model_dir}\")\n",
        "    print(f\"FuncMol checkpoint: {ckpt_name}\")\n",
        "    print(f\"Neural Field checkpoint: {nf_ckpt_path}\")\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "else:\n",
        "    # 对于 gt_only 和 gt_pred 模式，使用 Neural Field 的路径\n",
        "    ckpt_parts = Path(nf_ckpt_path).parts\n",
        "    neural_field_idx = ckpt_parts.index('neural_field')\n",
        "    exp_name = f\"{ckpt_parts[neural_field_idx + 1]}/{ckpt_parts[neural_field_idx + 2]}\"  # nf_qm9/20250911\n",
        "    ckpt_name = Path(nf_ckpt_path).stem  # model-epoch=39\n",
        "    model_dir = os.path.join(model_root, exp_name)\n",
        "    output_dir = os.path.join(model_dir, ckpt_name)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    batch, gt_coords, gt_types = prepare_data_with_sample_idx(config, device, sample_idx)\n",
        "    print(f\"Data loaded for sample {sample_idx}: {gt_coords.shape}, {gt_types.shape}\")\n",
        "    print(f\"Option: {option}\")\n",
        "    print(f\"Model directory: {model_dir}\")\n",
        "    print(f\"Checkpoint: {ckpt_name}\")\n",
        "    print(f\"Output directory: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "de1c8d5d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Neural Field model from: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251121/lightning_logs/version_1/checkpoints/model-epoch=999.ckpt\n",
            "Loading Lightning checkpoint from: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251121/lightning_logs/version_1/checkpoints/model-epoch=999.ckpt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> loaded dec\n",
            ">> loaded enc\n",
            "Model loaded successfully!\n",
            "Loading configuration from YAML: train_fm_qm9\n",
            ">> Using diffusion_method: new_x0\n",
            ">> DDPM config: {'num_timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02, 'schedule': 'cosine', 's': 0.008, 's1': 0.008, 'sT': 0.008, 'w': 1.0, 'use_time_weight': False}\n",
            ">> loaded denoiser\n",
            ">> loaded model trained for 89 epochs\n",
            ">> FuncMol model loaded successfully!\n",
            "[ClusteringProcessor] enable_bond_validation = True\n",
            "使用手动指定的 codes 目录:\n",
            "  codes_dir: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251223/samples/20251223_version_2_last/molecule\n",
            "  文件名格式: code_0000_tanh.pt\n",
            "\n",
            "最终使用的codes路径: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251223/samples/20251223_version_2_last/molecule/code_0000_tanh.pt\n",
            "Loading codes from: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251223/samples/20251223_version_2_last/molecule/code_0000_tanh.pt\n",
            "Loaded codes shape: torch.Size([1, 729, 128])\n",
            "Codes loaded/sampled and field_func set.\n",
            "[ClusteringProcessor] enable_bond_validation = True\n",
            "\n",
            "=== Converter 参数 ===\n",
            "step_size: 0.03\n",
            "eps: 0.05\n",
            "min_samples: 5\n",
            "field_variance_k_neighbors: 10\n",
            "field_variance_weight: 0.01\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "## Load model, generate or load codes\n",
        "if option == 'denoiser_only':       \n",
        "    print(f\"Loading Neural Field model from: {nf_ckpt_path}\")\n",
        "    encoder, decoder = load_neural_field(nf_ckpt_path, config)\n",
        "    # 确保模型在正确的设备上\n",
        "    encoder = encoder.to(device)\n",
        "    decoder = decoder.to(device)\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    \n",
        "    # 使用YAML配置文件加载FuncMol配置\n",
        "    funcmol_config = load_funcmol_config(\"train_fm_qm9\", config)\n",
        "    \n",
        "    # 创建FuncMol模型\n",
        "    funcmol = FuncMol(funcmol_config)\n",
        "    funcmol = funcmol.to(device)\n",
        "    \n",
        "    # 加载checkpoint并获取code_stats\n",
        "    funcmol, code_stats = load_checkpoint_fm(funcmol, fm_ckpt_path)\n",
        "    funcmol.eval()\n",
        "    \n",
        "    # 设置decoder的code_stats\n",
        "    decoder.set_code_stats(code_stats)\n",
        "    \n",
        "    print(\">> FuncMol model loaded successfully!\")\n",
        "    configs_dir = project_root / \"funcmol\" / \"configs\"\n",
        "    with hydra.initialize_config_dir(config_dir=str(configs_dir), version_base=None):\n",
        "        sample_fm_config = hydra.compose(config_name=\"sample_fm\")\n",
        "    \n",
        "    # 转换为字典格式（与 sample_fm.py 第51行完全一致）\n",
        "    config_dict = OmegaConf.to_container(sample_fm_config, resolve=True)\n",
        "        \n",
        "    # 创建 converter（与 sample_fm.py 第151行完全一致）\n",
        "    converter = create_gnf_converter(config_dict)\n",
        "    \n",
        "    # 获取 codes 的维度信息\n",
        "    grid_size = config_dict.get('dset', {}).get('grid_size', 9)  # 与 sample_fm.py 一致\n",
        "    code_dim = config_dict.get('encoder', {}).get('code_dim', 128)  # 与 sample_fm.py 一致\n",
        "    \n",
        "    if codes_source == 'load':\n",
        "        mol_save_dir = Path(codes_dir)\n",
        "        \n",
        "        code_path = mol_save_dir / f\"code_{codes_idx:04d}_tanh.pt\"\n",
        "        print(f\"使用手动指定的 codes 目录:\")\n",
        "        print(f\"  codes_dir: {codes_dir}\")\n",
        "        print(f\"  文件名格式: code_{codes_idx:04d}_tanh.pt\")\n",
        "        print(f\"\\n最终使用的codes路径: {code_path}\")\n",
        "        \n",
        "        if not code_path.exists():\n",
        "            raise FileNotFoundError(\n",
        "                f\"Codes file not found: {code_path}\\n\"\n",
        "                f\"Please check if the file exists or verify the codes_dir path.\"\n",
        "            )\n",
        "        \n",
        "        print(f\"Loading codes from: {code_path}\")\n",
        "        codes = torch.load(code_path, map_location=device)\n",
        "        # 确保codes的形状正确 [1, grid_size^3, code_dim]\n",
        "        if codes.dim() == 2:\n",
        "            # 如果是 [grid_size^3, code_dim]，添加batch维度\n",
        "            codes = codes.unsqueeze(0)\n",
        "        print(f\"Loaded codes shape: {codes.shape}\")\n",
        "        \n",
        "    else:\n",
        "        # 随机采样 codes\n",
        "        print(\"Sampling codes using DDPM...\")\n",
        "        with torch.no_grad():\n",
        "            codes = funcmol.sample_ddpm(shape=(1, grid_size**3, code_dim), progress=False)\n",
        "        print(f\"Sampled codes shape: {codes.shape}\")\n",
        "\n",
        "    # 使用统一的场计算函数（ddpm模式，使用已加载/采样的codes）\n",
        "    field_func = create_field_function(\n",
        "        mode='ddpm',\n",
        "        decoder=decoder,\n",
        "        codes=codes\n",
        "    )\n",
        "    print(\"Codes loaded/sampled and field_func set.\")\n",
        "    \n",
        "    \n",
        "elif option == 'gt_pred':\n",
        "    # 使用手动指定的 checkpoint 文件路径\n",
        "    if not os.path.exists(nf_ckpt_path):\n",
        "        raise FileNotFoundError(f\"Checkpoint file not found: {nf_ckpt_path}\")\n",
        "    \n",
        "    print(f\"Loading model from: {nf_ckpt_path}\")\n",
        "    encoder, decoder = load_neural_field(nf_ckpt_path, config)\n",
        "    \n",
        "    # 确保模型在正确的设备上\n",
        "    encoder = encoder.to(device)\n",
        "    decoder = decoder.to(device)\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    \n",
        "    # 生成 codes\n",
        "    print(f\"Batch device: {batch.pos.device}\")\n",
        "    print(f\"Encoder device: {next(encoder.parameters()).device}\")\n",
        "    print(f\"Batch size (number of graphs): {batch.num_graphs}\")\n",
        "    with torch.no_grad():\n",
        "        codes = encoder(batch)\n",
        "    print(f\"Codes shape: {codes.shape}\")\n",
        "    \n",
        "    # 使用统一的场计算函数\n",
        "    field_func = create_field_function(\n",
        "        mode='predicted',\n",
        "        decoder=decoder,\n",
        "        codes=codes\n",
        "    )\n",
        "else:  # gt only\n",
        "    encoder, decoder = None, None\n",
        "    codes = None\n",
        "\n",
        "converter = create_gnf_converter(config)\n",
        "\n",
        "# 打印 converter 的关键参数\n",
        "print(f\"\\n=== Converter 参数 ===\")\n",
        "print(f\"step_size: {converter.step_size}\")\n",
        "print(f\"eps: {converter.eps}\")\n",
        "print(f\"min_samples: {converter.min_samples}\")\n",
        "# field 参数\n",
        "print(f\"field_variance_k_neighbors: {converter.field_variance_k_neighbors}\")\n",
        "print(f\"field_variance_weight: {converter.field_variance_weight}\")\n",
        "\n",
        "# 创建场函数（在converter定义之后）\n",
        "if option == 'gt_only':\n",
        "    field_func = create_field_function(\n",
        "        mode='gt',\n",
        "        converter=converter,\n",
        "        gt_coords=gt_coords,\n",
        "        gt_types=gt_types\n",
        "    )\n",
        "print(f\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce76f71a",
      "metadata": {},
      "source": [
        "plot field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "47b35856",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 可视化1D梯度场（仅预测） ===\n",
            "使用默认 x 轴范围: (-11.0, 11.0)\n",
            "Field 1D comparison (atom_type=C) saved to: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/field_1d_sample_0_atom_C.png\n",
            "Field 1D comparison (atom_type=H) saved to: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/field_1d_sample_0_atom_H.png\n",
            "Field 1D comparison (atom_type=O) saved to: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/field_1d_sample_0_atom_O.png\n",
            "Field 1D comparison (atom_type=N) saved to: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/field_1d_sample_0_atom_N.png\n",
            "Field 1D comparison (atom_type=F) saved to: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/field_1d_sample_0_atom_F.png\n",
            "Gradient field visualization (generation mode):\n",
            "  Available atom types: [0, 1, 2, 3, 4]\n",
            "  C:\n",
            "    Magnitude: Mean=0.471898, Std=0.366171\n",
            "    Saved to: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/field_1d_sample_0_atom_C.png\n",
            "  H:\n",
            "    Magnitude: Mean=0.522638, Std=0.374714\n",
            "    Saved to: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/field_1d_sample_0_atom_H.png\n",
            "  O:\n",
            "    Magnitude: Mean=0.522993, Std=0.386970\n",
            "    Saved to: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/field_1d_sample_0_atom_O.png\n",
            "  N:\n",
            "    Magnitude: Mean=0.492626, Std=0.399980\n",
            "    Saved to: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/field_1d_sample_0_atom_N.png\n",
            "  F:\n",
            "    Magnitude: Mean=0.049909, Std=0.105309\n",
            "    Saved to: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/field_1d_sample_0_atom_F.png\n"
          ]
        }
      ],
      "source": [
        "if option != 'denoiser_only':\n",
        "    # 可视化一维梯度场对比（所有原子类型）\n",
        "    atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
        "    # 将1D可视化结果保存到 experiment 根目录下的 recon_animation 文件夹，避免生成 model-epoch=999 目录\n",
        "    field_1d_output_dir = os.path.join(model_dir, \"recon_animation\")\n",
        "    os.makedirs(field_1d_output_dir, exist_ok=True)\n",
        "    save_path = os.path.join(field_1d_output_dir, f\"field_1d_sample_{sample_idx}\")\n",
        "\n",
        "    gradient_results = visualize_1d_gradient_field_comparison(\n",
        "        gt_coords=gt_coords,\n",
        "        gt_types=gt_types,\n",
        "        converter=converter,\n",
        "        field_func=field_func,\n",
        "        sample_idx=0,  # 数据中只有1个样本，所以用索引0\n",
        "        atom_types=atom_types,  # 传入列表，不需要循环\n",
        "        x_range=None,\n",
        "        y_coord=0.0,\n",
        "        z_coord=0.0,\n",
        "        save_path=save_path,\n",
        "        display_sample_idx=sample_idx,  # 用于文件名和显示的原始样本索引\n",
        "    )\n",
        "\n",
        "    if gradient_results:\n",
        "        print(f\"Gradient field comparison (model: {model_dir}):\")\n",
        "        print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
        "        \n",
        "        # 打印每个原子类型的统计信息\n",
        "        for atom_name, stats in gradient_results['all_results'].items():\n",
        "            print(f\"  {atom_name}: MSE={stats['mse']:.6f}, MAE={stats['mae']:.6f}\")\n",
        "            print(f\"    Saved to: {stats['save_path']}\")\n",
        "\n",
        "elif option == 'denoiser_only':\n",
        "    # 可视化denoiser生成的codes对应的梯度场在1维上的变化曲线\n",
        "    print(\"\\n=== 可视化1D梯度场（仅预测） ===\")\n",
        "    \n",
        "    # 确定文件编号：如果使用load模式，使用codes_idx；否则使用sample_0\n",
        "    if codes_source == 'load':\n",
        "        field1d_idx = codes_idx\n",
        "    else:\n",
        "        field1d_idx = 0\n",
        "    \n",
        "    # 使用统一的场计算函数\n",
        "    atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
        "    save_path = os.path.join(output_dir, f\"field1d_gen_sample_{field1d_idx}\")\n",
        "    \n",
        "    # 调用修改后的函数，不传入gt_coords和gt_types，只绘制预测的梯度场\n",
        "    gradient_results = visualize_1d_gradient_field_comparison(\n",
        "        gt_coords=None,  # 无ground truth\n",
        "        gt_types=None,   # 无ground truth\n",
        "        converter=None,  # 无ground truth时converter可以为None\n",
        "        field_func=field_func,\n",
        "        sample_idx=0,\n",
        "        atom_types=atom_types,\n",
        "        x_range=None,  # 使用默认范围(-5.0, 5.0)\n",
        "        y_coord=0.0,\n",
        "        z_coord=0.0,\n",
        "        save_path=save_path,\n",
        "        display_sample_idx=field1d_idx,  # 使用field1d_idx作为文件名标识符\n",
        "    )\n",
        "    \n",
        "    if gradient_results:\n",
        "        print(f\"Gradient field visualization (generation mode):\")\n",
        "        print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
        "        \n",
        "        # 打印每个原子类型的统计信息\n",
        "        for atom_name, stats in gradient_results['all_results'].items():\n",
        "            print(f\"  {atom_name}:\")\n",
        "            print(f\"    Magnitude: Mean={stats.get('magnitude_mean', 'N/A'):.6f}, Std={stats.get('magnitude_std', 'N/A'):.6f}\")\n",
        "            print(f\"    Saved to: {stats['save_path']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "927131ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 执行 DDPM 分子生成 ===\n",
            "Generating molecular field and reconstructing molecule (loaded codes)...\n",
            "聚类历史将保存到: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/clustering_history\n",
            "  - Converter enable_clustering_history: True\n",
            "  - 样本标识符 (sample_id): 0\n",
            "    [梯度上升] 使用分批处理: 总点数=3350, 批次大小=2000, 批次数=2\n",
            "    [梯度上升] 总迭代数=400, 总时间=23.846s, 平均每次迭代=59.61ms, 分批处理: 总点数=3350, 批次大小=2000, 每迭代批次数=2\n",
            "      [ClusteringProcessor.merge_points_single_iteration] 原子类型: C, iteration: 0, 通过: 6, 拒绝: 0, 用时: 0.14ms\n",
            "\n",
            "============================================================\n",
            "[Iteration 0] 原子类型: C, min_samples=5\n",
            "  处理簇数: 6 (新簇: 6, 待重试: 0)\n",
            "  结果: ✓通过=6, ✗拒绝=0\n",
            "  当前参考点: 6 个, 类型分布: {'C': 6}\n",
            "============================================================\n",
            "      [ClusteringProcessor.merge_points_single_iteration] 原子类型: H, iteration: 0, 通过: 6, 拒绝: 0, 用时: 0.14ms\n",
            "\n",
            "============================================================\n",
            "[Iteration 0] 原子类型: H, min_samples=5\n",
            "  处理簇数: 6 (新簇: 6, 待重试: 0)\n",
            "  结果: ✓通过=6, ✗拒绝=0\n",
            "  当前参考点: 12 个, 类型分布: {'C': 6, 'H': 6}\n",
            "============================================================\n",
            "      [ClusteringProcessor.merge_points_single_iteration] 原子类型: O, iteration: 0, 通过: 2, 拒绝: 0, 用时: 0.06ms\n",
            "\n",
            "============================================================\n",
            "[Iteration 0] 原子类型: O, min_samples=5\n",
            "  处理簇数: 2 (新簇: 2, 待重试: 0)\n",
            "  结果: ✓通过=2, ✗拒绝=0\n",
            "  当前参考点: 14 个, 类型分布: {'C': 6, 'H': 6, 'O': 2}\n",
            "============================================================\n",
            "      [ClusteringProcessor.merge_points_single_iteration] 原子类型: N, iteration: 0, 通过: 1, 拒绝: 0, 用时: 0.03ms\n",
            "\n",
            "============================================================\n",
            "[Iteration 0] 原子类型: N, min_samples=5\n",
            "  处理簇数: 1 (新簇: 1, 待重试: 0)\n",
            "  结果: ✓通过=1, ✗拒绝=0\n",
            "  当前参考点: 15 个, 类型分布: {'C': 6, 'H': 6, 'O': 2, 'N': 1}\n",
            "============================================================\n",
            "      [ClusteringProcessor.merge_points_single_iteration] 原子类型: F, iteration: 0, 通过: 0, 拒绝: 0, 用时: 0.00ms\n",
            "\n",
            "============================================================\n",
            "[Iteration 0] 原子类型: F, min_samples=5\n",
            "  处理簇数: 0 (新簇: 0, 待重试: 0)\n",
            "  结果: ✓通过=0, ✗拒绝=0\n",
            "  当前参考点: 15 个, 类型分布: {'C': 6, 'H': 6, 'O': 2, 'N': 1}\n",
            "============================================================\n",
            "[详细时间] init_sampling=0.000s, candidate_field=0.036s, field_variance=0.002s, point_sampling=0.043s, gradient_ascent=23.863s, clustering=0.023s, total=23.969s\n",
            "[GNFConverter.gnf2mol] Batch 0 timing: predictor=0.000s, process=23.969s, merge=0.001s, connected_component=0.001s, history_io=0.000s, total=23.974s\n",
            "[GNFConverter.gnf2mol] Total time for all batches: 23.975s\n",
            "✗ 聚类历史SDF文件未生成: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/clustering_history/sample_0000_clustering_history.sdf\n",
            "✗ 聚类历史TXT文件未生成: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/clustering_history/sample_0000_clustering_history.txt\n",
            "Generated molecule: 15 atoms\n",
            "Atom types: [0, 1, 2, 3]\n",
            "Creating generation process animation from saved frames...\n",
            "\n",
            "=== DDPM Field 生成结果 ===\n",
            "Generated atoms: 15\n",
            "Atom type distribution: {tensor(0, device='cuda:0'): tensor(6, device='cuda:0'), tensor(1, device='cuda:0'): tensor(6, device='cuda:0'), tensor(2, device='cuda:0'): tensor(2, device='cuda:0'), tensor(3, device='cuda:0'): tensor(1, device='cuda:0')}\n",
            "最终分子图: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/funcmol_gen_sample_0_final.png\n",
            "生成过程动画: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251225/visualize/version_1_checkpoints_last/funcmol_gen_sample_0.gif\n"
          ]
        }
      ],
      "source": [
        "if option == 'denoiser_only':\n",
        "    # 对于 denoiser_only 模式，使用DDPM采样得到固定codes并可视化\n",
        "    print(\"\\n=== 执行 DDPM 分子生成 ===\")\n",
        "\n",
        "    grid_size = config.dset.grid_size\n",
        "    code_dim = config.encoder.code_dim\n",
        "\n",
        "    # 确定文件编号：如果使用load模式，使用codes_idx；否则使用sample_0\n",
        "    if codes_source == 'load':\n",
        "        file_idx = codes_idx\n",
        "    else:\n",
        "        file_idx = 0\n",
        "\n",
        "    # 使用gnf_visualizer中的函数创建可视化回调\n",
        "    visualization_callback, frame_paths, fixed_axis_limits_dict = create_visualization_callback(\n",
        "        output_dir=output_dir,\n",
        "        frame_prefix=f\"frame_gen_sample_{file_idx}\",\n",
        "        codes_device=codes.device,\n",
        "        n_atom_types=5\n",
        "    )\n",
        "\n",
        "    # 使用上一个单元已加载的 codes，重建分子，使用可视化\n",
        "    print(\"Generating molecular field and reconstructing molecule (loaded codes)...\")\n",
        "    save_interval = 100\n",
        "    \n",
        "    # 如果启用了聚类历史记录，则保存聚类历史文件\n",
        "    gnf2mol_kwargs = {\n",
        "        \"decoder\": decoder,\n",
        "        \"codes\": codes,\n",
        "        \"save_interval\": save_interval,\n",
        "        \"visualization_callback\": visualization_callback,\n",
        "        \"enable_timing\": True\n",
        "    }\n",
        "    \n",
        "    # 如果converter启用了聚类历史记录，则保存到文件\n",
        "    if converter.enable_clustering_history:\n",
        "        clustering_history_dir = os.path.join(output_dir, \"clustering_history\")\n",
        "        os.makedirs(clustering_history_dir, exist_ok=True)\n",
        "        gnf2mol_kwargs[\"save_clustering_history\"] = True\n",
        "        gnf2mol_kwargs[\"clustering_history_dir\"] = clustering_history_dir\n",
        "        gnf2mol_kwargs[\"sample_id\"] = file_idx  # 使用file_idx作为样本标识符\n",
        "        print(f\"聚类历史将保存到: {clustering_history_dir}\")\n",
        "        print(f\"  - Converter enable_clustering_history: {converter.enable_clustering_history}\")\n",
        "        print(f\"  - 样本标识符 (sample_id): {file_idx}\")\n",
        "    else:\n",
        "        print(f\"警告: Converter未启用聚类历史记录 (enable_clustering_history={converter.enable_clustering_history})\")\n",
        "    \n",
        "    recon_coords, recon_types = converter.gnf2mol(**gnf2mol_kwargs)\n",
        "    \n",
        "    # 检查聚类历史文件是否已生成\n",
        "    if converter.enable_clustering_history and gnf2mol_kwargs.get(\"save_clustering_history\", False):\n",
        "        clustering_history_dir = gnf2mol_kwargs.get(\"clustering_history_dir\")\n",
        "        if clustering_history_dir:\n",
        "            sdf_file = os.path.join(clustering_history_dir, f\"sample_{file_idx:04d}_clustering_history.sdf\")\n",
        "            txt_file = os.path.join(clustering_history_dir, f\"sample_{file_idx:04d}_clustering_history.txt\")\n",
        "            if os.path.exists(sdf_file):\n",
        "                print(f\"✓ 聚类历史SDF文件已生成: {sdf_file}\")\n",
        "            else:\n",
        "                print(f\"✗ 聚类历史SDF文件未生成: {sdf_file}\")\n",
        "            if os.path.exists(txt_file):\n",
        "                print(f\"✓ 聚类历史TXT文件已生成: {txt_file}\")\n",
        "            else:\n",
        "                print(f\"✗ 聚类历史TXT文件未生成: {txt_file}\")\n",
        "    \n",
        "    print(f\"Generated molecule: {recon_coords[0].shape[0]} atoms\")\n",
        "    print(f\"Atom types: {recon_types[0].unique().tolist()}\")\n",
        "\n",
        "    # 创建 GIF 动画（使用gnf_visualizer中的函数）\n",
        "    print(\"Creating generation process animation from saved frames...\")\n",
        "    gif_path = os.path.join(output_dir, f\"funcmol_gen_sample_{file_idx}.gif\")\n",
        "    create_gif_from_frames(\n",
        "        frame_paths=frame_paths,\n",
        "        gif_path=gif_path,\n",
        "        duration=0.1,\n",
        "        fps=15,\n",
        "        loop=1,\n",
        "        cleanup_frames=True\n",
        "    )\n",
        "\n",
        "    # 保存最终生成的分子\n",
        "    final_path = os.path.join(output_dir, f\"funcmol_gen_sample_{file_idx}_final.png\")\n",
        "    # 过滤掉填充的原子（类型为-1的原子）\n",
        "    valid_mask = recon_types[0] != -1\n",
        "    if valid_mask.any():\n",
        "        final_coords_valid = recon_coords[0][valid_mask]\n",
        "        final_types_valid = recon_types[0][valid_mask]\n",
        "        visualize_generated_molecule(\n",
        "            final_coords_valid, final_types_valid, save_path=final_path\n",
        "        )\n",
        "    else:\n",
        "        print(\"Warning: No valid atoms generated\")\n",
        "\n",
        "    print(f\"\\n=== DDPM Field 生成结果 ===\")\n",
        "    print(f\"Generated atoms: {recon_coords[0].shape[0]}\")\n",
        "    print(f\"Atom type distribution: {dict(zip(*torch.unique(recon_types[0], return_counts=True)))}\")\n",
        "    print(f\"最终分子图: {final_path}\")\n",
        "    print(f\"生成过程动画: {gif_path}\")\n",
        "    \n",
        "else:\n",
        "    # 根据option设置重建列表\n",
        "    if option == 'gt_only':\n",
        "        rec_list = ['gt_field']\n",
        "    else:\n",
        "        rec_list = ['predicted_field', 'gt_field']\n",
        "\n",
        "    # 创建可视化器（将重建动画统一保存到 experiment 根目录下的 recon_animation 文件夹）\n",
        "    recon_output_dir = os.path.join(model_dir, \"recon_animation\")\n",
        "    os.makedirs(recon_output_dir, exist_ok=True)\n",
        "    visualizer = GNFVisualizer(recon_output_dir)\n",
        "\n",
        "    # 为每种重建类型执行可视化\n",
        "    for rec_type in rec_list:\n",
        "        print(f\"\\n=== 执行 {rec_type} 重建 ===\")\n",
        "        \n",
        "        # 根据重建类型设置decoder和codes（使用与gnf2mol相同的方法）\n",
        "        if rec_type == 'gt_field':\n",
        "            # 对于gt_field模式，创建dummy decoder和codes\n",
        "            grid_size = config.dset.grid_size\n",
        "            code_dim = config.encoder.code_dim\n",
        "            dummy_codes = torch.randn(1, grid_size**3, code_dim, device=gt_coords.device)\n",
        "            \n",
        "            # 创建dummy decoder，返回ground truth field\n",
        "            class DummyDecoder:\n",
        "                def __init__(self, converter, gt_coords, gt_types):\n",
        "                    self.converter = converter\n",
        "                    self.gt_coords = gt_coords\n",
        "                    self.gt_types = gt_types\n",
        "                \n",
        "                def __call__(self, query_points, codes):\n",
        "                    return self.converter.mol2gnf(\n",
        "                        self.gt_coords.unsqueeze(0), \n",
        "                        self.gt_types.unsqueeze(0), \n",
        "                        query_points\n",
        "                    )\n",
        "            \n",
        "            # 过滤掉padding的原子\n",
        "            gt_mask = (gt_types[0] != PADDING_INDEX)\n",
        "            gt_valid_coords_for_decoder = gt_coords[0][gt_mask]\n",
        "            gt_valid_types_for_decoder = gt_types[0][gt_mask]\n",
        "            \n",
        "            dummy_decoder = DummyDecoder(converter, gt_valid_coords_for_decoder, gt_valid_types_for_decoder)\n",
        "            rec_decoder = dummy_decoder\n",
        "            rec_codes = dummy_codes\n",
        "        else:  # predicted_field\n",
        "            # 对于predicted_field模式，直接使用decoder和codes\n",
        "            rec_decoder = decoder\n",
        "            rec_codes = codes\n",
        "        \n",
        "        # 执行重建可视化（使用gnf2mol方法，与field_recon.py完全一致）\n",
        "        results = visualizer.create_reconstruction_animation(\n",
        "            gt_coords=gt_coords,\n",
        "            gt_types=gt_types,\n",
        "            converter=converter,\n",
        "            decoder=rec_decoder,\n",
        "            codes=rec_codes,\n",
        "            save_interval=100,\n",
        "            animation_name=f\"recon_sample_{sample_idx}_{rec_type}\",\n",
        "            sample_idx=sample_idx\n",
        "        )\n",
        "\n",
        "        print(f\"\\n=== {rec_type} 重建结果 ===\")\n",
        "        print(f\"RMSD: {results['final_rmsd']:.4f}\")\n",
        "        print(f\"Reconstruction Loss: {results['final_loss']:.4f}\")\n",
        "        print(f\"KL Divergence (orig->recon): {results['final_kl_1to2']:.4f}\")\n",
        "        print(f\"KL Divergence (recon->orig): {results['final_kl_2to1']:.4f}\")\n",
        "        print(f\"GIF动画: {results['gif_path']}\")\n",
        "        print(f\"对比图: {results['comparison_path']}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "funcmol_oss",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
