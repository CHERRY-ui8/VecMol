{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a52041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7dbf18ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import hydra\n",
    "from pathlib import Path\n",
    "from lightning import Fabric\n",
    "\n",
    "# 设置 torch.compile 兼容性\n",
    "try:\n",
    "    import torch._dynamo\n",
    "    torch._dynamo.config.suppress_errors = True\n",
    "except ImportError:\n",
    "    # PyTorch 版本 < 2.0 不支持 torch._dynamo\n",
    "    print(\"Warning: torch._dynamo not available in this PyTorch version\")\n",
    "\n",
    "## set up environment\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from funcmol.utils.constants import PADDING_INDEX\n",
    "from funcmol.utils.gnf_visualizer import (\n",
    "    load_config, load_model, create_converter, \n",
    "    prepare_data, prepare_data_with_sample_idx, visualize_1d_gradient_field_comparison,\n",
    "    GNFVisualizer\n",
    ")\n",
    "\n",
    "# 模型根目录\n",
    "model_root = \"/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/neural_field\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23544d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option: denoiser_only\n",
      "FuncMol model directory: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20250912\n",
      "FuncMol checkpoint: last\n",
      "Neural Field checkpoint: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20250911/lightning_logs/version_1/checkpoints/model-epoch=39.ckpt\n",
      "Output directory: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20250912/last\n"
     ]
    }
   ],
   "source": [
    "# TODO：手动指定是 gt_only、gt_pred 还是 denoiser_only 模式\n",
    "option = 'denoiser_only'  # 'gt_only', 'gt_pred', 'denoiser_only'\n",
    "\n",
    "# TODO：手动指定 checkpoint 文件路径，会根据ckpt_path自动提取exp_name\n",
    "nf_ckpt_path = '/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20250911/lightning_logs/version_1/checkpoints/model-epoch=39.ckpt'\n",
    "fm_ckpt_path = '/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20250912/lightning_logs/version_0/checkpoints/last.ckpt'\n",
    "\n",
    "# TODO：手动指定 sample_idx（仅用于 gt_only 和 gt_pred 模式）\n",
    "sample_idx = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，使用 FuncMol 的路径\n",
    "    ckpt_parts = Path(fm_ckpt_path).parts\n",
    "    funcmol_idx = ckpt_parts.index('funcmol')\n",
    "    exp_name = f\"{ckpt_parts[funcmol_idx + 1]}/{ckpt_parts[funcmol_idx + 2]}\"  # fm_qm9/20250912\n",
    "    ckpt_name = Path(fm_ckpt_path).stem  # funcmol-epoch=319\n",
    "    model_dir = os.path.join(\"/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol\", exp_name)\n",
    "    output_dir = os.path.join(model_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Option: {option}\")\n",
    "    print(f\"FuncMol model directory: {model_dir}\")\n",
    "    print(f\"FuncMol checkpoint: {ckpt_name}\")\n",
    "    print(f\"Neural Field checkpoint: {nf_ckpt_path}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "else:\n",
    "    # 对于 gt_only 和 gt_pred 模式，使用 Neural Field 的路径\n",
    "    ckpt_parts = Path(nf_ckpt_path).parts\n",
    "    neural_field_idx = ckpt_parts.index('neural_field')\n",
    "    exp_name = f\"{ckpt_parts[neural_field_idx + 1]}/{ckpt_parts[neural_field_idx + 2]}\"  # nf_qm9/20250911\n",
    "    ckpt_name = Path(nf_ckpt_path).stem  # model-epoch=39\n",
    "    model_dir = os.path.join(model_root, exp_name)\n",
    "    output_dir = os.path.join(model_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Option: {option}\")\n",
    "    print(f\"Model directory: {model_dir}\")\n",
    "    print(f\"Checkpoint: {ckpt_name}\")\n",
    "    print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ceafdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/funcmol/dataset/data\n",
      "Config loaded successfully: train_nf_qm9\n",
      "n_iter from converter config: 1000\n",
      "Denoiser-only mode: No dataset loading required\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "fabric = Fabric(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    precision=\"32-true\",\n",
    "    strategy=\"auto\"\n",
    ")\n",
    "fabric.launch()\n",
    "\n",
    "# 使用 load_config 函数从 configs 目录加载配置\n",
    "config = load_config(\"train_nf_qm9\")\n",
    "\n",
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，不需要加载数据集\n",
    "    batch, gt_coords, gt_types = None, None, None\n",
    "    print(\"Denoiser-only mode: No dataset loading required\")\n",
    "else:\n",
    "    # 准备包含特定样本的数据\n",
    "    batch, gt_coords, gt_types = prepare_data_with_sample_idx(fabric, config, device, sample_idx)\n",
    "    print(f\"Data loaded for sample {sample_idx}: {gt_coords.shape}, {gt_types.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b023b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing model from: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20250912\n",
      "Loading Neural Field model from: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20250911/lightning_logs/version_1/checkpoints/model-epoch=39.ckpt\n",
      "Loading Lightning checkpoint from: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20250911/lightning_logs/version_1/checkpoints/model-epoch=39.ckpt\n",
      "Model loaded successfully!\n",
      "Loading FuncMol model from: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20250912/lightning_logs/version_0/checkpoints/last.ckpt\n",
      ">> loaded denoiser\n",
      ">> loaded model trained for 1284 epochs\n",
      "GNF Converter created with n_iter: 1000, gradient_field_method: tanh, n_atom_types: 5\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nProcessing model from: {model_dir}\")\n",
    "\n",
    "## Load model\n",
    "if option == 'denoiser_only':\n",
    "    # 加载 Neural Field 模型和 FuncMol 模型\n",
    "    from funcmol.models.funcmol import FuncMol\n",
    "    from funcmol.utils.utils_fm import load_checkpoint_fm\n",
    "    \n",
    "    # 加载 Neural Field 模型\n",
    "    print(f\"Loading Neural Field model from: {nf_ckpt_path}\")\n",
    "    encoder, decoder = load_model(fabric, config, model_path=nf_ckpt_path)\n",
    "    encoder = fabric.setup_module(encoder)\n",
    "    decoder = fabric.setup_module(decoder)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # 加载 FuncMol 模型\n",
    "    print(f\"Loading FuncMol model from: {fm_ckpt_path}\")\n",
    "    funcmol_config = {\n",
    "        \"smooth_sigma\": 0.5,\n",
    "        \"denoiser\": {\n",
    "            \"use_gnn\": True,\n",
    "            \"n_hidden_units\": 256,\n",
    "            \"num_blocks\": 4,\n",
    "            \"dropout\": 0.1,\n",
    "            \"k_neighbors\": 8,\n",
    "            \"cutoff\": 5.0,\n",
    "            \"radius\": 3.0,\n",
    "            \"use_radius_graph\": True\n",
    "        },\n",
    "        \"encoder\": config.encoder,\n",
    "        \"decoder\": config.decoder,\n",
    "        \"dset\": config.dset\n",
    "    }\n",
    "    funcmol = FuncMol(funcmol_config, fabric)\n",
    "    funcmol = funcmol.cuda()\n",
    "    funcmol, _ = load_checkpoint_fm(funcmol, fm_ckpt_path, fabric=fabric)\n",
    "    funcmol.eval()\n",
    "    \n",
    "    # 定义 denoiser 场函数\n",
    "    def denoiser_field_func(points):\n",
    "        # 生成随机噪声代码\n",
    "        grid_size = config.dset.grid_size\n",
    "        code_dim = config.encoder.code_dim\n",
    "        batch_size = 1\n",
    "        \n",
    "        # 创建随机噪声代码\n",
    "        noise_codes = torch.randn(batch_size, grid_size**3, code_dim, device=points.device)\n",
    "        \n",
    "        # 通过 denoiser 生成分子代码\n",
    "        with torch.no_grad():\n",
    "            denoised_codes = funcmol(noise_codes)\n",
    "        \n",
    "        # 使用 decoder 生成场\n",
    "        if points.dim() == 2:  # [n_points, 3]\n",
    "            points = points.unsqueeze(0)  # [1, n_points, 3]\n",
    "        elif points.dim() == 3:  # [batch, n_points, 3]\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "        \n",
    "        result = decoder(points, denoised_codes[0:1])\n",
    "        if result.dim() == 4:  # [batch, n_points, n_atom_types, 3]\n",
    "            return result[0]  # 取第一个batch\n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    field_func = denoiser_field_func\n",
    "    codes = None  # denoiser 模式不需要预计算的 codes\n",
    "    \n",
    "elif option == 'gt_pred':\n",
    "    # 使用手动指定的 checkpoint 文件路径\n",
    "    if not os.path.exists(nf_ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {nf_ckpt_path}\")\n",
    "    \n",
    "    print(f\"Loading model from: {nf_ckpt_path}\")\n",
    "    encoder, decoder = load_model(fabric, config, model_path=nf_ckpt_path)\n",
    "    \n",
    "    # 确保模型在正确的设备上\n",
    "    encoder = fabric.setup_module(encoder)\n",
    "    decoder = fabric.setup_module(decoder)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # 生成 codes\n",
    "    print(f\"Batch device: {batch.pos.device}\")\n",
    "    print(f\"Encoder device: {next(encoder.parameters()).device}\")\n",
    "    with torch.no_grad():\n",
    "        codes = encoder(batch)\n",
    "    # 定义预测场函数\n",
    "    def predicted_field_func(points):\n",
    "        # 确保 points 是正确的形状\n",
    "        if points.dim() == 2:  # [n_points, 3]\n",
    "            points = points.unsqueeze(0)  # [1, n_points, 3]\n",
    "        elif points.dim() == 3:  # [batch, n_points, 3]\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "        \n",
    "        result = decoder(points, codes[0:1])  # 现在codes只有1个样本，所以用索引0\n",
    "        # 确保返回 [n_points, n_atom_types, 3] 形状\n",
    "        if result.dim() == 4:  # [batch, n_points, n_atom_types, 3]\n",
    "            return result[0]  # 取第一个batch\n",
    "        else:\n",
    "            return result\n",
    "    field_func = predicted_field_func\n",
    "else:  # gt only\n",
    "    encoder, decoder = None, None\n",
    "    # 定义真实场函数\n",
    "    def gt_field_func(points):\n",
    "        gt_mask = (gt_types[0] != PADDING_INDEX)  # 现在只有1个样本，所以用索引0\n",
    "        gt_valid_coords = gt_coords[0][gt_mask]\n",
    "        gt_valid_types = gt_types[0][gt_mask]\n",
    "        \n",
    "        # 确保 points 是正确的形状\n",
    "        if points.dim() == 2:  # [n_points, 3]\n",
    "            points = points.unsqueeze(0)  # [1, n_points, 3]\n",
    "        elif points.dim() == 3:  # [batch, n_points, 3]\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "        \n",
    "        result = converter.mol2gnf(\n",
    "            gt_valid_coords.unsqueeze(0),\n",
    "            gt_valid_types.unsqueeze(0),\n",
    "            points\n",
    "        )\n",
    "        # 确保返回 [n_points, n_atom_types, 3] 形状\n",
    "        if result.dim() == 4:  # [batch, n_points, n_atom_types, 3]\n",
    "            return result[0]  # 取第一个batch\n",
    "        else:\n",
    "            return result\n",
    "    field_func = gt_field_func\n",
    "    codes = None\n",
    "\n",
    "converter = create_converter(config, device)\n",
    "print(f\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47b35856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoiser-only mode: Skipping gradient field comparison\n"
     ]
    }
   ],
   "source": [
    "if option != 'denoiser_only':\n",
    "    # 可视化一维梯度场对比（所有原子类型）\n",
    "    atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
    "    save_path = os.path.join(output_dir, f\"field1d_sample_{sample_idx}\")\n",
    "\n",
    "    gradient_results = visualize_1d_gradient_field_comparison(\n",
    "        gt_coords=gt_coords,\n",
    "        gt_types=gt_types,\n",
    "        converter=converter,\n",
    "        field_func=field_func,\n",
    "        sample_idx=0,  # 数据中只有1个样本，所以用索引0\n",
    "        atom_types=atom_types,  # 传入列表，不需要循环\n",
    "        x_range=None,\n",
    "        y_coord=0.0,\n",
    "        z_coord=0.0,\n",
    "        save_path=save_path,  # save_path已经包含了正确的sample_idx (14441)\n",
    "        display_sample_idx=sample_idx,  # 用于文件名和显示的原始样本索引\n",
    "    )\n",
    "\n",
    "    if gradient_results:\n",
    "        print(f\"Gradient field comparison (model: {model_dir}):\")\n",
    "        print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
    "        \n",
    "        # 打印每个原子类型的统计信息\n",
    "        for atom_name, stats in gradient_results['all_results'].items():\n",
    "            print(f\"  {atom_name}: MSE={stats['mse']:.6f}, MAE={stats['mae']:.6f}\")\n",
    "            print(f\"    Saved to: {stats['save_path']}\")\n",
    "else:\n",
    "    print(\"Denoiser-only mode: Skipping gradient field comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "927131ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 执行 denoiser_field 分子生成 ===\n",
      "Generating molecular field and reconstructing molecule...\n",
      ">>     Memory status at iteration 0: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 50: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 100: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 150: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 200: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 250: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 300: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 350: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 400: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 450: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 500: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 550: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 600: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 650: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 700: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 750: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 800: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 850: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 900: Allocated=0.02GB, Reserved=0.98GB\n",
      ">>     Memory status at iteration 950: Allocated=0.02GB, Reserved=0.98GB\n",
      "[DBSCAN] Total points: 500, Clusters found: 9, Noise points: 438\n",
      "[DBSCAN] Total points: 500, Clusters found: 7, Noise points: 431\n",
      "[DBSCAN] Total points: 500, Clusters found: 11, Noise points: 402\n",
      "[DBSCAN] Total points: 500, Clusters found: 8, Noise points: 442\n",
      "[DBSCAN] Total points: 500, Clusters found: 9, Noise points: 416\n",
      "Generated molecule: 44 atoms\n",
      "Atom types: [0, 1, 2, 3, 4]\n",
      "Creating single molecule visualization...\n",
      "Creating generation process animation...\n",
      "\n",
      "Starting generation for molecule 0\n",
      "[DBSCAN] Total points: 500, Clusters found: 2, Noise points: 483\n",
      "[DBSCAN] Total points: 500, Clusters found: 0, Noise points: 500\n",
      "[DBSCAN] Total points: 500, Clusters found: 0, Noise points: 500\n",
      "[DBSCAN] Total points: 500, Clusters found: 2, Noise points: 485\n",
      "[DBSCAN] Total points: 500, Clusters found: 5, Noise points: 462\n",
      "\n",
      "=== Denoiser Field 生成结果 ===\n",
      "Generated atoms: 44\n",
      "Atom type distribution: {tensor(0, device='cuda:0'): tensor(9, device='cuda:0'), tensor(1, device='cuda:0'): tensor(7, device='cuda:0'), tensor(2, device='cuda:0'): tensor(11, device='cuda:0'), tensor(3, device='cuda:0'): tensor(8, device='cuda:0'), tensor(4, device='cuda:0'): tensor(9, device='cuda:0')}\n",
      "单张分子图: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20250912/last/generated_molecule_single.png\n",
      "生成过程动画: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20250912/last/funcmol_gen_sample_0.gif\n"
     ]
    }
   ],
   "source": [
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，生成分子并可视化\n",
    "    print(\"\\n=== 执行 denoiser_field 分子生成 ===\")\n",
    "    \n",
    "    # 导入必要的函数\n",
    "    from funcmol.utils.gnf_visualizer import visualize_single_molecule\n",
    "    \n",
    "    # 生成随机噪声代码\n",
    "    grid_size = config.dset.grid_size\n",
    "    code_dim = config.encoder.code_dim\n",
    "    batch_size = 1\n",
    "    \n",
    "    # 创建随机噪声代码\n",
    "    noise_codes = torch.randn(batch_size, grid_size**3, code_dim, device=device)\n",
    "    \n",
    "    # 通过 denoiser 生成分子代码\n",
    "    with torch.no_grad():\n",
    "        denoised_codes = funcmol(noise_codes)\n",
    "    \n",
    "    # 使用 decoder 生成场并重建分子\n",
    "    print(\"Generating molecular field and reconstructing molecule...\")\n",
    "    recon_coords, recon_types = converter.gnf2mol(\n",
    "        decoder,\n",
    "        denoised_codes,\n",
    "        fabric=fabric\n",
    "    )\n",
    "    \n",
    "    print(f\"Generated molecule: {recon_coords[0].shape[0]} atoms\")\n",
    "    print(f\"Atom types: {recon_types[0].unique().tolist()}\")\n",
    "    \n",
    "    # 生成单张分子图片\n",
    "    print(\"Creating single molecule visualization...\")\n",
    "    single_mol_path = os.path.join(output_dir, \"generated_molecule_single.png\")\n",
    "    visualize_single_molecule(\n",
    "        coords=recon_coords[0],\n",
    "        types=recon_types[0],\n",
    "        save_path=single_mol_path,\n",
    "        title=\"Generated Molecule (Denoiser Field)\",\n",
    "        figsize=(10, 8)\n",
    "    )\n",
    "    \n",
    "    # 创建生成过程动画（使用现有的 GNFVisualizer 函数）\n",
    "    print(\"Creating generation process animation...\")\n",
    "    visualizer = GNFVisualizer(output_dir)\n",
    "    \n",
    "    # 定义生成过程的场函数（每次调用都生成新的随机噪声）\n",
    "    def generation_field_func(points):\n",
    "        # 生成随机噪声代码\n",
    "        grid_size = config.dset.grid_size\n",
    "        code_dim = config.encoder.code_dim\n",
    "        batch_size = 1\n",
    "        \n",
    "        # 创建随机噪声代码\n",
    "        noise_codes = torch.randn(batch_size, grid_size**3, code_dim, device=points.device)\n",
    "        \n",
    "        # 通过 denoiser 生成分子代码\n",
    "        with torch.no_grad():\n",
    "            denoised_codes = funcmol(noise_codes)\n",
    "        \n",
    "        # 使用 decoder 生成场\n",
    "        if points.dim() == 2:  # [n_points, 3]\n",
    "            points = points.unsqueeze(0)  # [1, n_points, 3]\n",
    "        elif points.dim() == 3:  # [batch, n_points, 3]\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "        \n",
    "        result = decoder(points, denoised_codes[0:1])\n",
    "        if result.dim() == 4:  # [batch, n_points, n_atom_types, 3]\n",
    "            return result[0]  # 取第一个batch\n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    # 使用现有的 create_generation_animation 函数，设置 use_recon_dir=False\n",
    "    results = visualizer.create_generation_animation(\n",
    "        converter=converter,\n",
    "        field_func=generation_field_func,\n",
    "        sample_idx=0,\n",
    "        save_interval=100,\n",
    "        create_1d_plots=False,  # 不创建1D场可视化\n",
    "        use_recon_dir=False,    # 直接在主目录下生成文件\n",
    "        fixed_axis=True         # 使用固定坐标轴，避免GIF中视角震荡\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n=== Denoiser Field 生成结果 ===\")\n",
    "    print(f\"Generated atoms: {recon_coords[0].shape[0]}\")\n",
    "    print(f\"Atom type distribution: {dict(zip(*torch.unique(recon_types[0], return_counts=True)))}\")\n",
    "    print(f\"单张分子图: {single_mol_path}\")\n",
    "    print(f\"生成过程动画: {results['gif_path']}\")\n",
    "    \n",
    "else:\n",
    "    # 根据option设置重建列表\n",
    "    if option == 'gt_only':\n",
    "        rec_list = ['gt_field']\n",
    "    else:\n",
    "        rec_list = ['predicted_field', 'gt_field']\n",
    "\n",
    "    # 创建可视化器\n",
    "    visualizer = GNFVisualizer(output_dir)\n",
    "\n",
    "    # 为每种重建类型执行可视化\n",
    "    for rec_type in rec_list:\n",
    "        print(f\"\\n=== 执行 {rec_type} 重建 ===\")\n",
    "        \n",
    "        # 根据重建类型设置场函数\n",
    "        if rec_type == 'gt_field':\n",
    "            # 定义真实场函数\n",
    "            def gt_field_func(points):\n",
    "                gt_mask = (gt_types[0] != PADDING_INDEX)  # 现在只有1个样本，所以用索引0\n",
    "                gt_valid_coords = gt_coords[0][gt_mask]\n",
    "                gt_valid_types = gt_types[0][gt_mask]\n",
    "                return converter.mol2gnf(\n",
    "                    gt_valid_coords.unsqueeze(0),\n",
    "                    gt_valid_types.unsqueeze(0),\n",
    "                    points\n",
    "                )\n",
    "            field_func = gt_field_func\n",
    "        else:  # predicted_field\n",
    "            # 定义预测场函数\n",
    "            def predicted_field_func(points):\n",
    "                if points.dim() == 2:\n",
    "                    points = points.unsqueeze(0)\n",
    "                elif points.dim() == 3:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "                result = decoder(points, codes[0:1])  # 现在codes只有1个样本，所以用索引0\n",
    "                return result[0] if result.dim() == 4 else result\n",
    "            field_func = predicted_field_func\n",
    "        \n",
    "        # 执行重建可视化\n",
    "        results = visualizer.create_reconstruction_animation(\n",
    "            gt_coords=gt_coords,\n",
    "            gt_types=gt_types,\n",
    "            converter=converter,\n",
    "            field_func=field_func,\n",
    "            save_interval=100,\n",
    "            animation_name=f\"recon_sample_{sample_idx}_{rec_type}\",\n",
    "            sample_idx=0  # 现在只有1个样本，所以用索引0\n",
    "        )\n",
    "\n",
    "        print(f\"\\n=== {rec_type} 重建结果 ===\")\n",
    "        print(f\"RMSD: {results['final_rmsd']:.4f}\")\n",
    "        print(f\"Reconstruction Loss: {results['final_loss']:.4f}\")\n",
    "        print(f\"KL Divergence (orig->recon): {results['final_kl_1to2']:.4f}\")\n",
    "        print(f\"KL Divergence (recon->orig): {results['final_kl_2to1']:.4f}\")\n",
    "        print(f\"GIF动画: {results['gif_path']}\")\n",
    "        print(f\"对比图: {results['comparison_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funcmol_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
