{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a52041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/huayuchen/Neurl-voxel/funcmol/notebooks\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd /home/huayuchen/Neurl-voxel/funcmol/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbf18ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/huayuchen/Neurl-voxel\n",
      "Python path: /home/huayuchen/Neurl-voxel\n",
      "Dataset directory: /home/huayuchen/Neurl-voxel/funcmol/dataset/data\n",
      "Config loaded successfully: train_nf_qm9\n",
      "n_iter from converter config: 600\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "import torch\n",
    "import hydra\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# 设置 torch.compile 兼容性\n",
    "try:\n",
    "    import torch._dynamo\n",
    "    torch._dynamo.config.suppress_errors = True\n",
    "except ImportError:\n",
    "    # PyTorch 版本 < 2.0 不支持 torch._dynamo\n",
    "    print(\"Warning: torch._dynamo not available in this PyTorch version\")\n",
    "\n",
    "## set up environment\n",
    "# 当前目录是 funcmol/notebooks，需要将 funcmol 的父目录添加到路径中\n",
    "# 这样 funcmol 才能作为包被正确导入\n",
    "notebook_dir = Path(os.getcwd())  # funcmol/notebooks\n",
    "project_root = notebook_dir.parent.parent  # funcmol 的父目录\n",
    "sys.path.insert(0, str(project_root))\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path: {sys.path[0]}\")\n",
    "\n",
    "from funcmol.dataset.dataset_field import create_gnf_converter, prepare_data_with_sample_idx\n",
    "from funcmol.utils.utils_nf import load_neural_field\n",
    "from funcmol.utils.utils_fm import load_checkpoint_fm\n",
    "from funcmol.utils.constants import PADDING_INDEX\n",
    "from funcmol.utils.gnf_visualizer import (\n",
    "    visualize_1d_gradient_field_comparison, \n",
    "    GNFVisualizer,\n",
    "    visualize_generated_molecule,\n",
    "    create_visualization_callback,\n",
    "    create_gif_from_frames\n",
    ")\n",
    "from funcmol.utils.misc import load_nf_config, load_funcmol_config, create_field_function\n",
    "from funcmol.models.funcmol import FuncMol\n",
    "    \n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 模型根目录\n",
    "model_root = \"/home/huayuchen/Neurl-voxel/exps/neural_field\"\n",
    "config = load_nf_config(\"train_nf_qm9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91676465",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SETTINGS #####\n",
    "# TODO：手动指定是 gt_only、gt_pred 还是 denoiser_only 模式\n",
    "option = 'gt_pred'  # 'gt_only', 'gt_pred', 'denoiser_only'\n",
    "\n",
    "# TODO：手动指定 checkpoint 文件路径，会根据ckpt_path自动提取exp_name\n",
    "nf_ckpt_path = '/home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/lightning_logs/version_1/checkpoints/model-epoch=999.ckpt'\n",
    "fm_ckpt_path = '/home/huayuchen/Neurl-voxel/exps/funcmol/fm_qm9/20251108/lightning_logs/version_1/checkpoints/model-epoch=364.ckpt'\n",
    "# nf_ckpt_path = '/home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20250911/lightning_logs/version_1/checkpoints/model-epoch=39.ckpt'\n",
    "# fm_ckpt_path = '/home/huayuchen/Neurl-voxel/exps/funcmol/fm_qm9/20250917/lightning_logs/version_22/checkpoints/model-epoch=144.ckpt'\n",
    "\n",
    "# TODO：手动指定 sample_idx（仅用于 gt_only 和 gt_pred 模式）\n",
    "sample_idx = 587  # 2,7,74,83,108,158,186,375,404,433\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TODO：手动指定 codes 编号 （仅用于 denoiser_only 模式）\n",
    "codes_source = 'load'  # 'load' 或 'sample' \n",
    "codes_idx = 501  # 例如：0 表示 code_0000_tanh.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23544d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val set size: 20042\n",
      "Data loaded for sample 587: torch.Size([1, 12, 3]), torch.Size([1, 12])\n",
      "Option: gt_pred\n",
      "Model directory: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121\n",
      "Checkpoint: model-epoch=999\n",
      "Output directory: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999\n"
     ]
    }
   ],
   "source": [
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，使用 FuncMol 的路径\n",
    "    ckpt_parts = Path(fm_ckpt_path).parts\n",
    "    funcmol_idx = ckpt_parts.index('funcmol')\n",
    "    exp_name = f\"{ckpt_parts[funcmol_idx + 1]}/{ckpt_parts[funcmol_idx + 2]}\"  # fm_qm9/20250912\n",
    "    ckpt_name = Path(fm_ckpt_path).stem  # funcmol-epoch=319\n",
    "    model_dir = os.path.join(\"/home/huayuchen/Neurl-voxel/exps/funcmol\", exp_name)\n",
    "    output_dir = os.path.join(model_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Option: {option}\")\n",
    "    print(f\"FuncMol model directory: {model_dir}\")\n",
    "    print(f\"FuncMol checkpoint: {ckpt_name}\")\n",
    "    print(f\"Neural Field checkpoint: {nf_ckpt_path}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "else:\n",
    "    # 对于 gt_only 和 gt_pred 模式，使用 Neural Field 的路径\n",
    "    ckpt_parts = Path(nf_ckpt_path).parts\n",
    "    neural_field_idx = ckpt_parts.index('neural_field')\n",
    "    exp_name = f\"{ckpt_parts[neural_field_idx + 1]}/{ckpt_parts[neural_field_idx + 2]}\"  # nf_qm9/20250911\n",
    "    ckpt_name = Path(nf_ckpt_path).stem  # model-epoch=39\n",
    "    model_dir = os.path.join(model_root, exp_name)\n",
    "    output_dir = os.path.join(model_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    batch, gt_coords, gt_types = prepare_data_with_sample_idx(config, device, sample_idx)\n",
    "    print(f\"Data loaded for sample {sample_idx}: {gt_coords.shape}, {gt_types.shape}\")\n",
    "    print(f\"Option: {option}\")\n",
    "    print(f\"Model directory: {model_dir}\")\n",
    "    print(f\"Checkpoint: {ckpt_name}\")\n",
    "    print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1c8d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/lightning_logs/version_1/checkpoints/model-epoch=999.ckpt\n",
      "Loading Lightning checkpoint from: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/lightning_logs/version_1/checkpoints/model-epoch=999.ckpt\n",
      ">> loaded dec\n",
      ">> loaded enc\n",
      "Model loaded successfully!\n",
      "Batch device: cuda:0\n",
      "Encoder device: cuda:0\n",
      "Batch size (number of graphs): 1\n",
      "Codes shape: torch.Size([1, 729, 128])\n",
      "\n",
      "=== Converter 参数 ===\n",
      "step_size: 0.04\n",
      "eps: 0.05\n",
      "min_samples: 20\n",
      "field_variance_k_neighbors: 10\n",
      "field_variance_weight: 0.01\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "## Load model, generate or load codes\n",
    "if option == 'denoiser_only':       \n",
    "    print(f\"Loading Neural Field model from: {nf_ckpt_path}\")\n",
    "    encoder, decoder = load_neural_field(nf_ckpt_path, config)\n",
    "    # 确保模型在正确的设备上\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # 使用YAML配置文件加载FuncMol配置\n",
    "    funcmol_config = load_funcmol_config(\"train_fm_qm9\", config)\n",
    "    \n",
    "    # 创建FuncMol模型\n",
    "    funcmol = FuncMol(funcmol_config)\n",
    "    funcmol = funcmol.to(device)\n",
    "    \n",
    "    # 加载checkpoint并获取code_stats\n",
    "    funcmol, code_stats = load_checkpoint_fm(funcmol, fm_ckpt_path)\n",
    "    funcmol.eval()\n",
    "    \n",
    "    # 设置decoder的code_stats\n",
    "    decoder.set_code_stats(code_stats)\n",
    "    \n",
    "    print(\">> FuncMol model loaded successfully!\")\n",
    "    configs_dir = project_root / \"funcmol\" / \"configs\"\n",
    "    with hydra.initialize_config_dir(config_dir=str(configs_dir), version_base=None):\n",
    "        sample_fm_config = hydra.compose(config_name=\"sample_fm\")\n",
    "    \n",
    "    # 转换为字典格式（与 sample_fm.py 第51行完全一致）\n",
    "    config_dict = OmegaConf.to_container(sample_fm_config, resolve=True)\n",
    "        \n",
    "    # 创建 converter（与 sample_fm.py 第151行完全一致）\n",
    "    converter = create_gnf_converter(config_dict)\n",
    "    \n",
    "    # 获取 codes 的维度信息\n",
    "    grid_size = config_dict.get('dset', {}).get('grid_size', 9)  # 与 sample_fm.py 一致\n",
    "    code_dim = config_dict.get('encoder', {}).get('code_dim', 128)  # 与 sample_fm.py 一致\n",
    "    \n",
    "    if codes_source == 'load':\n",
    "        # 从保存的codes文件加载\n",
    "        mol_save_dir = Path(model_dir) / \"molecule\"\n",
    "        code_path = mol_save_dir / f\"code_{codes_idx:04d}_tanh.pt\"\n",
    "        print(f\"根据索引自动构建路径:\")\n",
    "        print(f\"  mol_save_dir: {mol_save_dir}\")\n",
    "        print(f\"  文件名格式: code_{codes_idx:04d}_tanh.pt\")\n",
    "        print(f\"\\n最终使用的codes路径: {code_path}\")\n",
    "        \n",
    "        if not code_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Codes file not found: {code_path}\\n\"\n",
    "                f\"Please check if the file exists or run sample_fm.py first to generate codes.\"\n",
    "            )\n",
    "        \n",
    "        print(f\"Loading codes from: {code_path}\")\n",
    "        codes = torch.load(code_path, map_location=device)\n",
    "        # 确保codes的形状正确 [1, grid_size^3, code_dim]\n",
    "        if codes.dim() == 2:\n",
    "            # 如果是 [grid_size^3, code_dim]，添加batch维度\n",
    "            codes = codes.unsqueeze(0)\n",
    "        print(f\"Loaded codes shape: {codes.shape}\")\n",
    "        \n",
    "    else:\n",
    "        # 随机采样 codes\n",
    "        print(\"Sampling codes using DDPM...\")\n",
    "        with torch.no_grad():\n",
    "            codes = funcmol.sample_ddpm(shape=(1, grid_size**3, code_dim), progress=False)\n",
    "        print(f\"Sampled codes shape: {codes.shape}\")\n",
    "\n",
    "    # 使用统一的场计算函数（ddpm模式，使用已加载/采样的codes）\n",
    "    field_func = create_field_function(\n",
    "        mode='ddpm',\n",
    "        decoder=decoder,\n",
    "        codes=codes\n",
    "    )\n",
    "    print(\"Codes loaded/sampled and field_func set.\")\n",
    "    \n",
    "    \n",
    "elif option == 'gt_pred':\n",
    "    # 使用手动指定的 checkpoint 文件路径\n",
    "    if not os.path.exists(nf_ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {nf_ckpt_path}\")\n",
    "    \n",
    "    print(f\"Loading model from: {nf_ckpt_path}\")\n",
    "    encoder, decoder = load_neural_field(nf_ckpt_path, config)\n",
    "    \n",
    "    # 确保模型在正确的设备上\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # 生成 codes\n",
    "    print(f\"Batch device: {batch.pos.device}\")\n",
    "    print(f\"Encoder device: {next(encoder.parameters()).device}\")\n",
    "    print(f\"Batch size (number of graphs): {batch.num_graphs}\")\n",
    "    with torch.no_grad():\n",
    "        codes = encoder(batch)\n",
    "    print(f\"Codes shape: {codes.shape}\")\n",
    "    \n",
    "    # 使用统一的场计算函数\n",
    "    field_func = create_field_function(\n",
    "        mode='predicted',\n",
    "        decoder=decoder,\n",
    "        codes=codes\n",
    "    )\n",
    "else:  # gt only\n",
    "    encoder, decoder = None, None\n",
    "    codes = None\n",
    "\n",
    "converter = create_gnf_converter(config)\n",
    "\n",
    "# 打印 converter 的关键参数\n",
    "print(f\"\\n=== Converter 参数 ===\")\n",
    "print(f\"step_size: {converter.step_size}\")\n",
    "print(f\"eps: {converter.eps}\")\n",
    "print(f\"min_samples: {converter.min_samples}\")\n",
    "# field 参数\n",
    "print(f\"field_variance_k_neighbors: {converter.field_variance_k_neighbors}\")\n",
    "print(f\"field_variance_weight: {converter.field_variance_weight}\")\n",
    "\n",
    "# 创建场函数（在converter定义之后）\n",
    "if option == 'gt_only':\n",
    "    field_func = create_field_function(\n",
    "        mode='gt',\n",
    "        converter=converter,\n",
    "        gt_coords=gt_coords,\n",
    "        gt_types=gt_types\n",
    "    )\n",
    "print(f\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b35856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告：样本 587 中没有类型为 O 的原子\n",
      "警告：样本 587 中没有类型为 F 的原子\n",
      "自动计算 x 轴范围: (-3.0959600448608398, 3.0959600448608398)\n",
      "Field 1D comparison (atom_type=C) saved to: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999/field_1d_sample_587_atom_C.png\n",
      "Field 1D comparison (atom_type=H) saved to: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999/field_1d_sample_587_atom_H.png\n",
      "Field 1D comparison (atom_type=N) saved to: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999/field_1d_sample_587_atom_N.png\n",
      "Gradient field comparison (model: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121):\n",
      "  Available atom types: [0, 1, 3]\n",
      "  C: MSE=0.000262, MAE=0.011883\n",
      "    Saved to: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999/field_1d_sample_587_atom_C.png\n",
      "  H: MSE=0.000196, MAE=0.008832\n",
      "    Saved to: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999/field_1d_sample_587_atom_H.png\n",
      "  N: MSE=0.000500, MAE=0.014357\n",
      "    Saved to: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999/field_1d_sample_587_atom_N.png\n"
     ]
    }
   ],
   "source": [
    "if option != 'denoiser_only':\n",
    "    # 可视化一维梯度场对比（所有原子类型）\n",
    "    atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
    "    save_path = os.path.join(output_dir, f\"field1d_sample_{sample_idx}\")\n",
    "\n",
    "    gradient_results = visualize_1d_gradient_field_comparison(\n",
    "        gt_coords=gt_coords,\n",
    "        gt_types=gt_types,\n",
    "        converter=converter,\n",
    "        field_func=field_func,\n",
    "        sample_idx=0,  # 数据中只有1个样本，所以用索引0\n",
    "        atom_types=atom_types,  # 传入列表，不需要循环\n",
    "        x_range=None,\n",
    "        y_coord=0.0,\n",
    "        z_coord=0.0,\n",
    "        save_path=save_path,\n",
    "        display_sample_idx=sample_idx,  # 用于文件名和显示的原始样本索引\n",
    "    )\n",
    "\n",
    "    if gradient_results:\n",
    "        print(f\"Gradient field comparison (model: {model_dir}):\")\n",
    "        print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
    "        \n",
    "        # 打印每个原子类型的统计信息\n",
    "        for atom_name, stats in gradient_results['all_results'].items():\n",
    "            print(f\"  {atom_name}: MSE={stats['mse']:.6f}, MAE={stats['mae']:.6f}\")\n",
    "            print(f\"    Saved to: {stats['save_path']}\")\n",
    "\n",
    "elif option == 'denoiser_only':\n",
    "    # 可视化denoiser生成的codes对应的梯度场在1维上的变化曲线\n",
    "    print(\"\\n=== 可视化1D梯度场（仅预测） ===\")\n",
    "    \n",
    "    # 使用统一的场计算函数\n",
    "    atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
    "    save_path = os.path.join(output_dir, f\"field1d_gen_sample_0\")\n",
    "    \n",
    "    # 调用修改后的函数，不传入gt_coords和gt_types，只绘制预测的梯度场\n",
    "    gradient_results = visualize_1d_gradient_field_comparison(\n",
    "        gt_coords=None,  # 无ground truth\n",
    "        gt_types=None,   # 无ground truth\n",
    "        converter=None,  # 无ground truth时converter可以为None\n",
    "        field_func=field_func,\n",
    "        sample_idx=0,\n",
    "        atom_types=atom_types,\n",
    "        x_range=None,  # 使用默认范围(-5.0, 5.0)\n",
    "        y_coord=0.0,\n",
    "        z_coord=0.0,\n",
    "        save_path=save_path,\n",
    "        display_sample_idx=0,\n",
    "    )\n",
    "    \n",
    "    if gradient_results:\n",
    "        print(f\"Gradient field visualization (generation mode):\")\n",
    "        print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
    "        \n",
    "        # 打印每个原子类型的统计信息\n",
    "        for atom_name, stats in gradient_results['all_results'].items():\n",
    "            print(f\"  {atom_name}:\")\n",
    "            print(f\"    Magnitude: Mean={stats.get('magnitude_mean', 'N/A'):.6f}, Std={stats.get('magnitude_std', 'N/A'):.6f}\")\n",
    "            print(f\"    Saved to: {stats['save_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927131ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 执行 predicted_field 重建 ===\n",
      "\n",
      "Starting reconstruction for molecule 0\n",
      "Ground truth atoms: 12\n",
      "[DBSCAN] Total points: 6000, Clusters found: 2, Noise points: 123\n",
      "[DBSCAN] Total points: 1000, Clusters found: 5, Noise points: 3\n",
      "[DBSCAN] Total points: 200, Clusters found: 0, Noise points: 200\n",
      "[DBSCAN] Total points: 200, Clusters found: 4, Noise points: 7\n",
      "[DBSCAN] Total points: 100, Clusters found: 0, Noise points: 100\n",
      "\n",
      "=== predicted_field 重建结果 ===\n",
      "RMSD: 0.2527\n",
      "Reconstruction Loss: 0.6198\n",
      "KL Divergence (orig->recon): 8.9214\n",
      "KL Divergence (recon->orig): -2.4932\n",
      "GIF动画: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999/recon/recon_sample_587_predicted_field.gif\n",
      "对比图: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999/recon/recon_sample_587_predicted_field_final.png\n",
      "\n",
      "=== 执行 gt_field 重建 ===\n",
      "\n",
      "Starting reconstruction for molecule 0\n",
      "Ground truth atoms: 12\n",
      "[DBSCAN] Total points: 6000, Clusters found: 2, Noise points: 0\n",
      "[DBSCAN] Total points: 1000, Clusters found: 5, Noise points: 0\n",
      "[DBSCAN] Total points: 200, Clusters found: 0, Noise points: 200\n",
      "[DBSCAN] Total points: 200, Clusters found: 5, Noise points: 0\n",
      "[DBSCAN] Total points: 100, Clusters found: 0, Noise points: 100\n",
      "\n",
      "=== gt_field 重建结果 ===\n",
      "RMSD: 0.1021\n",
      "Reconstruction Loss: 0.3433\n",
      "KL Divergence (orig->recon): 8.9210\n",
      "KL Divergence (recon->orig): -2.5518\n",
      "GIF动画: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999/recon/recon_sample_587_gt_field.gif\n",
      "对比图: /home/huayuchen/Neurl-voxel/exps/neural_field/nf_qm9/20251121/model-epoch=999/recon/recon_sample_587_gt_field_final.png\n"
     ]
    }
   ],
   "source": [
    "if option == 'denoiser_only':\n",
    "    # 对于 denoiser_only 模式，使用DDPM采样得到固定codes并可视化\n",
    "    print(\"\\n=== 执行 DDPM 分子生成 ===\")\n",
    "\n",
    "    grid_size = config.dset.grid_size\n",
    "    code_dim = config.encoder.code_dim\n",
    "\n",
    "    # 使用gnf_visualizer中的函数创建可视化回调\n",
    "    visualization_callback, frame_paths, fixed_axis_limits_dict = create_visualization_callback(\n",
    "        output_dir=output_dir,\n",
    "        frame_prefix=\"frame_gen_sample_0\",\n",
    "        codes_device=codes.device,\n",
    "        n_atom_types=5\n",
    "    )\n",
    "\n",
    "    # 使用上一个单元已加载的 codes，重建分子，使用可视化\n",
    "    print(\"Generating molecular field and reconstructing molecule (loaded codes)...\")\n",
    "    save_interval = 100\n",
    "    recon_coords, recon_types = converter.gnf2mol(\n",
    "        decoder,\n",
    "        codes,\n",
    "        save_interval=save_interval,\n",
    "        visualization_callback=visualization_callback\n",
    "    )\n",
    "    \n",
    "    print(f\"Generated molecule: {recon_coords[0].shape[0]} atoms\")\n",
    "    print(f\"Atom types: {recon_types[0].unique().tolist()}\")\n",
    "\n",
    "    # 创建 GIF 动画（使用gnf_visualizer中的函数）\n",
    "    print(\"Creating generation process animation from saved frames...\")\n",
    "    gif_path = os.path.join(output_dir, f\"funcmol_gen_sample_0.gif\")\n",
    "    create_gif_from_frames(\n",
    "        frame_paths=frame_paths,\n",
    "        gif_path=gif_path,\n",
    "        duration=0.1,\n",
    "        fps=15,\n",
    "        loop=1,\n",
    "        cleanup_frames=True\n",
    "    )\n",
    "\n",
    "    # 保存最终生成的分子\n",
    "    final_path = os.path.join(output_dir, f\"funcmol_gen_sample_0_final.png\")\n",
    "    # 过滤掉填充的原子（类型为-1的原子）\n",
    "    valid_mask = recon_types[0] != -1\n",
    "    if valid_mask.any():\n",
    "        final_coords_valid = recon_coords[0][valid_mask]\n",
    "        final_types_valid = recon_types[0][valid_mask]\n",
    "        visualize_generated_molecule(\n",
    "            final_coords_valid, final_types_valid, save_path=final_path\n",
    "        )\n",
    "    else:\n",
    "        print(\"Warning: No valid atoms generated\")\n",
    "\n",
    "    print(f\"\\n=== DDPM Field 生成结果 ===\")\n",
    "    print(f\"Generated atoms: {recon_coords[0].shape[0]}\")\n",
    "    print(f\"Atom type distribution: {dict(zip(*torch.unique(recon_types[0], return_counts=True)))}\")\n",
    "    print(f\"最终分子图: {final_path}\")\n",
    "    print(f\"生成过程动画: {gif_path}\")\n",
    "    \n",
    "else:\n",
    "    # 根据option设置重建列表\n",
    "    if option == 'gt_only':\n",
    "        rec_list = ['gt_field']\n",
    "    else:\n",
    "        rec_list = ['predicted_field', 'gt_field']\n",
    "\n",
    "    # 创建可视化器\n",
    "    visualizer = GNFVisualizer(output_dir)\n",
    "\n",
    "    # 为每种重建类型执行可视化\n",
    "    for rec_type in rec_list:\n",
    "        print(f\"\\n=== 执行 {rec_type} 重建 ===\")\n",
    "        \n",
    "        # 根据重建类型设置decoder和codes（使用与gnf2mol相同的方法）\n",
    "        if rec_type == 'gt_field':\n",
    "            # 对于gt_field模式，创建dummy decoder和codes（与field_recon.py一致）\n",
    "            grid_size = config.dset.grid_size\n",
    "            code_dim = config.encoder.code_dim\n",
    "            dummy_codes = torch.randn(1, grid_size**3, code_dim, device=gt_coords.device)\n",
    "            \n",
    "            # 创建dummy decoder，返回ground truth field\n",
    "            class DummyDecoder:\n",
    "                def __init__(self, converter, gt_coords, gt_types):\n",
    "                    self.converter = converter\n",
    "                    self.gt_coords = gt_coords\n",
    "                    self.gt_types = gt_types\n",
    "                \n",
    "                def __call__(self, query_points, codes):\n",
    "                    return self.converter.mol2gnf(\n",
    "                        self.gt_coords.unsqueeze(0), \n",
    "                        self.gt_types.unsqueeze(0), \n",
    "                        query_points\n",
    "                    )\n",
    "            \n",
    "            # 过滤掉padding的原子\n",
    "            gt_mask = (gt_types[0] != PADDING_INDEX)\n",
    "            gt_valid_coords_for_decoder = gt_coords[0][gt_mask]\n",
    "            gt_valid_types_for_decoder = gt_types[0][gt_mask]\n",
    "            \n",
    "            dummy_decoder = DummyDecoder(converter, gt_valid_coords_for_decoder, gt_valid_types_for_decoder)\n",
    "            rec_decoder = dummy_decoder\n",
    "            rec_codes = dummy_codes\n",
    "        else:  # predicted_field\n",
    "            # 对于predicted_field模式，直接使用decoder和codes\n",
    "            rec_decoder = decoder\n",
    "            rec_codes = codes\n",
    "        \n",
    "        # 执行重建可视化（使用gnf2mol方法，与field_recon.py完全一致）\n",
    "        results = visualizer.create_reconstruction_animation(\n",
    "            gt_coords=gt_coords,\n",
    "            gt_types=gt_types,\n",
    "            converter=converter,\n",
    "            decoder=rec_decoder,\n",
    "            codes=rec_codes,\n",
    "            save_interval=100,\n",
    "            animation_name=f\"recon_sample_{sample_idx}_{rec_type}\",\n",
    "            sample_idx=0\n",
    "        )\n",
    "\n",
    "        print(f\"\\n=== {rec_type} 重建结果 ===\")\n",
    "        print(f\"RMSD: {results['final_rmsd']:.4f}\")\n",
    "        print(f\"Reconstruction Loss: {results['final_loss']:.4f}\")\n",
    "        print(f\"KL Divergence (orig->recon): {results['final_kl_1to2']:.4f}\")\n",
    "        print(f\"KL Divergence (recon->orig): {results['final_kl_2to1']:.4f}\")\n",
    "        print(f\"GIF动画: {results['gif_path']}\")\n",
    "        print(f\"对比图: {results['comparison_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funcmol_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
