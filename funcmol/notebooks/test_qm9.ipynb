{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a52041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dbf18ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import hydra\n",
    "from pathlib import Path\n",
    "from lightning import Fabric\n",
    "\n",
    "# 设置 torch.compile 兼容性\n",
    "try:\n",
    "    import torch._dynamo\n",
    "    torch._dynamo.config.suppress_errors = True\n",
    "except ImportError:\n",
    "    # PyTorch 版本 < 2.0 不支持 torch._dynamo\n",
    "    print(\"Warning: torch._dynamo not available in this PyTorch version\")\n",
    "\n",
    "## set up environment\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from funcmol.utils.constants import PADDING_INDEX\n",
    "from gnf_visualizer import (\n",
    "    load_config_from_exp_dir, load_model, \n",
    "    create_converter, prepare_data, visualize_1d_gradient_field_comparison,\n",
    "    GNFVisualizer\n",
    ")\n",
    "\n",
    "# 模型根目录\n",
    "model_root = \"/datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23544d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option: gt_pred\n",
      "Model directory: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9_20250804_153549_358664\n",
      "Output directory: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9_20250804_153549_358664\n"
     ]
    }
   ],
   "source": [
    "# TODO：只需要修改这里的就好，会根据exp_name判断gradient_field_method\n",
    "exp_name = 'nf_qm9_20250804_153549_358664'\n",
    "sample_idx = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 判断是gt_only还是gt_pred模式\n",
    "if '2025' in exp_name:  # gt + predicted field\n",
    "    option = 'gt_pred'\n",
    "    model_dir = os.path.join(model_root, exp_name)\n",
    "else:  # gt only. exp_name is the name of field (e.g., gaussian_mag)\n",
    "    option = 'gt_only'\n",
    "    model_dir = os.path.join(model_root, exp_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "output_dir = model_dir\n",
    "print(f\"Option: {option}\")\n",
    "print(f\"Model directory: {model_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceafdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/funcmol/dataset/data\n",
      ">> val set size: 20042\n",
      "Data loaded: torch.Size([128, 18, 3]), torch.Size([128, 18])\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "fabric = Fabric(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    precision=\"32-true\",\n",
    "    strategy=\"auto\"\n",
    ")\n",
    "fabric.launch()\n",
    "\n",
    "# 从实验目录加载配置\n",
    "config = load_config_from_exp_dir(model_dir)\n",
    "\n",
    "# 准备数据\n",
    "batch, gt_coords, gt_types = prepare_data(fabric, config, device)\n",
    "print(f\"Data loaded: {gt_coords.shape}, {gt_types.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b023b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing model from: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9_20250804_153549_358664\n",
      "Loading model from: /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9_20250804_153549_358664/model.pt\n",
      ">> loaded dec\n",
      ">> loaded enc\n",
      ">> loaded dec\n",
      ">> loaded enc\n",
      "Model loaded successfully!\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "'knn_graph' requires 'torch-cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 生成 codes\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     codes \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 定义预测场函数\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredicted_field_func\u001b[39m(points):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# 确保 points 是正确的形状\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/lightning/fabric/wrappers.py:133\u001b[0m, in \u001b[0;36m_FabricModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_precision\u001b[38;5;241m.\u001b[39mconvert_input((args, kwargs))\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_precision\u001b[38;5;241m.\u001b[39mforward_context():\n\u001b[0;32m--> 133\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_precision\u001b[38;5;241m.\u001b[39mconvert_output(output)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/funcmol/models/encoder.py:122\u001b[0m, in \u001b[0;36mCrossGraphEncoder.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    118\u001b[0m node_pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([atom_coords, grid_coords_flat], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [(N_total_atoms + B*n_grid), 3]\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# 5. 构建两个分离的图\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# 5.1 原子内部连接图（只连接原子之间）\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m atom_edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mknn_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matom_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matom_k_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matom_batch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# 5.2 原子-网格连接图\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# 使用knn构建原子到网格的连接\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# 在这里找的是 grid 的邻居，因为要更新的是 grid 的特征，而且这样每个 grid 都一定会有连边（不需要给所有grid加自环边了）\u001b[39;00m\n\u001b[1;32m    132\u001b[0m grid_to_atom_edges \u001b[38;5;241m=\u001b[39m knn(\n\u001b[1;32m    133\u001b[0m     x\u001b[38;5;241m=\u001b[39matom_coords,            \u001b[38;5;66;03m# source points  (atom)\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     y\u001b[38;5;241m=\u001b[39mgrid_coords_flat,       \u001b[38;5;66;03m# target points (grid)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     batch_y\u001b[38;5;241m=\u001b[39mgrid_batch_idx\n\u001b[1;32m    138\u001b[0m )  \u001b[38;5;66;03m# [2, E] 其中 E = k_neighbors * N_total_atoms (22240 = 32 * 695)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_geometric/nn/pool/__init__.py:171\u001b[0m, in \u001b[0;36mknn_graph\u001b[0;34m(x, k, batch, loop, flow, cosine, num_workers, batch_size)\u001b[0m\n\u001b[1;32m    168\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch_geometric\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mWITH_TORCH_CLUSTER_BATCH_SIZE:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_cluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn_graph\u001b[49m(x, k, batch, loop, flow, cosine,\n\u001b[1;32m    172\u001b[0m                                    num_workers)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch_cluster\u001b[38;5;241m.\u001b[39mknn_graph(x, k, batch, loop, flow, cosine,\n\u001b[1;32m    174\u001b[0m                                num_workers, batch_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_geometric/typing.py:104\u001b[0m, in \u001b[0;36mTorchCluster.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch-cluster\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: 'knn_graph' requires 'torch-cluster'"
     ]
    }
   ],
   "source": [
    "print(f\"\\nProcessing model from: {model_dir}\")\n",
    "\n",
    "## Load model\n",
    "if option == 'gt_pred':\n",
    "    encoder, decoder = load_model(fabric, config, model_dir=model_dir)\n",
    "    # 生成 codes\n",
    "    with torch.no_grad():\n",
    "        codes = encoder(batch)\n",
    "    # 定义预测场函数\n",
    "    def predicted_field_func(points):\n",
    "        # 确保 points 是正确的形状\n",
    "        if points.dim() == 2:  # [n_points, 3]\n",
    "            points = points.unsqueeze(0)  # [1, n_points, 3]\n",
    "        elif points.dim() == 3:  # [batch, n_points, 3]\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "        \n",
    "        result = decoder(points, codes[sample_idx:sample_idx+1])\n",
    "        # 确保返回 [n_points, n_atom_types, 3] 形状\n",
    "        if result.dim() == 4:  # [batch, n_points, n_atom_types, 3]\n",
    "            return result[0]  # 取第一个batch\n",
    "        else:\n",
    "            return result\n",
    "    field_func = predicted_field_func\n",
    "else:  # gt only\n",
    "    encoder, decoder = None, None\n",
    "    # 定义真实场函数\n",
    "    def gt_field_func(points):\n",
    "        gt_mask = (gt_types[sample_idx] != PADDING_INDEX)\n",
    "        gt_valid_coords = gt_coords[sample_idx][gt_mask]\n",
    "        gt_valid_types = gt_types[sample_idx][gt_mask]\n",
    "        \n",
    "        # 确保 points 是正确的形状\n",
    "        if points.dim() == 2:  # [n_points, 3]\n",
    "            points = points.unsqueeze(0)  # [1, n_points, 3]\n",
    "        elif points.dim() == 3:  # [batch, n_points, 3]\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "        \n",
    "        result = converter.mol2gnf(\n",
    "            gt_valid_coords.unsqueeze(0),\n",
    "            gt_valid_types.unsqueeze(0),\n",
    "            points\n",
    "        )\n",
    "        # 确保返回 [n_points, n_atom_types, 3] 形状\n",
    "        if result.dim() == 4:  # [batch, n_points, n_atom_types, 3]\n",
    "            return result[0]  # 取第一个batch\n",
    "        else:\n",
    "            return result\n",
    "    field_func = gt_field_func\n",
    "\n",
    "converter = create_converter(config, device)\n",
    "print(f\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b35856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] Graph break from `Tensor.item()`, consider setting:\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     torch._dynamo.config.capture_scalar_outputs = True\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] or:\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] to include these operations in the captured graph.\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] \n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] Graph break: from user code at:\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]   File \"/home/huayuchen/funcmol-main-neuralfield/funcmol/models/decoder.py\", line 47, in forward\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     vector_field = self.net(x, codes)\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]   File \"/home/huayuchen/funcmol-main-neuralfield/funcmol/models/egnn.py\", line 197, in forward\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     edge_grid_query = knn(\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_geometric/nn/pool/__init__.py\", line 117, in knn\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     return torch_cluster.knn(x, y, k, batch_x, batch_y, cosine, num_workers,\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_cluster/knn.py\", line 66, in knn\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0]     batch_size = int(batch_x.max()) + 1\n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] \n",
      "W0805 14:46:58.809617 1266057 site-packages/torch/_dynamo/variables/tensor.py:776] [0/0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告：样本 20 中没有类型为 N 的原子\n",
      "警告：样本 20 中没有类型为 F 的原子\n",
      "自动计算 x 轴范围: (-2.382029986381531, 2.382029986381531)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] WON'T CONVERT torch_dynamo_resume_in_knn_at_69 /home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_cluster/knn.py line 69 \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] due to: \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return _compile(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     tracer.run()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     super().run()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     while self.step():\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 582, in wrapper\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return inner_fn(self, inst)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 1602, in CALL_FUNCTION\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.call_function(fn, args, {})\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 830, in call_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/torch.py\", line 897, in call_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     tensor_variable = wrap_fx_proxy(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/builder.py\", line 2037, in wrap_fx_proxy\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/builder.py\", line 2124, in wrap_fx_proxy_cls\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2082, in get_fake_value\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     raise TorchRuntimeError(str(e)).with_traceback(e.__traceback__) from None\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2017, in get_fake_value\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     ret_val = wrap_fake_exception(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 1574, in wrap_fake_exception\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return fn()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2018, in <lambda>\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     lambda: run_node(tx.output, node, args, kwargs, nnmodule)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2150, in run_node\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(make_error_message(e)).with_traceback(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2132, in run_node\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return node.target(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_ops.py\", line 1116, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return self._op(*args, **(kwargs or {}))\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.TorchRuntimeError: Failed running call_function torch_cluster.knn(*(FakeTensor(..., device='cuda:0', size=(729, 3)), FakeTensor(..., device='cuda:0', size=(3000, 3)), None, None, 16, False, 1), **{}):\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] The tensor has a non-zero number of elements, but its data is not allocated yet.\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] If you're using torch.compile/export/fx, it is likely that we are erroneously tracing into a custom kernel. To fix this, please wrap the custom kernel into an opaque custom op. Please see the following for details: https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] If you're using Caffe2, Caffe2 uses a lazy allocation, so you will need to call mutable_data() or raw_mutable_data() to actually allocate memory.\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] from user code:\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]    File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_cluster/knn.py\", line 81, in torch_dynamo_resume_in_knn_at_69\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return torch.ops.torch_cluster.knn(x, y, ptr_x, ptr_y, k, cosine,\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return _compile(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     tracer.run()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     super().run()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     while self.step():\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 582, in wrapper\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return inner_fn(self, inst)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 1602, in CALL_FUNCTION\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.call_function(fn, args, {})\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py\", line 830, in call_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/torch.py\", line 897, in call_function\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     tensor_variable = wrap_fx_proxy(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/builder.py\", line 2037, in wrap_fx_proxy\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/variables/builder.py\", line 2124, in wrap_fx_proxy_cls\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2082, in get_fake_value\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     raise TorchRuntimeError(str(e)).with_traceback(e.__traceback__) from None\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2017, in get_fake_value\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     ret_val = wrap_fake_exception(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 1574, in wrap_fake_exception\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return fn()\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2018, in <lambda>\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     lambda: run_node(tx.output, node, args, kwargs, nnmodule)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2150, in run_node\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(make_error_message(e)).with_traceback(\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_dynamo/utils.py\", line 2132, in run_node\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return node.target(*args, **kwargs)\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]   File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch/_ops.py\", line 1116, in __call__\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return self._op(*args, **(kwargs or {}))\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.TorchRuntimeError: Failed running call_function torch_cluster.knn(*(FakeTensor(..., device='cuda:0', size=(729, 3)), FakeTensor(..., device='cuda:0', size=(3000, 3)), None, None, 16, False, 1), **{}):\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] The tensor has a non-zero number of elements, but its data is not allocated yet.\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] If you're using torch.compile/export/fx, it is likely that we are erroneously tracing into a custom kernel. To fix this, please wrap the custom kernel into an opaque custom op. Please see the following for details: https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] If you're using Caffe2, Caffe2 uses a lazy allocation, so you will need to call mutable_data() or raw_mutable_data() to actually allocate memory.\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] from user code:\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]    File \"/home/huayuchen/miniconda3/envs/funcmol_oss/lib/python3.9/site-packages/torch_cluster/knn.py\", line 81, in torch_dynamo_resume_in_knn_at_69\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125]     return torch.ops.torch_cluster.knn(x, y, ptr_x, ptr_y, k, cosine,\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0805 14:47:01.104112 1266057 site-packages/torch/_dynamo/convert_frame.py:1125] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 1D comparison (atom_type=C) saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_C.png\n",
      "Field 1D comparison (atom_type=H) saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_H.png\n",
      "Field 1D comparison (atom_type=O) saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_O.png\n",
      "Gradient field comparison (model: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945):\n",
      "  Available atom types: [0, 1, 2]\n",
      "  C: MSE=0.000050, MAE=0.005117\n",
      "    Saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_C.png\n",
      "  H: MSE=0.000038, MAE=0.004623\n",
      "    Saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_H.png\n",
      "  O: MSE=0.000002, MAE=0.001188\n",
      "    Saved to: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/field_1d_sample_20_atom_O.png\n"
     ]
    }
   ],
   "source": [
    "# 可视化一维梯度场对比（所有原子类型）\n",
    "atom_types = [0, 1, 2, 3, 4]  # C, H, O, N, F\n",
    "save_path = os.path.join(output_dir, \"recon\", f\"field1d_sample_{sample_idx}\")\n",
    "\n",
    "gradient_results = visualize_1d_gradient_field_comparison(\n",
    "    gt_coords=gt_coords,\n",
    "    gt_types=gt_types,\n",
    "    converter=converter,\n",
    "    field_func=field_func,\n",
    "    sample_idx=sample_idx,\n",
    "    atom_types=atom_types,  # 传入列表，不需要循环\n",
    "    x_range=None,\n",
    "    y_coord=0.0,\n",
    "    z_coord=0.0,\n",
    "    save_path=save_path,\n",
    ")\n",
    "\n",
    "if gradient_results:\n",
    "    print(f\"Gradient field comparison (model: {model_dir}):\")\n",
    "    print(f\"  Available atom types: {gradient_results['available_atom_types']}\")\n",
    "    \n",
    "    # 打印每个原子类型的统计信息\n",
    "    for atom_name, stats in gradient_results['all_results'].items():\n",
    "        print(f\"  {atom_name}: MSE={stats['mse']:.6f}, MAE={stats['mae']:.6f}\")\n",
    "        print(f\"    Saved to: {stats['save_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927131ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 执行 predicted_field 重建 ===\n",
      "\n",
      "Starting reconstruction for molecule 20\n",
      "Ground truth atoms: 9\n",
      "[DBSCAN] Total points: 3000, Clusters found: 3, Noise points: 2636\n",
      "[DBSCAN] Total points: 3000, Clusters found: 4, Noise points: 2545\n",
      "[DBSCAN] Total points: 3000, Clusters found: 2, Noise points: 2758\n",
      "[DBSCAN] Total points: 3000, Clusters found: 0, Noise points: 3000\n",
      "[DBSCAN] Total points: 3000, Clusters found: 0, Noise points: 3000\n",
      "\n",
      "=== predicted_field 重建结果 ===\n",
      "RMSD: 0.7993\n",
      "Reconstruction Loss: 0.5683\n",
      "KL Divergence (orig->recon): 9.5590\n",
      "KL Divergence (recon->orig): -2.9384\n",
      "GIF动画: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/recon_sample_20_predicted_field.gif\n",
      "对比图: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/recon_sample_20_predicted_field_final.png\n",
      "\n",
      "=== 执行 gt_field 重建 ===\n",
      "\n",
      "Starting reconstruction for molecule 20\n",
      "Ground truth atoms: 9\n",
      "[DBSCAN] Total points: 3000, Clusters found: 3, Noise points: 2677\n",
      "[DBSCAN] Total points: 3000, Clusters found: 4, Noise points: 2544\n",
      "[DBSCAN] Total points: 3000, Clusters found: 2, Noise points: 2740\n",
      "[DBSCAN] Total points: 3000, Clusters found: 0, Noise points: 3000\n",
      "[DBSCAN] Total points: 3000, Clusters found: 0, Noise points: 3000\n",
      "\n",
      "=== gt_field 重建结果 ===\n",
      "RMSD: 0.7924\n",
      "Reconstruction Loss: 0.5679\n",
      "KL Divergence (orig->recon): 9.5609\n",
      "KL Divergence (recon->orig): -2.9736\n",
      "GIF动画: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/recon_sample_20_gt_field.gif\n",
      "对比图: /home/huayuchen/funcmol-main-neuralfield/funcmol/exps/neural_field/nf_qm9_20250803_150822_593945/recon/recon_sample_20_gt_field_final.png\n"
     ]
    }
   ],
   "source": [
    "# 根据option设置重建列表\n",
    "if option == 'gt_only':\n",
    "    rec_list = ['gt_field']\n",
    "else:\n",
    "    rec_list = ['predicted_field', 'gt_field']\n",
    "\n",
    "# 创建可视化器\n",
    "visualizer = GNFVisualizer(output_dir)\n",
    "\n",
    "# 为每种重建类型执行可视化\n",
    "for rec_type in rec_list:\n",
    "    print(f\"\\n=== 执行 {rec_type} 重建 ===\")\n",
    "    \n",
    "    # 根据重建类型设置场函数\n",
    "    if rec_type == 'gt_field':\n",
    "        # 定义真实场函数\n",
    "        def gt_field_func(points):\n",
    "            gt_mask = (gt_types[sample_idx] != PADDING_INDEX)\n",
    "            gt_valid_coords = gt_coords[sample_idx][gt_mask]\n",
    "            gt_valid_types = gt_types[sample_idx][gt_mask]\n",
    "            return converter.mol2gnf(\n",
    "                gt_valid_coords.unsqueeze(0),\n",
    "                gt_valid_types.unsqueeze(0),\n",
    "                points\n",
    "            )\n",
    "        field_func = gt_field_func\n",
    "    else:  # predicted_field\n",
    "        # 定义预测场函数\n",
    "        def predicted_field_func(points):\n",
    "            if points.dim() == 2:\n",
    "                points = points.unsqueeze(0)\n",
    "            elif points.dim() == 3:\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected points shape: {points.shape}\")\n",
    "            result = decoder(points, codes[sample_idx:sample_idx+1])\n",
    "            return result[0] if result.dim() == 4 else result\n",
    "        field_func = predicted_field_func\n",
    "    \n",
    "    # 执行重建可视化\n",
    "    results = visualizer.create_reconstruction_animation(\n",
    "        gt_coords=gt_coords,\n",
    "        gt_types=gt_types,\n",
    "        converter=converter,\n",
    "        field_func=field_func,\n",
    "        save_interval=100,\n",
    "        animation_name=f\"recon_sample_{sample_idx}_{rec_type}\",\n",
    "        sample_idx=sample_idx\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== {rec_type} 重建结果 ===\")\n",
    "    print(f\"RMSD: {results['final_rmsd']:.4f}\")\n",
    "    print(f\"Reconstruction Loss: {results['final_loss']:.4f}\")\n",
    "    print(f\"KL Divergence (orig->recon): {results['final_kl_1to2']:.4f}\")\n",
    "    print(f\"KL Divergence (recon->orig): {results['final_kl_2to1']:.4f}\")\n",
    "    print(f\"GIF动画: {results['gif_path']}\")\n",
    "    print(f\"对比图: {results['comparison_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funcmol_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
