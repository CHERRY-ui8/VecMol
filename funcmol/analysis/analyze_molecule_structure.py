"""
åˆ†æç”Ÿæˆåˆ†å­çš„ç»“æ„é—®é¢˜ï¼š
1. æœ€è¿‘åŸå­è·ç¦»åˆ†å¸ƒ
2. åˆ†å­è¿é€šæ€§ï¼ˆæ˜¯å¦å½¢æˆå®Œæ•´graphï¼‰
3. é”®é•¿åˆ†å¸ƒ
"""

import sys
from pathlib import Path
import torch
import numpy as np
import argparse
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from funcmol.analysis.baselines_evaluation import (
    atom_decoder_dict,
    build_xae_molecule
)


def compute_min_distances(coords):
    """
    è®¡ç®—åˆ†å­ä¸­æ‰€æœ‰åŸå­å¯¹çš„æœ€å°è·ç¦»
    
    Args:
        coords: [N, 3] åŸå­åæ ‡
        
    Returns:
        min_distances: æ¯ä¸ªåŸå­åˆ°æœ€è¿‘é‚»åŸå­çš„è·ç¦» [N]
        all_distances: æ‰€æœ‰åŸå­å¯¹çš„è·ç¦»ï¼ˆä¸Šä¸‰è§’çŸ©é˜µï¼‰
    """
    n_atoms = coords.shape[0]
    if n_atoms < 2:
        return torch.tensor([]), torch.tensor([])
    
    # è®¡ç®—æ‰€æœ‰åŸå­å¯¹çš„è·ç¦»
    distances = torch.cdist(coords, coords, p=2)  # [N, N]
    
    # å°†å¯¹è§’çº¿è®¾ä¸ºæ— ç©·å¤§ï¼ˆè‡ªå·±åˆ°è‡ªå·±çš„è·ç¦»ï¼‰
    distances.fill_diagonal_(float('inf'))
    
    # æ‰¾åˆ°æ¯ä¸ªåŸå­åˆ°æœ€è¿‘é‚»çš„è·ç¦»
    min_distances, _ = torch.min(distances, dim=1)
    
    # è·å–ä¸Šä¸‰è§’çŸ©é˜µï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
    triu_mask = torch.triu(torch.ones(n_atoms, n_atoms, dtype=torch.bool), diagonal=1)
    all_distances = distances[triu_mask]
    
    return min_distances, all_distances


def check_connectivity(bond_types):
    """
    æ£€æŸ¥åˆ†å­çš„è¿é€šæ€§ï¼ˆä½¿ç”¨ç®€å•çš„DFSï¼‰
    
    Args:
        bond_types: [N, N] é”®ç±»å‹çŸ©é˜µ
        
    Returns:
        num_components: è¿é€šåˆ†é‡æ•°
        is_connected: æ˜¯å¦è¿é€šï¼ˆè¿é€šåˆ†é‡æ•°==1ï¼‰
    """
    n_atoms = bond_types.shape[0]
    if n_atoms == 0:
        return 0, False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹
    has_edges = (bond_types > 0).any()
    if not has_edges:
        # æ²¡æœ‰è¾¹ï¼Œæ¯ä¸ªåŸå­éƒ½æ˜¯ç‹¬ç«‹çš„è¿é€šåˆ†é‡
        return n_atoms, False
    
    # ä½¿ç”¨DFSè®¡ç®—è¿é€šåˆ†é‡
    visited = torch.zeros(n_atoms, dtype=torch.bool)
    num_components = 0
    
    def dfs(node):
        """æ·±åº¦ä¼˜å…ˆæœç´¢"""
        visited[node] = True
        # æ‰¾åˆ°æ‰€æœ‰ä¸å½“å‰èŠ‚ç‚¹ç›¸è¿çš„èŠ‚ç‚¹
        neighbors = torch.nonzero(bond_types[node] > 0, as_tuple=False).squeeze(-1)
        for neighbor in neighbors:
            if neighbor.item() != node and not visited[neighbor.item()]:
                dfs(neighbor.item())
    
    # éå†æ‰€æœ‰æœªè®¿é—®çš„èŠ‚ç‚¹
    for i in range(n_atoms):
        if not visited[i]:
            dfs(i)
            num_components += 1
    
    is_connected = (num_components == 1)
    return num_components, is_connected


def analyze_molecules(molecule_dir, output_dir=None):
    """
    åˆ†æåˆ†å­ç»“æ„
    
    Args:
        molecule_dir: åŒ…å« .npz æ–‡ä»¶çš„ç›®å½•
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
    """
    molecule_dir = Path(molecule_dir)
    npz_files = sorted(molecule_dir.glob("generated_*.npz"))
    
    print(f"æ‰¾åˆ° {len(npz_files)} ä¸ª .npz åˆ†å­æ–‡ä»¶")
    
    atom_decoder = atom_decoder_dict['qm9_with_h']
    dataset_info = {'name': 'qm9'}
    
    # å­˜å‚¨ç»Ÿè®¡æ•°æ®
    all_min_distances = []
    all_pair_distances = []
    num_components_list = []
    is_connected_list = []
    bond_lengths = []
    num_atoms_list = []
    
    # ç©ºé—´åˆ†å¸ƒç»Ÿè®¡
    coord_ranges = []  # æ¯ä¸ªåˆ†å­çš„åæ ‡èŒƒå›´ (max - min)
    coord_centers = []  # æ¯ä¸ªåˆ†å­çš„ä¸­å¿ƒåæ ‡
    coord_spans = []  # æ¯ä¸ªåˆ†å­çš„è·¨åº¦ï¼ˆæœ€å¤§è·ç¦»ï¼‰
    large_gap_ratios = []  # æ¯ä¸ªåˆ†å­ä¸­è·ç¦»>3Ã…çš„åŸå­å¯¹æ¯”ä¾‹
    
    print("åˆ†æåˆ†å­ç»“æ„...")
    for npz_file in tqdm(npz_files, desc="å¤„ç†åˆ†å­"):
        try:
            # åŠ è½½åˆ†å­
            data = np.load(npz_file)
            coords = data['coords']  # (N, 3)
            types = data['types']    # (N,)
            
            # è½¬æ¢ä¸ºtorchå¼ é‡
            positions = torch.tensor(coords, dtype=torch.float32)
            atom_types = torch.tensor(types, dtype=torch.long)
            
            # è¿‡æ»¤æ‰å¡«å……çš„åŸå­
            valid_mask = atom_types != -1
            if not valid_mask.any():
                continue
            
            positions = positions[valid_mask]
            atom_types = atom_types[valid_mask]
            num_atoms = len(positions)
            num_atoms_list.append(num_atoms)
            
            # è®¡ç®—ç©ºé—´åˆ†å¸ƒç»Ÿè®¡
            coord_min = positions.min(dim=0)[0]
            coord_max = positions.max(dim=0)[0]
            coord_range = coord_max - coord_min  # [3]
            coord_center = positions.mean(dim=0)  # [3]
            coord_span = torch.cdist(positions, positions, p=2).max().item()  # æœ€å¤§åŸå­å¯¹è·ç¦»
            
            coord_ranges.append(coord_range.cpu().numpy())
            coord_centers.append(coord_center.cpu().numpy())
            coord_spans.append(coord_span)
            
            # è®¡ç®—æœ€è¿‘è·ç¦»
            min_dists, pair_dists = compute_min_distances(positions)
            if len(min_dists) > 0:
                all_min_distances.extend(min_dists.cpu().numpy())
            if len(pair_dists) > 0:
                all_pair_distances.extend(pair_dists.cpu().numpy())
                # è®¡ç®—è·ç¦»>3Ã…çš„åŸå­å¯¹æ¯”ä¾‹
                large_gap_ratio = (pair_dists > 3.0).sum().item() / len(pair_dists) * 100
                large_gap_ratios.append(large_gap_ratio)
            
            # æ„å»ºé”®ç±»å‹çŸ©é˜µ
            _, _, bond_types = build_xae_molecule(
                positions=positions,
                atom_types=atom_types,
                dataset_info=dataset_info,
                atom_decoder=atom_decoder
            )
            
            # æ£€æŸ¥è¿é€šæ€§
            num_components, is_connected = check_connectivity(bond_types)
            num_components_list.append(num_components)
            is_connected_list.append(is_connected)
            
            # è®¡ç®—é”®é•¿ï¼ˆåªè®¡ç®—æœ‰é”®çš„åŸå­å¯¹ï¼‰
            distances = torch.cdist(positions, positions, p=2)
            triu_mask = torch.triu(torch.ones_like(bond_types, dtype=torch.bool), diagonal=1)
            bond_mask = (bond_types > 0) & triu_mask
            
            if bond_mask.any():
                bond_distances = distances[bond_mask]
                bond_lengths.extend(bond_distances.cpu().numpy())
            
        except Exception as e:
            print(f"\nå¤„ç†æ–‡ä»¶ {npz_file} æ—¶å‡ºé”™: {e}")
            continue
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    all_min_distances = np.array(all_min_distances)
    all_pair_distances = np.array(all_pair_distances)
    num_components_list = np.array(num_components_list)
    is_connected_list = np.array(is_connected_list)
    bond_lengths = np.array(bond_lengths) if bond_lengths else np.array([])
    num_atoms_list = np.array(num_atoms_list)
    coord_ranges = np.array(coord_ranges)  # [N_mols, 3]
    coord_centers = np.array(coord_centers)  # [N_mols, 3]
    coord_spans = np.array(coord_spans)
    large_gap_ratios = np.array(large_gap_ratios) if large_gap_ratios else np.array([])
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print("\n" + "="*60)
    print("åˆ†å­ç»“æ„åˆ†æç»“æœ")
    print("="*60)
    
    print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
    print(f"  æ€»åˆ†å­æ•°: {len(npz_files)}")
    print(f"  å¹³å‡åŸå­æ•°: {num_atoms_list.mean():.2f}")
    print(f"  åŸå­æ•°èŒƒå›´: {num_atoms_list.min()} - {num_atoms_list.max()}")
    
    print(f"\nğŸ“ æœ€è¿‘åŸå­è·ç¦»ç»Ÿè®¡:")
    if len(all_min_distances) > 0:
        print(f"  å¹³å‡æœ€è¿‘è·ç¦»: {all_min_distances.mean():.4f} Ã…")
        print(f"  ä¸­ä½æ•°æœ€è¿‘è·ç¦»: {np.median(all_min_distances):.4f} Ã…")
        print(f"  æœ€å°æœ€è¿‘è·ç¦»: {all_min_distances.min():.4f} Ã…")
        print(f"  æœ€å¤§æœ€è¿‘è·ç¦»: {all_min_distances.max():.4f} Ã…")
        print(f"  æ ‡å‡†å·®: {all_min_distances.std():.4f} Ã…")
        
        # ç»Ÿè®¡è·ç¦»è¿‡å¤§çš„åŸå­æ¯”ä¾‹
        large_dist_threshold = 3.0  # è¶…è¿‡3Ã…è®¤ä¸ºè·ç¦»è¿‡å¤§
        large_dist_ratio = (all_min_distances > large_dist_threshold).sum() / len(all_min_distances) * 100
        print(f"  æœ€è¿‘è·ç¦» > {large_dist_threshold}Ã… çš„åŸå­æ¯”ä¾‹: {large_dist_ratio:.2f}%")
        
        # ç»Ÿè®¡è·ç¦»è¿‡å°çš„åŸå­æ¯”ä¾‹ï¼ˆå¯èƒ½æ˜¯é‡å ï¼‰
        small_dist_threshold = 0.5  # å°äº0.5Ã…è®¤ä¸ºè·ç¦»è¿‡å°
        small_dist_ratio = (all_min_distances < small_dist_threshold).sum() / len(all_min_distances) * 100
        print(f"  æœ€è¿‘è·ç¦» < {small_dist_threshold}Ã… çš„åŸå­æ¯”ä¾‹: {small_dist_ratio:.2f}%")
    
    print(f"\nğŸ”— é”®é•¿ç»Ÿè®¡:")
    if len(bond_lengths) > 0:
        print(f"  æ€»é”®æ•°: {len(bond_lengths)}")
        print(f"  å¹³å‡é”®é•¿: {bond_lengths.mean():.4f} Ã…")
        print(f"  ä¸­ä½æ•°é”®é•¿: {np.median(bond_lengths):.4f} Ã…")
        print(f"  é”®é•¿èŒƒå›´: {bond_lengths.min():.4f} - {bond_lengths.max():.4f} Ã…")
        
        # ç»Ÿè®¡å¼‚å¸¸é”®é•¿
        normal_bond_range = (0.7, 2.0)  # æ­£å¸¸é”®é•¿èŒƒå›´
        normal_bond_ratio = ((bond_lengths >= normal_bond_range[0]) & 
                            (bond_lengths <= normal_bond_range[1])).sum() / len(bond_lengths) * 100
        print(f"  æ­£å¸¸é”®é•¿ ({normal_bond_range[0]}-{normal_bond_range[1]}Ã…) æ¯”ä¾‹: {normal_bond_ratio:.2f}%")
    else:
        print("  æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•é”®ï¼")
    
    print(f"\nğŸŒ åˆ†å­è¿é€šæ€§ç»Ÿè®¡:")
    print(f"  è¿é€šåˆ†å­æ•°ï¼ˆè¿é€šåˆ†é‡=1ï¼‰: {is_connected_list.sum()}")
    print(f"  éè¿é€šåˆ†å­æ•°ï¼ˆè¿é€šåˆ†é‡>1ï¼‰: {(~is_connected_list).sum()}")
    print(f"  è¿é€šåˆ†å­æ¯”ä¾‹: {is_connected_list.sum() / len(is_connected_list) * 100:.2f}%")
    print(f"  å¹³å‡è¿é€šåˆ†é‡æ•°: {num_components_list.mean():.2f}")
    print(f"  æœ€å¤§è¿é€šåˆ†é‡æ•°: {num_components_list.max()}")
    print(f"  è¿é€šåˆ†é‡æ•°åˆ†å¸ƒ:")
    unique, counts = np.unique(num_components_list, return_counts=True)
    for comp, count in zip(unique, counts):
        print(f"    {comp} ä¸ªè¿é€šåˆ†é‡: {count} ä¸ªåˆ†å­ ({count/len(num_components_list)*100:.2f}%)")
    
    print(f"\nğŸ“ æ‰€æœ‰åŸå­å¯¹è·ç¦»ç»Ÿè®¡:")
    if len(all_pair_distances) > 0:
        print(f"  å¹³å‡è·ç¦»: {all_pair_distances.mean():.4f} Ã…")
        print(f"  ä¸­ä½æ•°è·ç¦»: {np.median(all_pair_distances):.4f} Ã…")
        print(f"  æœ€å°è·ç¦»: {all_pair_distances.min():.4f} Ã…")
        print(f"  æœ€å¤§è·ç¦»: {all_pair_distances.max():.4f} Ã…")
        
        # ç»Ÿè®¡å¯èƒ½å½¢æˆé”®çš„è·ç¦»ï¼ˆ< 2.0Ã…ï¼‰
        potential_bond_threshold = 2.0
        potential_bonds = (all_pair_distances < potential_bond_threshold).sum()
        print(f"  è·ç¦» < {potential_bond_threshold}Ã… çš„åŸå­å¯¹æ•°é‡: {potential_bonds}")
        print(f"  å¯èƒ½å½¢æˆé”®çš„åŸå­å¯¹æ¯”ä¾‹: {potential_bonds / len(all_pair_distances) * 100:.2f}%")
        
        # ç»Ÿè®¡è·ç¦»è¿‡å¤§çš„åŸå­å¯¹
        large_dist_threshold = 3.0
        large_dists = (all_pair_distances > large_dist_threshold).sum()
        print(f"  è·ç¦» > {large_dist_threshold}Ã… çš„åŸå­å¯¹æ•°é‡: {large_dists}")
        print(f"  è·ç¦»è¿‡å¤§çš„åŸå­å¯¹æ¯”ä¾‹: {large_dists / len(all_pair_distances) * 100:.2f}%")
    
    print(f"\nğŸ“¦ åˆ†å­ç©ºé—´åˆ†å¸ƒç»Ÿè®¡:")
    if len(coord_ranges) > 0:
        print(f"  å¹³å‡åæ ‡èŒƒå›´ (X, Y, Z): ({coord_ranges[:, 0].mean():.2f}, {coord_ranges[:, 1].mean():.2f}, {coord_ranges[:, 2].mean():.2f}) Ã…")
        print(f"  æœ€å¤§åæ ‡èŒƒå›´: {coord_ranges.max():.2f} Ã…")
        print(f"  å¹³å‡åˆ†å­è·¨åº¦ï¼ˆæœ€å¤§åŸå­å¯¹è·ç¦»ï¼‰: {coord_spans.mean():.2f} Ã…")
        print(f"  æœ€å¤§åˆ†å­è·¨åº¦: {coord_spans.max():.2f} Ã…")
        print(f"  ä¸­ä½æ•°åˆ†å­è·¨åº¦: {np.median(coord_spans):.2f} Ã…")
        
        # ç»Ÿè®¡è·¨åº¦è¿‡å¤§çš„åˆ†å­
        large_span_threshold = 10.0  # è¶…è¿‡10Ã…è®¤ä¸ºè·¨åº¦è¿‡å¤§
        large_span_count = (coord_spans > large_span_threshold).sum()
        print(f"  è·¨åº¦ > {large_span_threshold}Ã… çš„åˆ†å­æ•°: {large_span_count} ({large_span_count/len(coord_spans)*100:.2f}%)")
        
        if len(large_gap_ratios) > 0:
            print(f"  å¹³å‡å¤§è·ç¦»åŸå­å¯¹æ¯”ä¾‹ï¼ˆ>3Ã…ï¼‰: {large_gap_ratios.mean():.2f}%")
            print(f"  ä¸­ä½æ•°å¤§è·ç¦»åŸå­å¯¹æ¯”ä¾‹: {np.median(large_gap_ratios):.2f}%")
    
    # ç”Ÿæˆå¯è§†åŒ–
    if output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®å­—ä½“
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial']
        plt.rcParams['axes.unicode_minus'] = False
        
        # 1. æœ€è¿‘è·ç¦»åˆ†å¸ƒ
        if len(all_min_distances) > 0:
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            
            # æœ€è¿‘è·ç¦»ç›´æ–¹å›¾
            axes[0, 0].hist(all_min_distances, bins=100, edgecolor='black', alpha=0.7)
            axes[0, 0].axvline(all_min_distances.mean(), color='r', linestyle='--', 
                              label=f'Mean: {all_min_distances.mean():.3f}Ã…')
            axes[0, 0].axvline(np.median(all_min_distances), color='g', linestyle='--', 
                              label=f'Median: {np.median(all_min_distances):.3f}Ã…')
            axes[0, 0].set_xlabel('Nearest Atom Distance (Ã…)')
            axes[0, 0].set_ylabel('Frequency')
            axes[0, 0].set_title('Nearest Atom Distance Distribution')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            # æœ€è¿‘è·ç¦»ç´¯ç§¯åˆ†å¸ƒ
            sorted_dists = np.sort(all_min_distances)
            cumulative = np.arange(1, len(sorted_dists) + 1) / len(sorted_dists)
            axes[0, 1].plot(sorted_dists, cumulative, linewidth=2)
            axes[0, 1].axvline(3.0, color='r', linestyle='--', label='3.0Ã… threshold')
            axes[0, 1].set_xlabel('Nearest Atom Distance (Ã…)')
            axes[0, 1].set_ylabel('Cumulative Probability')
            axes[0, 1].set_title('Cumulative Distribution of Nearest Distances')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
            
            # é”®é•¿åˆ†å¸ƒ
            if len(bond_lengths) > 0:
                axes[1, 0].hist(bond_lengths, bins=100, edgecolor='black', alpha=0.7, color='orange')
                axes[1, 0].axvline(bond_lengths.mean(), color='r', linestyle='--', 
                                  label=f'Mean: {bond_lengths.mean():.3f}Ã…')
                axes[1, 0].axvline(np.median(bond_lengths), color='g', linestyle='--', 
                                  label=f'Median: {np.median(bond_lengths):.3f}Ã…')
                axes[1, 0].set_xlabel('Bond Length (Ã…)')
                axes[1, 0].set_ylabel('Frequency')
                axes[1, 0].set_title('Bond Length Distribution')
                axes[1, 0].legend()
                axes[1, 0].grid(True, alpha=0.3)
            else:
                axes[1, 0].text(0.5, 0.5, 'No bonds detected', 
                              ha='center', va='center', transform=axes[1, 0].transAxes)
                axes[1, 0].set_title('Bond Length Distribution (No Data)')
            
            # è¿é€šåˆ†é‡æ•°åˆ†å¸ƒ
            unique_components, counts = np.unique(num_components_list, return_counts=True)
            axes[1, 1].bar(unique_components, counts, edgecolor='black', alpha=0.7, color='green')
            axes[1, 1].set_xlabel('Number of Connected Components')
            axes[1, 1].set_ylabel('Number of Molecules')
            axes[1, 1].set_title('Connected Components Distribution')
            axes[1, 1].grid(True, alpha=0.3, axis='y')
        
        # 3. åˆ†å­è·¨åº¦åˆ†å¸ƒ
        if len(coord_spans) > 0:
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.hist(coord_spans, bins=50, edgecolor='black', alpha=0.7, color='red')
            ax.axvline(coord_spans.mean(), color='r', linestyle='--', 
                      label=f'Mean: {coord_spans.mean():.2f}Ã…')
            ax.axvline(np.median(coord_spans), color='g', linestyle='--', 
                      label=f'Median: {np.median(coord_spans):.2f}Ã…')
            ax.axvline(10.0, color='orange', linestyle='--', label='10.0Ã… threshold')
            ax.set_xlabel('Molecular Span (Max Atom Pair Distance, Ã…)')
            ax.set_ylabel('Number of Molecules')
            ax.set_title('Molecular Span Distribution (Reflecting Atom Dispersion)')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            fig_path = output_dir / "molecule_span_distribution.png"
            plt.savefig(fig_path, dpi=300, bbox_inches='tight')
            print(f"åˆ†å­è·¨åº¦åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {fig_path}")
            plt.close()
            
            plt.tight_layout()
            fig_path = output_dir / "molecule_structure_analysis.png"
            plt.savefig(fig_path, dpi=300, bbox_inches='tight')
            print(f"\nå¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {fig_path}")
            plt.close()
        
        # 2. æ‰€æœ‰åŸå­å¯¹è·ç¦»åˆ†å¸ƒï¼ˆå¦‚æœæ•°æ®é‡ä¸å¤ªå¤§ï¼‰
        if len(all_pair_distances) > 0 and len(all_pair_distances) < 1000000:
            fig, ax = plt.subplots(figsize=(10, 6))
            # åªæ˜¾ç¤ºåˆç†èŒƒå›´çš„è·ç¦»
            valid_dists = all_pair_distances[all_pair_distances < 10.0]
            ax.hist(valid_dists, bins=200, edgecolor='black', alpha=0.7, color='purple')
            ax.axvline(valid_dists.mean(), color='r', linestyle='--', 
                      label=f'Mean: {valid_dists.mean():.3f}Ã…')
            ax.axvline(2.0, color='orange', linestyle='--', label='2.0Ã… (potential bond)')
            ax.set_xlabel('Atom Pair Distance (Ã…)')
            ax.set_ylabel('Frequency')
            ax.set_title('Atom Pair Distance Distribution (< 10Ã…)')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            fig_path = output_dir / "pairwise_distance_distribution.png"
            plt.savefig(fig_path, dpi=300, bbox_inches='tight')
            print(f"åŸå­å¯¹è·ç¦»åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {fig_path}")
            plt.close()
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœåˆ°æ–‡ä»¶
        results_file = output_dir / "structure_analysis_results.txt"
        with open(results_file, 'w', encoding='utf-8') as f:
            f.write("åˆ†å­ç»“æ„åˆ†æç»“æœ\n")
            f.write("="*60 + "\n\n")
            f.write(f"æ€»åˆ†å­æ•°: {len(npz_files)}\n")
            f.write(f"å¹³å‡åŸå­æ•°: {num_atoms_list.mean():.2f}\n\n")
            
            if len(all_min_distances) > 0:
                f.write("æœ€è¿‘åŸå­è·ç¦»ç»Ÿè®¡:\n")
                f.write(f"  å¹³å‡: {all_min_distances.mean():.4f} Ã…\n")
                f.write(f"  ä¸­ä½æ•°: {np.median(all_min_distances):.4f} Ã…\n")
                f.write(f"  èŒƒå›´: {all_min_distances.min():.4f} - {all_min_distances.max():.4f} Ã…\n")
                f.write(f"  æ ‡å‡†å·®: {all_min_distances.std():.4f} Ã…\n\n")
            
            if len(bond_lengths) > 0:
                f.write("é”®é•¿ç»Ÿè®¡:\n")
                f.write(f"  æ€»é”®æ•°: {len(bond_lengths)}\n")
                f.write(f"  å¹³å‡: {bond_lengths.mean():.4f} Ã…\n")
                f.write(f"  èŒƒå›´: {bond_lengths.min():.4f} - {bond_lengths.max():.4f} Ã…\n\n")
            
            f.write("è¿é€šæ€§ç»Ÿè®¡:\n")
            f.write(f"  è¿é€šåˆ†å­æ¯”ä¾‹: {is_connected_list.sum() / len(is_connected_list) * 100:.2f}%\n")
            f.write(f"  å¹³å‡è¿é€šåˆ†é‡æ•°: {num_components_list.mean():.2f}\n")
        
        print(f"ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    return {
        'min_distances': all_min_distances,
        'pair_distances': all_pair_distances,
        'bond_lengths': bond_lengths,
        'num_components': num_components_list,
        'is_connected': is_connected_list,
        'num_atoms': num_atoms_list
    }


def main():
    parser = argparse.ArgumentParser(description='åˆ†æç”Ÿæˆåˆ†å­çš„ç»“æ„é—®é¢˜')
    parser.add_argument(
        '--molecule_dir',
        type=str,
        required=True,
        help='åŒ…å« .npz åˆ†å­æ–‡ä»¶çš„ç›®å½•è·¯å¾„'
    )
    parser.add_argument(
        '--output_dir',
        type=str,
        default=None,
        help='è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰'
    )
    
    args = parser.parse_args()
    
    print("="*60)
    print("åˆ†å­ç»“æ„åˆ†æå·¥å…·")
    print("="*60)
    print(f"åˆ†å­ç›®å½•: {args.molecule_dir}")
    print("="*60)
    
    results = analyze_molecules(args.molecule_dir, args.output_dir)
    
    print("\n" + "="*60)
    print("åˆ†æå®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    main()

