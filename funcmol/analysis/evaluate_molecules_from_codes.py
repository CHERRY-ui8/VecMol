"""
è¯„ä¼°ä» .npz æ–‡ä»¶åŠ è½½çš„åˆ†å­è´¨é‡

ä½¿ç”¨æ–¹æ³•:
    python -m funcmol.analysis.evaluate_molecules_from_codes \
        --molecule_dir /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/exps/funcmol/fm_qm9/20251108/molecule \
        --output_dir /datapool/data2/home/pxg/data/hyc/funcmol-main-neuralfield/funcmol/analysis/analysis_metrics
"""

import sys
from pathlib import Path
import torch
import numpy as np
import argparse
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from funcmol.analysis.rdkit_functions import Molecule, check_stability
from funcmol.analysis.baselines_evaluation import (
    SimpleSamplingMetrics,
    atom_decoder_dict,
    build_xae_molecule
)


def load_molecules_from_npz(molecule_dir):
    """
    ä» .npz æ–‡ä»¶ç›´æ¥åŠ è½½å·²ç”Ÿæˆçš„åˆ†å­
    
    Args:
        molecule_dir: åŒ…å« .npz æ–‡ä»¶çš„ç›®å½•è·¯å¾„
        
    Returns:
        list: Molecule å¯¹è±¡åˆ—è¡¨
    """
    molecule_dir = Path(molecule_dir)
    npz_files = sorted(molecule_dir.glob("generated_*.npz"))
    
    print(f"æ‰¾åˆ° {len(npz_files)} ä¸ª .npz åˆ†å­æ–‡ä»¶")
    
    atom_decoder = atom_decoder_dict['qm9_with_h']
    molecules = []
    
    for npz_file in tqdm(npz_files, desc="åŠ è½½åˆ†å­æ–‡ä»¶"):
        try:
            # åŠ è½½ npz æ–‡ä»¶
            data = np.load(npz_file)
            coords = data['coords']  # (N, 3) åæ ‡
            types = data['types']    # (N,) åŸå­ç±»å‹
            
            # è½¬æ¢ä¸ºtorchå¼ é‡
            positions = torch.tensor(coords, dtype=torch.float32)
            atom_types = torch.tensor(types, dtype=torch.long)
            
            # è¿‡æ»¤æ‰å¡«å……çš„åŸå­ï¼ˆå€¼ä¸º -1ï¼‰
            valid_mask = atom_types != -1
            if not valid_mask.any():
                continue
            
            positions = positions[valid_mask]
            atom_types = atom_types[valid_mask]
            
            # æ„å»ºé”®ç±»å‹çŸ©é˜µ
            dataset_info = {'name': 'qm9'}
            _, _, bond_types = build_xae_molecule(
                positions=positions,
                atom_types=atom_types,
                dataset_info=dataset_info,
                atom_decoder=atom_decoder
            )
            
            # åˆ›å»ºé›¶ç”µè·
            charges = torch.zeros_like(atom_types)
            
            # åˆ›å»º Molecule å¯¹è±¡
            molecule = Molecule(
                atom_types=atom_types.long(),
                bond_types=bond_types.long(),
                positions=positions.float(),
                charges=charges,
                atom_decoder=atom_decoder
            )
            
            molecules.append(molecule)
            
        except Exception as e:
            print(f"\nåŠ è½½æ–‡ä»¶ {npz_file} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"æˆåŠŸåŠ è½½ {len(molecules)} ä¸ªåˆ†å­")
    return molecules




def evaluate_molecules(molecules, output_dir=None):
    """
    è¯„ä¼°åˆ†å­è´¨é‡æŒ‡æ ‡
    
    Args:
        molecules: Molecule å¯¹è±¡åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
    """
    if not molecules:
        print("æ²¡æœ‰æœ‰æ•ˆçš„åˆ†å­å¯ä»¥è¯„ä¼°ï¼")
        return
    
    # åˆ›å»ºç®€åŒ–çš„æ•°æ®é›†ä¿¡æ¯
    class SimpleDatasetInfo:
        def __init__(self):
            self.atom_decoder = atom_decoder_dict['qm9_with_h']
            self.remove_h = False
            # æ·»åŠ å¿…è¦çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            self.statistics = {
                'test': type('obj', (object,), {
                    'num_nodes': {i: 1 for i in range(1, 30)},
                    'atom_types': torch.ones(5),
                    'bond_types': torch.ones(5),
                    'charge_types': torch.ones(5),
                    'valencies': {atom: {0: 1, 1: 1, 2: 1, 3: 1, 4: 1} for atom in atom_decoder_dict['qm9_with_h']},
                    'bond_lengths': {1: {1.5: 1}, 2: {1.3: 1}, 3: {1.2: 1}, 4: {1.4: 1}},
                    'bond_angles': torch.ones(5, 1801)
                })()
            }
    
    dataset_infos = SimpleDatasetInfo()
    
    # åˆ›å»ºé‡‡æ ·æŒ‡æ ‡è¯„ä¼°å™¨
    sampling_metrics = SimpleSamplingMetrics(
        train_smiles=[],
        dataset_infos=dataset_infos,
        test=True
    )
    
    # è¯„ä¼°åˆ†å­
    print("\n" + "="*60)
    print(f"å¼€å§‹è¯„ä¼°åˆ†å­è´¨é‡ï¼ˆå…± {len(molecules)} ä¸ªåˆ†å­ï¼‰...")
    print("="*60)
    
    print("æ­£åœ¨è®¡ç®—æœ‰æ•ˆæ€§ã€å”¯ä¸€æ€§å’Œæ–°é¢–æ€§...")
    sampling_metrics(
        molecules=molecules,
        name='generated_molecules',
        current_epoch=0,
        local_rank=0
    )
    print("è¯„ä¼°å®Œæˆï¼")
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("åˆ†å­è´¨é‡è¯„ä¼°ç»“æœ")
    print("="*60)
    
    validity = sampling_metrics.validity_metric
    uniqueness = sampling_metrics.uniqueness
    novelty = sampling_metrics.novelty
    mean_components = sampling_metrics.mean_components
    max_components = sampling_metrics.max_components
    mol_stable = sampling_metrics.mol_stable
    atom_stable = sampling_metrics.atom_stable
    
    print(f"\nğŸ“Š æ€»ä½“è´¨é‡æŒ‡æ ‡:")
    print(f"  æœ‰æ•ˆæ€§ (Validity): {validity*100:.2f}%")
    print(f"  å”¯ä¸€æ€§ (Uniqueness): {uniqueness*100:.2f}%")
    print(f"  æ–°é¢–æ€§ (Novelty): {novelty*100:.2f}%")
    print(f"  å¹³å‡è¿é€šåˆ†é‡æ•°: {mean_components:.2f}")
    print(f"  æœ€å¤§è¿é€šåˆ†é‡æ•°: {max_components:.2f}")
    print(f"  åˆ†å­ç¨³å®šæ€§: {float(mol_stable)*100:.2f}%")
    print(f"  åŸå­ç¨³å®šæ€§: {float(atom_stable)*100:.2f}%")
    
    # åˆ†æå•ä¸ªåˆ†å­
    print(f"\nğŸ“ˆ å•ä¸ªåˆ†å­åˆ†æï¼ˆå‰10ä¸ªï¼‰:")
    valid_molecules = 0
    stable_molecules = 0
    
    for i, mol in enumerate(molecules[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
        if mol.rdkit_mol is not None:
            valid_molecules += 1
            try:
                mol_stable, atom_stable, _ = check_stability(
                    mol, None, atom_decoder=atom_decoder_dict['qm9_with_h']
                )
                if mol_stable.item() > 0.5:
                    stable_molecules += 1
                    print(f"  åˆ†å­ {i+1}: {mol.num_nodes} ä¸ªåŸå­, RDKitæœ‰æ•ˆ: æ˜¯, ç¨³å®š: æ˜¯")
                else:
                    print(f"  åˆ†å­ {i+1}: {mol.num_nodes} ä¸ªåŸå­, RDKitæœ‰æ•ˆ: æ˜¯, ç¨³å®š: å¦")
            except Exception as e:
                print(f"  åˆ†å­ {i+1}: {mol.num_nodes} ä¸ªåŸå­, RDKitæœ‰æ•ˆ: æ˜¯, ç¨³å®šæ€§æ£€æŸ¥å¤±è´¥: {e}")
        else:
            print(f"  åˆ†å­ {i+1}: {mol.num_nodes} ä¸ªåŸå­, RDKitæœ‰æ•ˆ: å¦")
    
    # ç»Ÿè®¡æ‰€æœ‰åˆ†å­
    print(f"\nğŸ“Š ç»Ÿè®¡æ‰€æœ‰åˆ†å­ï¼ˆå…± {len(molecules)} ä¸ªï¼‰...")
    total_valid = sum(1 for mol in tqdm(molecules, desc="æ£€æŸ¥æœ‰æ•ˆæ€§", leave=False) if mol.rdkit_mol is not None)
    total_stable = 0
    for mol in tqdm(molecules, desc="æ£€æŸ¥ç¨³å®šæ€§"):
        if mol.rdkit_mol is not None:
            try:
                mol_stable, _, _ = check_stability(
                    mol, None, atom_decoder=atom_decoder_dict['qm9_with_h']
                )
                if mol_stable.item() > 0.5:
                    total_stable += 1
            except:
                pass
    
    print(f"\nğŸ“Š ç»Ÿè®¡æ‘˜è¦:")
    print(f"  æ€»åˆ†å­æ•°: {len(molecules)}")
    print(f"  æœ‰æ•ˆåˆ†å­æ•°: {total_valid}")
    print(f"  ç¨³å®šåˆ†å­æ•°: {total_stable}")
    print(f"  æœ‰æ•ˆæ€§: {total_valid/len(molecules)*100:.1f}%")
    print(f"  ç¨³å®šæ€§: {total_stable/len(molecules)*100:.1f}%")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šäº†è¾“å‡ºç›®å½•ï¼‰
    if output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        results_file = output_dir / "evaluation_results.txt"
        with open(results_file, 'w', encoding='utf-8') as f:
            f.write("åˆ†å­è´¨é‡è¯„ä¼°ç»“æœ\n")
            f.write("="*60 + "\n\n")
            f.write(f"æ€»åˆ†å­æ•°: {len(molecules)}\n")
            f.write(f"æœ‰æ•ˆåˆ†å­æ•°: {total_valid}\n")
            f.write(f"ç¨³å®šåˆ†å­æ•°: {total_stable}\n")
            f.write(f"æœ‰æ•ˆæ€§: {validity*100:.2f}%\n")
            f.write(f"å”¯ä¸€æ€§: {uniqueness*100:.2f}%\n")
            f.write(f"æ–°é¢–æ€§: {novelty*100:.2f}%\n")
            f.write(f"å¹³å‡è¿é€šåˆ†é‡æ•°: {mean_components:.2f}\n")
            f.write(f"æœ€å¤§è¿é€šåˆ†é‡æ•°: {max_components:.2f}\n")
            f.write(f"åˆ†å­ç¨³å®šæ€§: {float(mol_stable)*100:.2f}%\n")
            f.write(f"åŸå­ç¨³å®šæ€§: {float(atom_stable)*100:.2f}%\n")
        
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {results_file}")


def main():
    parser = argparse.ArgumentParser(description='è¯„ä¼°ä» .npz æ–‡ä»¶åŠ è½½çš„åˆ†å­è´¨é‡')
    parser.add_argument(
        '--molecule_dir',
        type=str,
        required=True,
        help='åŒ…å« .npz åˆ†å­æ–‡ä»¶çš„ç›®å½•è·¯å¾„'
    )
    parser.add_argument(
        '--output_dir',
        type=str,
        default=None,
        help='è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰'
    )
    
    args = parser.parse_args()
    
    print("="*60)
    print("åˆ†å­è´¨é‡è¯„ä¼°å·¥å…·")
    print("="*60)
    print(f"åˆ†å­ç›®å½•: {args.molecule_dir}")
    print("="*60)
    
    # 1. åŠ è½½åˆ†å­
    print("\n1. åŠ è½½åˆ†å­æ–‡ä»¶...")
    molecules = load_molecules_from_npz(args.molecule_dir)
    
    if not molecules:
        print("é”™è¯¯: æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•åˆ†å­ï¼")
        return
    
    print(f"æˆåŠŸåŠ è½½ {len(molecules)} ä¸ªåˆ†å­")
    
    # 2. è¯„ä¼°åˆ†å­
    print("\n2. è¯„ä¼°åˆ†å­è´¨é‡...")
    evaluate_molecules(molecules, output_dir=args.output_dir)
    
    print("\n" + "="*60)
    print("è¯„ä¼°å®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    main()

