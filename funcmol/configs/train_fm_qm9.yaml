defaults:
  - dset: qm9
  - encoder: gnn
  - decoder: decoder_global
  - denoiser: gnn
  - wjs: wjs_training_small
  - converter: gnf_converter_qm9
  - override hydra/job_logging: custom
  - _self_

debug: False
wandb: False
seed: 1234

diffusion_method: "new_x0"  # "old" (WJS) 或 "new" (DDPM) 或 "new_x0" (DDPM with x0)

# DDPM配置（仅当diffusion_method为"new"或"new_x0"时使用）
ddpm:
  # 模型配置
  hidden_dim: 128
  num_layers: 4
  time_emb_dim: 64
  dropout: 0.1
  
  # 扩散过程配置
  # 根据 num_timesteps 选择对应的 beta 配置：
  # - num_timesteps: 100   -> beta_start: 0.0005, beta_end: 0.05
  # - num_timesteps: 1000 -> beta_start: 0.0001, beta_end: 0.02
  num_timesteps: 1000 # 1000
  beta_start: 0.0001  # 当 num_timesteps: 100 时使用0.0005；当 num_timesteps: 1000 时改为 0.0001
  beta_end: 0.02      # 当 num_timesteps: 100 时使用0.05；当 num_timesteps: 1000 时改为 0.02
  schedule: "linear"  # 可选: "linear", "cosine", "sigmoid"
  
  # Sigmoid调度参数（仅当schedule为"sigmoid"时使用）
  s1: 0.008
  sT: 0.008
  w: 1.0

# nf_pretrained_path: ../exps/neural_field/nf_qm9
# nf_pretrained_path: ../exps/neural_field/nf_qm9_20250812_181425_750832
nf_pretrained_path: /datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/model-epoch=409.ckpt
exp_dir: ../exps/funcmol
exp_name: "fm_${dset.dset_name}/${now:%Y%m%d}"
dirname: "${exp_dir}/${exp_name}"
reload_model_path: null

# data params
smooth_sigma: 0.5 # 2.0, 1.0, 0.5
normalize_codes: 1
on_the_fly: False  # use True to compute codes on the fly from neural field
codes_dir: "/datapool/data3/storage/pengxingang/pxg/hyc/funcmol-main-neuralfield/exps/neural_field/nf_qm9/20251024/lightning_logs/version_0/checkpoints/"

# data augmentation for denoiser training
use_data_augmentation: True  # 是否启用数据增强
data_augmentation:
  apply_rotation: True  # 是否应用旋转增强
  apply_translation: False  # 是否应用平移增强

# training params
num_epochs: 50000
num_iterations: 50000  # 总迭代次数，用于学习率调度
dset:
  batch_size: 16
  num_workers: 1

ckpt_every_n_epochs: 5  # 每隔多少epoch保存一次ckpt
decoder:
  code_dim: 128 # 和encoder的code_dim一致
num_augmentations: null

# optim params
lr: 1e-3 # 5e-4
# use_lr_schedule: 1 # 0-NOT use lr schedule, 1-use lr schedule
use_lr_schedule: 0 # 暂时禁用学习率调度，使用固定学习率
# num_warmup_iter: 4000
num_warmup_iter: 1000
wd: 1e-6
# ema_decay: 0.999
ema_decay: 0.999  # 启用EMA
max_grad_norm: 0.5  # 0.5，1

# set the running dir
hydra:
  run:
    dir: "${dirname}"
  job:
    chdir: false
  output_subdir: null
